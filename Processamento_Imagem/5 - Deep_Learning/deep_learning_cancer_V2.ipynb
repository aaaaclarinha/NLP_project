{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 images belonging to 3 classes.\n",
      "Found 120 images belonging to 3 classes.\n",
      "Found 120 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy-VS\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_56 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_57 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_58 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_59 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,097,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m1,539\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,164,771</span> (8.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,164,771\u001b[0m (8.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,164,771</span> (8.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,164,771\u001b[0m (8.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy-VS\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3878 - loss: 1.1514\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63333, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 298ms/step - accuracy: 0.3903 - loss: 1.1455 - val_accuracy: 0.6333 - val_loss: 0.7230 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.6741 - loss: 0.6133\n",
      "Epoch 2: val_accuracy improved from 0.63333 to 0.70000, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.6746 - loss: 0.6115 - val_accuracy: 0.7000 - val_loss: 0.4555 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.6843 - loss: 0.5512\n",
      "Epoch 3: val_accuracy improved from 0.70000 to 0.78333, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 293ms/step - accuracy: 0.6852 - loss: 0.5503 - val_accuracy: 0.7833 - val_loss: 0.4629 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.7370 - loss: 0.5847\n",
      "Epoch 4: val_accuracy did not improve from 0.78333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 387ms/step - accuracy: 0.7372 - loss: 0.5838 - val_accuracy: 0.7667 - val_loss: 0.4497 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7690 - loss: 0.4885\n",
      "Epoch 5: val_accuracy improved from 0.78333 to 0.80000, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - accuracy: 0.7691 - loss: 0.4880 - val_accuracy: 0.8000 - val_loss: 0.3844 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7351 - loss: 0.4920\n",
      "Epoch 6: val_accuracy improved from 0.80000 to 0.85833, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 206ms/step - accuracy: 0.7356 - loss: 0.4920 - val_accuracy: 0.8583 - val_loss: 0.4268 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7740 - loss: 0.4771\n",
      "Epoch 7: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - accuracy: 0.7741 - loss: 0.4751 - val_accuracy: 0.8500 - val_loss: 0.3409 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8054 - loss: 0.4413\n",
      "Epoch 8: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - accuracy: 0.8063 - loss: 0.4396 - val_accuracy: 0.7917 - val_loss: 0.3695 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7755 - loss: 0.4559\n",
      "Epoch 9: val_accuracy improved from 0.85833 to 0.89167, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - accuracy: 0.7767 - loss: 0.4550 - val_accuracy: 0.8917 - val_loss: 0.3240 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8475 - loss: 0.3856\n",
      "Epoch 10: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 204ms/step - accuracy: 0.8470 - loss: 0.3854 - val_accuracy: 0.8833 - val_loss: 0.3143 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8174 - loss: 0.4211\n",
      "Epoch 11: val_accuracy improved from 0.89167 to 0.93333, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.8173 - loss: 0.4179 - val_accuracy: 0.9333 - val_loss: 0.2568 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8220 - loss: 0.3761\n",
      "Epoch 12: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - accuracy: 0.8217 - loss: 0.3780 - val_accuracy: 0.9250 - val_loss: 0.2938 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.8464 - loss: 0.3421\n",
      "Epoch 13: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 389ms/step - accuracy: 0.8465 - loss: 0.3425 - val_accuracy: 0.8750 - val_loss: 0.2674 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8317 - loss: 0.3597\n",
      "Epoch 14: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.8332 - loss: 0.3579 - val_accuracy: 0.9083 - val_loss: 0.2341 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9029 - loss: 0.2555\n",
      "Epoch 15: val_accuracy improved from 0.93333 to 0.94167, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 381ms/step - accuracy: 0.9014 - loss: 0.2583 - val_accuracy: 0.9417 - val_loss: 0.2318 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.8458 - loss: 0.3187\n",
      "Epoch 16: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.8468 - loss: 0.3178 - val_accuracy: 0.8583 - val_loss: 0.3284 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.8907 - loss: 0.3218\n",
      "Epoch 17: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 419ms/step - accuracy: 0.8910 - loss: 0.3201 - val_accuracy: 0.9083 - val_loss: 0.2247 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.8902 - loss: 0.3180\n",
      "Epoch 18: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.8902 - loss: 0.3173 - val_accuracy: 0.9167 - val_loss: 0.2323 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8905 - loss: 0.2775\n",
      "Epoch 19: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 378ms/step - accuracy: 0.8880 - loss: 0.2799 - val_accuracy: 0.8917 - val_loss: 0.2408 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8443 - loss: 0.3251\n",
      "Epoch 20: val_accuracy improved from 0.94167 to 0.95000, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - accuracy: 0.8454 - loss: 0.3246 - val_accuracy: 0.9500 - val_loss: 0.1854 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8641 - loss: 0.2923\n",
      "Epoch 21: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.8646 - loss: 0.2921 - val_accuracy: 0.8917 - val_loss: 0.2551 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8690 - loss: 0.3167\n",
      "Epoch 22: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 353ms/step - accuracy: 0.8703 - loss: 0.3147 - val_accuracy: 0.9333 - val_loss: 0.1847 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8945 - loss: 0.2506\n",
      "Epoch 23: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.8933 - loss: 0.2517 - val_accuracy: 0.9417 - val_loss: 0.1787 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8893 - loss: 0.2819\n",
      "Epoch 24: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - accuracy: 0.8890 - loss: 0.2814 - val_accuracy: 0.9167 - val_loss: 0.1841 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.8625 - loss: 0.3049\n",
      "Epoch 25: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 378ms/step - accuracy: 0.8630 - loss: 0.3040 - val_accuracy: 0.9167 - val_loss: 0.1943 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9064 - loss: 0.2462\n",
      "Epoch 26: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - accuracy: 0.9056 - loss: 0.2469 - val_accuracy: 0.9000 - val_loss: 0.2756 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8912 - loss: 0.3241\n",
      "Epoch 27: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - accuracy: 0.8906 - loss: 0.3230 - val_accuracy: 0.9000 - val_loss: 0.2505 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8680 - loss: 0.2989\n",
      "Epoch 28: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.8675 - loss: 0.2997 - val_accuracy: 0.9167 - val_loss: 0.2052 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.8692 - loss: 0.3159\n",
      "Epoch 29: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 402ms/step - accuracy: 0.8691 - loss: 0.3170 - val_accuracy: 0.8833 - val_loss: 0.2685 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.8679 - loss: 0.2978\n",
      "Epoch 30: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 420ms/step - accuracy: 0.8689 - loss: 0.2971 - val_accuracy: 0.9250 - val_loss: 0.2000 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.8971 - loss: 0.2503\n",
      "Epoch 31: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 380ms/step - accuracy: 0.8960 - loss: 0.2529 - val_accuracy: 0.9333 - val_loss: 0.2100 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9177 - loss: 0.2678\n",
      "Epoch 32: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 391ms/step - accuracy: 0.9169 - loss: 0.2676 - val_accuracy: 0.9500 - val_loss: 0.1554 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.8922 - loss: 0.2727\n",
      "Epoch 33: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 404ms/step - accuracy: 0.8929 - loss: 0.2711 - val_accuracy: 0.9333 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9153 - loss: 0.2305\n",
      "Epoch 34: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.9149 - loss: 0.2307 - val_accuracy: 0.9417 - val_loss: 0.2145 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.9034 - loss: 0.2196\n",
      "Epoch 35: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 419ms/step - accuracy: 0.9027 - loss: 0.2207 - val_accuracy: 0.9333 - val_loss: 0.1796 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.8780 - loss: 0.2600\n",
      "Epoch 36: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 377ms/step - accuracy: 0.8790 - loss: 0.2587 - val_accuracy: 0.9417 - val_loss: 0.1809 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.8961 - loss: 0.2440\n",
      "Epoch 37: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 383ms/step - accuracy: 0.8966 - loss: 0.2439 - val_accuracy: 0.9000 - val_loss: 0.2435 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.8551 - loss: 0.2999\n",
      "Epoch 38: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 395ms/step - accuracy: 0.8551 - loss: 0.3007 - val_accuracy: 0.8667 - val_loss: 0.4239 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8884 - loss: 0.2948\n",
      "Epoch 39: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 399ms/step - accuracy: 0.8886 - loss: 0.2932 - val_accuracy: 0.9417 - val_loss: 0.1624 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8674 - loss: 0.3218\n",
      "Epoch 40: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 384ms/step - accuracy: 0.8693 - loss: 0.3176 - val_accuracy: 0.9333 - val_loss: 0.2065 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.8954 - loss: 0.2438\n",
      "Epoch 41: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.8953 - loss: 0.2435 - val_accuracy: 0.9250 - val_loss: 0.1901 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.8982 - loss: 0.2402\n",
      "Epoch 42: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 329ms/step - accuracy: 0.8974 - loss: 0.2431 - val_accuracy: 0.9083 - val_loss: 0.2876 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9020 - loss: 0.2455\n",
      "Epoch 43: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9013 - loss: 0.2472 - val_accuracy: 0.9250 - val_loss: 0.2145 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.9131 - loss: 0.2304\n",
      "Epoch 44: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 383ms/step - accuracy: 0.9125 - loss: 0.2319 - val_accuracy: 0.9333 - val_loss: 0.1669 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.8899 - loss: 0.2678\n",
      "Epoch 45: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.8898 - loss: 0.2688 - val_accuracy: 0.9417 - val_loss: 0.1559 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.9021 - loss: 0.2390\n",
      "Epoch 46: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9021 - loss: 0.2408 - val_accuracy: 0.9250 - val_loss: 0.2247 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.9074 - loss: 0.2514\n",
      "Epoch 47: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - accuracy: 0.9049 - loss: 0.2543 - val_accuracy: 0.9250 - val_loss: 0.1841 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.9207 - loss: 0.2179\n",
      "Epoch 48: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - accuracy: 0.9192 - loss: 0.2208 - val_accuracy: 0.9500 - val_loss: 0.1665 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.8800 - loss: 0.2658\n",
      "Epoch 49: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.8807 - loss: 0.2656 - val_accuracy: 0.9417 - val_loss: 0.1607 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8745 - loss: 0.2896\n",
      "Epoch 50: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - accuracy: 0.8763 - loss: 0.2869 - val_accuracy: 0.8917 - val_loss: 0.2315 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8826 - loss: 0.2506\n",
      "Epoch 51: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.8827 - loss: 0.2500 - val_accuracy: 0.9333 - val_loss: 0.1721 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9010 - loss: 0.2295\n",
      "Epoch 52: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - accuracy: 0.9015 - loss: 0.2287 - val_accuracy: 0.9333 - val_loss: 0.1571 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9435 - loss: 0.1661\n",
      "Epoch 53: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - accuracy: 0.9421 - loss: 0.1686 - val_accuracy: 0.9250 - val_loss: 0.1474 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8925 - loss: 0.2593\n",
      "Epoch 54: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step - accuracy: 0.8928 - loss: 0.2586 - val_accuracy: 0.9083 - val_loss: 0.2289 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8759 - loss: 0.2944\n",
      "Epoch 55: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - accuracy: 0.8780 - loss: 0.2905 - val_accuracy: 0.9333 - val_loss: 0.1531 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.9245 - loss: 0.2095\n",
      "Epoch 56: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.9230 - loss: 0.2101 - val_accuracy: 0.9417 - val_loss: 0.1749 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8937 - loss: 0.2266\n",
      "Epoch 57: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - accuracy: 0.8947 - loss: 0.2252 - val_accuracy: 0.9500 - val_loss: 0.1468 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.9253 - loss: 0.1904\n",
      "Epoch 58: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 205ms/step - accuracy: 0.9240 - loss: 0.1931 - val_accuracy: 0.8833 - val_loss: 0.2544 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8867 - loss: 0.2747\n",
      "Epoch 59: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 284ms/step - accuracy: 0.8874 - loss: 0.2735 - val_accuracy: 0.8917 - val_loss: 0.2624 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.8995 - loss: 0.2425\n",
      "Epoch 60: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.9000 - loss: 0.2426 - val_accuracy: 0.9333 - val_loss: 0.1829 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9002 - loss: 0.2222\n",
      "Epoch 61: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 376ms/step - accuracy: 0.9001 - loss: 0.2225 - val_accuracy: 0.9333 - val_loss: 0.1609 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9000 - loss: 0.2131\n",
      "Epoch 62: val_accuracy improved from 0.95000 to 0.96667, saving model to saved_models/best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.9004 - loss: 0.2141 - val_accuracy: 0.9667 - val_loss: 0.1481 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9178 - loss: 0.1958\n",
      "Epoch 63: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9174 - loss: 0.1977 - val_accuracy: 0.9417 - val_loss: 0.1651 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.8936 - loss: 0.2454\n",
      "Epoch 64: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.8939 - loss: 0.2448 - val_accuracy: 0.9333 - val_loss: 0.1794 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9029 - loss: 0.2364\n",
      "Epoch 65: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9035 - loss: 0.2345 - val_accuracy: 0.9167 - val_loss: 0.1842 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.9056 - loss: 0.2030\n",
      "Epoch 66: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.9059 - loss: 0.2036 - val_accuracy: 0.8917 - val_loss: 0.2543 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.8900 - loss: 0.2908\n",
      "Epoch 67: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 413ms/step - accuracy: 0.8897 - loss: 0.2901 - val_accuracy: 0.8917 - val_loss: 0.2145 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.8916 - loss: 0.2513\n",
      "Epoch 68: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 391ms/step - accuracy: 0.8925 - loss: 0.2496 - val_accuracy: 0.9250 - val_loss: 0.1768 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9119 - loss: 0.1784\n",
      "Epoch 69: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 407ms/step - accuracy: 0.9118 - loss: 0.1792 - val_accuracy: 0.9250 - val_loss: 0.1654 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9127 - loss: 0.1900\n",
      "Epoch 70: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 400ms/step - accuracy: 0.9128 - loss: 0.1904 - val_accuracy: 0.9333 - val_loss: 0.1385 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9167 - loss: 0.1752\n",
      "Epoch 71: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 397ms/step - accuracy: 0.9170 - loss: 0.1759 - val_accuracy: 0.8833 - val_loss: 0.2316 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9343 - loss: 0.1967\n",
      "Epoch 72: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 384ms/step - accuracy: 0.9333 - loss: 0.1966 - val_accuracy: 0.9250 - val_loss: 0.1674 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9499 - loss: 0.1565\n",
      "Epoch 73: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - accuracy: 0.9490 - loss: 0.1578 - val_accuracy: 0.9500 - val_loss: 0.1321 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9140 - loss: 0.1858\n",
      "Epoch 74: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 200ms/step - accuracy: 0.9136 - loss: 0.1889 - val_accuracy: 0.8833 - val_loss: 0.2831 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9221 - loss: 0.1977\n",
      "Epoch 75: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - accuracy: 0.9209 - loss: 0.1998 - val_accuracy: 0.9250 - val_loss: 0.2517 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9102 - loss: 0.2180\n",
      "Epoch 76: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - accuracy: 0.9103 - loss: 0.2171 - val_accuracy: 0.9500 - val_loss: 0.1659 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8993 - loss: 0.2599\n",
      "Epoch 77: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step - accuracy: 0.8992 - loss: 0.2581 - val_accuracy: 0.8917 - val_loss: 0.2692 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.9267 - loss: 0.1852\n",
      "Epoch 78: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.9257 - loss: 0.1883 - val_accuracy: 0.9167 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.9294 - loss: 0.1771\n",
      "Epoch 79: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.9289 - loss: 0.1791 - val_accuracy: 0.9333 - val_loss: 0.1585 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9267 - loss: 0.2043\n",
      "Epoch 80: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.9262 - loss: 0.2051 - val_accuracy: 0.9333 - val_loss: 0.1586 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9138 - loss: 0.1931\n",
      "Epoch 81: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - accuracy: 0.9137 - loss: 0.1945 - val_accuracy: 0.9250 - val_loss: 0.1577 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9248 - loss: 0.2052\n",
      "Epoch 82: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.9250 - loss: 0.2044 - val_accuracy: 0.9333 - val_loss: 0.1534 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.9227 - loss: 0.1873\n",
      "Epoch 83: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.9232 - loss: 0.1870 - val_accuracy: 0.9583 - val_loss: 0.1286 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9067 - loss: 0.2385\n",
      "Epoch 84: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.9084 - loss: 0.2348 - val_accuracy: 0.9000 - val_loss: 0.1784 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.9113 - loss: 0.1950\n",
      "Epoch 85: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.9116 - loss: 0.1944 - val_accuracy: 0.8917 - val_loss: 0.1911 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9072 - loss: 0.2111\n",
      "Epoch 86: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - accuracy: 0.9083 - loss: 0.2090 - val_accuracy: 0.9417 - val_loss: 0.1322 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.9255 - loss: 0.2100\n",
      "Epoch 87: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.9247 - loss: 0.2114 - val_accuracy: 0.9083 - val_loss: 0.2225 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9003 - loss: 0.2588\n",
      "Epoch 88: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 198ms/step - accuracy: 0.8995 - loss: 0.2591 - val_accuracy: 0.8750 - val_loss: 0.2413 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.8782 - loss: 0.2275\n",
      "Epoch 89: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - accuracy: 0.8801 - loss: 0.2256 - val_accuracy: 0.9417 - val_loss: 0.1426 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9000 - loss: 0.2162\n",
      "Epoch 90: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.9007 - loss: 0.2151 - val_accuracy: 0.9083 - val_loss: 0.1903 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9339 - loss: 0.1723\n",
      "Epoch 91: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - accuracy: 0.9337 - loss: 0.1726 - val_accuracy: 0.8917 - val_loss: 0.2783 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9084 - loss: 0.1936\n",
      "Epoch 92: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 266ms/step - accuracy: 0.9088 - loss: 0.1933 - val_accuracy: 0.9417 - val_loss: 0.1318 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9158 - loss: 0.2109\n",
      "Epoch 93: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - accuracy: 0.9168 - loss: 0.2095 - val_accuracy: 0.9250 - val_loss: 0.1643 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.9130 - loss: 0.2117\n",
      "Epoch 94: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - accuracy: 0.9135 - loss: 0.2100 - val_accuracy: 0.9333 - val_loss: 0.1618 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.9197 - loss: 0.2169\n",
      "Epoch 95: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.9201 - loss: 0.2146 - val_accuracy: 0.9083 - val_loss: 0.1960 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.9057 - loss: 0.2064\n",
      "Epoch 96: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - accuracy: 0.9065 - loss: 0.2055 - val_accuracy: 0.9333 - val_loss: 0.1568 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.9500 - loss: 0.1521\n",
      "Epoch 97: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step - accuracy: 0.9479 - loss: 0.1540 - val_accuracy: 0.9417 - val_loss: 0.1416 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.9097 - loss: 0.2075\n",
      "Epoch 98: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - accuracy: 0.9103 - loss: 0.2076 - val_accuracy: 0.8917 - val_loss: 0.2592 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9032 - loss: 0.2025\n",
      "Epoch 99: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - accuracy: 0.9041 - loss: 0.2026 - val_accuracy: 0.9167 - val_loss: 0.1920 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.9079 - loss: 0.1923\n",
      "Epoch 100: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.9083 - loss: 0.1918 - val_accuracy: 0.9667 - val_loss: 0.1152 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step - accuracy: 0.8683 - loss: 0.2793\n",
      "Accuracy on the test dataset =  89.99999761581421 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 1024\n",
    "EPOCHS = 100\n",
    "\n",
    "# Set up the directories\n",
    "train_dir = \"../Images_data/training_test_reduced/training_set\"\n",
    "test_dir = \"../Images_data/training_test_reduced/test_set\"\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Setting aside 20% of training data for validation\n",
    ")\n",
    "\n",
    "# Data normalization for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    seed=RANDOM_SEED,\n",
    "    subset='training'  # Use training subset\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    seed=RANDOM_SEED,\n",
    "    subset='validation'  # Use validation subset\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    seed=RANDOM_SEED,\n",
    "    shuffle=False  # No shuffling to maintain order for evaluation\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "drop = 0.25\n",
    "#kernel_initializer = 'he_uniform'  # Using he uniform initializer\n",
    "kernel_initializer = 'glorot_uniform'  # Using glorot uniform initializer\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same', input_shape=(32, 32, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(drop),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(drop),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_initializer=kernel_initializer),\n",
    "    Dropout(drop),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "opt = Adam(use_ema=True)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint('saved_models/best_model.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "log_csv = CSVLogger('saved_logs/my_logs.csv', separator=',', append=False)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < int(0.3 * epoch):\n",
    "        return lr\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "callbacks_list = [checkpoint, log_csv, LearningRateScheduler(scheduler)]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "_, test_acc = model.evaluate(test_generator)\n",
    "print(\"Accuracy on the test dataset = \", (test_acc * 100.0), \"%\")\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_test = model.predict(test_generator)\n",
    "prediction_test = np.argmax(y_pred_test, axis=1)\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "# Parallelizing confusion matrix computation using ThreadPoolExecutor\n",
    "def compute_confusion_matrix(ground_truth, prediction_test):\n",
    "    return confusion_matrix(ground_truth, prediction_test)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    cm = executor.submit(compute_confusion_matrix, ground_truth, prediction_test).result()\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code + Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy-VS\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy-VS\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3226 - loss: 7.0358\n",
      "Epoch 1: val_accuracy improved from -inf to 0.44167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.3224 - loss: 6.8658 - val_accuracy: 0.4417 - val_loss: 1.0619 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3514 - loss: 1.0778\n",
      "Epoch 2: val_accuracy improved from 0.44167 to 0.62500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.3531 - loss: 1.0766 - val_accuracy: 0.6250 - val_loss: 0.9919 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5899 - loss: 0.8531\n",
      "Epoch 3: val_accuracy improved from 0.62500 to 0.79167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.5913 - loss: 0.8467 - val_accuracy: 0.7917 - val_loss: 0.4576 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6311 - loss: 0.6222\n",
      "Epoch 4: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6314 - loss: 0.6190 - val_accuracy: 0.6750 - val_loss: 0.5087 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6405 - loss: 0.6007\n",
      "Epoch 5: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.6403 - loss: 0.6009 - val_accuracy: 0.7583 - val_loss: 0.4624 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7038 - loss: 0.5514\n",
      "Epoch 6: val_accuracy improved from 0.79167 to 0.80000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7036 - loss: 0.5488 - val_accuracy: 0.8000 - val_loss: 0.3886 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7289 - loss: 0.5021\n",
      "Epoch 7: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7292 - loss: 0.5022 - val_accuracy: 0.7667 - val_loss: 0.4064 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7100 - loss: 0.5042\n",
      "Epoch 8: val_accuracy improved from 0.80000 to 0.82500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.7121 - loss: 0.5023 - val_accuracy: 0.8250 - val_loss: 0.3401 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8395 - loss: 0.3910\n",
      "Epoch 9: val_accuracy improved from 0.82500 to 0.87500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8388 - loss: 0.3923 - val_accuracy: 0.8750 - val_loss: 0.3282 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8016 - loss: 0.4511\n",
      "Epoch 10: val_accuracy improved from 0.87500 to 0.88333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8011 - loss: 0.4499 - val_accuracy: 0.8833 - val_loss: 0.2872 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7988 - loss: 0.4276\n",
      "Epoch 11: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7980 - loss: 0.4285 - val_accuracy: 0.7667 - val_loss: 0.4682 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7380 - loss: 0.4602\n",
      "Epoch 12: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7392 - loss: 0.4601 - val_accuracy: 0.8750 - val_loss: 0.3584 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8378 - loss: 0.4000\n",
      "Epoch 13: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8384 - loss: 0.3988 - val_accuracy: 0.8417 - val_loss: 0.3465 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8301 - loss: 0.4196\n",
      "Epoch 14: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8303 - loss: 0.4199 - val_accuracy: 0.8667 - val_loss: 0.2919 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8571 - loss: 0.3717\n",
      "Epoch 15: val_accuracy improved from 0.88333 to 0.90000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.8575 - loss: 0.3711 - val_accuracy: 0.9000 - val_loss: 0.2660 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8879 - loss: 0.2697\n",
      "Epoch 16: val_accuracy improved from 0.90000 to 0.92500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.8859 - loss: 0.2726 - val_accuracy: 0.9250 - val_loss: 0.2586 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8805 - loss: 0.3101\n",
      "Epoch 17: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8782 - loss: 0.3152 - val_accuracy: 0.8833 - val_loss: 0.2919 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8424 - loss: 0.3604\n",
      "Epoch 18: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8449 - loss: 0.3609 - val_accuracy: 0.8833 - val_loss: 0.2944 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8534 - loss: 0.3956\n",
      "Epoch 19: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8545 - loss: 0.3922 - val_accuracy: 0.8833 - val_loss: 0.2700 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8982 - loss: 0.2685\n",
      "Epoch 20: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8976 - loss: 0.2706 - val_accuracy: 0.8917 - val_loss: 0.2758 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8645 - loss: 0.3228\n",
      "Epoch 21: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.8650 - loss: 0.3214 - val_accuracy: 0.9167 - val_loss: 0.2027 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.8871 - loss: 0.2795\n",
      "Epoch 22: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - accuracy: 0.8870 - loss: 0.2791 - val_accuracy: 0.9167 - val_loss: 0.2049 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8691 - loss: 0.3313\n",
      "Epoch 23: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.8669 - loss: 0.3334 - val_accuracy: 0.8417 - val_loss: 0.2928 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8521 - loss: 0.3560\n",
      "Epoch 24: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8531 - loss: 0.3547 - val_accuracy: 0.8750 - val_loss: 0.2587 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8656 - loss: 0.3319\n",
      "Epoch 25: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.8660 - loss: 0.3317 - val_accuracy: 0.8750 - val_loss: 0.2957 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8544 - loss: 0.3080\n",
      "Epoch 26: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.8557 - loss: 0.3073 - val_accuracy: 0.9083 - val_loss: 0.2182 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8756 - loss: 0.2828\n",
      "Epoch 27: val_accuracy improved from 0.92500 to 0.93333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 175ms/step - accuracy: 0.8754 - loss: 0.2832 - val_accuracy: 0.9333 - val_loss: 0.2253 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8778 - loss: 0.2960\n",
      "Epoch 28: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.8774 - loss: 0.2974 - val_accuracy: 0.9250 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8908 - loss: 0.2918\n",
      "Epoch 29: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.8919 - loss: 0.2905 - val_accuracy: 0.9083 - val_loss: 0.2156 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9052 - loss: 0.2404\n",
      "Epoch 30: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9053 - loss: 0.2407 - val_accuracy: 0.9250 - val_loss: 0.2011 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9185 - loss: 0.1987\n",
      "Epoch 31: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9176 - loss: 0.2014 - val_accuracy: 0.9250 - val_loss: 0.1904 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9105 - loss: 0.2351\n",
      "Epoch 32: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9099 - loss: 0.2355 - val_accuracy: 0.9167 - val_loss: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9146 - loss: 0.2119\n",
      "Epoch 33: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.9146 - loss: 0.2126 - val_accuracy: 0.9083 - val_loss: 0.2315 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9142 - loss: 0.2213\n",
      "Epoch 34: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9137 - loss: 0.2228 - val_accuracy: 0.9333 - val_loss: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9011 - loss: 0.2307\n",
      "Epoch 35: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.9012 - loss: 0.2307 - val_accuracy: 0.9167 - val_loss: 0.1785 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8982 - loss: 0.2505\n",
      "Epoch 36: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.8974 - loss: 0.2527 - val_accuracy: 0.9167 - val_loss: 0.2326 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8842 - loss: 0.2876\n",
      "Epoch 37: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.8839 - loss: 0.2880 - val_accuracy: 0.9333 - val_loss: 0.2289 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9149 - loss: 0.2263\n",
      "Epoch 38: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9145 - loss: 0.2264 - val_accuracy: 0.9167 - val_loss: 0.1923 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9318 - loss: 0.2201\n",
      "Epoch 39: val_accuracy improved from 0.93333 to 0.94167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - accuracy: 0.9310 - loss: 0.2215 - val_accuracy: 0.9417 - val_loss: 0.1634 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9092 - loss: 0.2240\n",
      "Epoch 40: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.9097 - loss: 0.2229 - val_accuracy: 0.9083 - val_loss: 0.2120 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9023 - loss: 0.2226\n",
      "Epoch 41: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9024 - loss: 0.2234 - val_accuracy: 0.9167 - val_loss: 0.2272 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8953 - loss: 0.2671\n",
      "Epoch 42: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8963 - loss: 0.2646 - val_accuracy: 0.9333 - val_loss: 0.1566 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9106 - loss: 0.2486 \n",
      "Epoch 43: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9101 - loss: 0.2492 - val_accuracy: 0.9417 - val_loss: 0.1656 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9013 - loss: 0.2511\n",
      "Epoch 44: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9015 - loss: 0.2503 - val_accuracy: 0.9250 - val_loss: 0.2517 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8898 - loss: 0.2872\n",
      "Epoch 45: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.8900 - loss: 0.2860 - val_accuracy: 0.9333 - val_loss: 0.1674 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.9175 - loss: 0.2081\n",
      "Epoch 46: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - accuracy: 0.9175 - loss: 0.2095 - val_accuracy: 0.9417 - val_loss: 0.1711 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9107 - loss: 0.2213\n",
      "Epoch 47: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - accuracy: 0.9110 - loss: 0.2211 - val_accuracy: 0.9167 - val_loss: 0.2188 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.9129 - loss: 0.2350\n",
      "Epoch 48: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.9129 - loss: 0.2353 - val_accuracy: 0.9333 - val_loss: 0.2132 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.9095 - loss: 0.2318\n",
      "Epoch 49: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - accuracy: 0.9094 - loss: 0.2315 - val_accuracy: 0.9417 - val_loss: 0.2083 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9297 - loss: 0.1852\n",
      "Epoch 50: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - accuracy: 0.9280 - loss: 0.1888 - val_accuracy: 0.9250 - val_loss: 0.2331 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9023 - loss: 0.2249\n",
      "Epoch 51: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - accuracy: 0.9024 - loss: 0.2244 - val_accuracy: 0.9333 - val_loss: 0.1885 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9165 - loss: 0.2170\n",
      "Epoch 52: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9166 - loss: 0.2166 - val_accuracy: 0.9333 - val_loss: 0.2207 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9188 - loss: 0.2353\n",
      "Epoch 53: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.9181 - loss: 0.2352 - val_accuracy: 0.9250 - val_loss: 0.1905 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.9162 - loss: 0.2316\n",
      "Epoch 54: val_accuracy improved from 0.94167 to 0.95000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 0.9165 - loss: 0.2305 - val_accuracy: 0.9500 - val_loss: 0.1405 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9294 - loss: 0.2177\n",
      "Epoch 55: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9290 - loss: 0.2181 - val_accuracy: 0.8833 - val_loss: 0.2830 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8675 - loss: 0.3299\n",
      "Epoch 56: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.8691 - loss: 0.3258 - val_accuracy: 0.9167 - val_loss: 0.1807 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9043 - loss: 0.2216\n",
      "Epoch 57: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.9046 - loss: 0.2214 - val_accuracy: 0.9417 - val_loss: 0.2134 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9083 - loss: 0.2490\n",
      "Epoch 58: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.9085 - loss: 0.2484 - val_accuracy: 0.9250 - val_loss: 0.2090 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.8871 - loss: 0.2421\n",
      "Epoch 59: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.8878 - loss: 0.2424 - val_accuracy: 0.9333 - val_loss: 0.1631 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.9202 - loss: 0.2168\n",
      "Epoch 60: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - accuracy: 0.9192 - loss: 0.2182 - val_accuracy: 0.9250 - val_loss: 0.2213 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9213 - loss: 0.2281\n",
      "Epoch 61: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9210 - loss: 0.2285 - val_accuracy: 0.9000 - val_loss: 0.2159 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8896 - loss: 0.2485\n",
      "Epoch 62: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8900 - loss: 0.2486 - val_accuracy: 0.9083 - val_loss: 0.2149 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9068 - loss: 0.2218\n",
      "Epoch 63: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.9064 - loss: 0.2230 - val_accuracy: 0.9500 - val_loss: 0.1609 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9269 - loss: 0.1774\n",
      "Epoch 64: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.9264 - loss: 0.1784 - val_accuracy: 0.9417 - val_loss: 0.1588 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9423 - loss: 0.1627\n",
      "Epoch 65: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9419 - loss: 0.1642 - val_accuracy: 0.8917 - val_loss: 0.2509 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9037 - loss: 0.2145\n",
      "Epoch 66: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9034 - loss: 0.2166 - val_accuracy: 0.9167 - val_loss: 0.2270 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9038 - loss: 0.2251\n",
      "Epoch 67: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9050 - loss: 0.2236 - val_accuracy: 0.9250 - val_loss: 0.2276 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9203 - loss: 0.2167\n",
      "Epoch 68: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9206 - loss: 0.2157 - val_accuracy: 0.9333 - val_loss: 0.1753 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9144 - loss: 0.2177\n",
      "Epoch 69: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9136 - loss: 0.2179 - val_accuracy: 0.9167 - val_loss: 0.2029 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9189 - loss: 0.2300\n",
      "Epoch 70: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.9191 - loss: 0.2286 - val_accuracy: 0.9083 - val_loss: 0.2497 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9192 - loss: 0.2228\n",
      "Epoch 71: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.9196 - loss: 0.2216 - val_accuracy: 0.9000 - val_loss: 0.2108 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9059 - loss: 0.2395\n",
      "Epoch 72: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.9060 - loss: 0.2394 - val_accuracy: 0.9167 - val_loss: 0.1954 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9070 - loss: 0.2652\n",
      "Epoch 73: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.9070 - loss: 0.2639 - val_accuracy: 0.9417 - val_loss: 0.1954 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9217 - loss: 0.2023\n",
      "Epoch 74: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9218 - loss: 0.2026 - val_accuracy: 0.9167 - val_loss: 0.2358 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9217 - loss: 0.1867\n",
      "Epoch 75: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9218 - loss: 0.1867 - val_accuracy: 0.9500 - val_loss: 0.1358 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9181 - loss: 0.1985\n",
      "Epoch 76: val_accuracy improved from 0.95000 to 0.95833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.9179 - loss: 0.1990 - val_accuracy: 0.9583 - val_loss: 0.1640 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9169 - loss: 0.1871\n",
      "Epoch 77: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9169 - loss: 0.1874 - val_accuracy: 0.9417 - val_loss: 0.1705 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9018 - loss: 0.2328\n",
      "Epoch 78: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.9013 - loss: 0.2333 - val_accuracy: 0.9167 - val_loss: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9120 - loss: 0.2297\n",
      "Epoch 79: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9126 - loss: 0.2280 - val_accuracy: 0.9417 - val_loss: 0.1730 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9045 - loss: 0.1859\n",
      "Epoch 80: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.9054 - loss: 0.1854 - val_accuracy: 0.9417 - val_loss: 0.1553 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9240 - loss: 0.1848\n",
      "Epoch 81: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9236 - loss: 0.1851 - val_accuracy: 0.9417 - val_loss: 0.1766 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9342 - loss: 0.1851\n",
      "Epoch 82: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.9344 - loss: 0.1845 - val_accuracy: 0.9167 - val_loss: 0.1849 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9287 - loss: 0.1791\n",
      "Epoch 83: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.9282 - loss: 0.1802 - val_accuracy: 0.9000 - val_loss: 0.2498 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9083 - loss: 0.2595\n",
      "Epoch 84: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9088 - loss: 0.2569 - val_accuracy: 0.9417 - val_loss: 0.1545 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9265 - loss: 0.1768\n",
      "Epoch 85: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9265 - loss: 0.1773 - val_accuracy: 0.9417 - val_loss: 0.1489 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9298 - loss: 0.1974\n",
      "Epoch 86: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9300 - loss: 0.1970 - val_accuracy: 0.9333 - val_loss: 0.1840 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9209 - loss: 0.1761\n",
      "Epoch 87: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9218 - loss: 0.1757 - val_accuracy: 0.8833 - val_loss: 0.2979 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9432 - loss: 0.1642\n",
      "Epoch 88: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9421 - loss: 0.1662 - val_accuracy: 0.9250 - val_loss: 0.2057 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9405 - loss: 0.1623\n",
      "Epoch 89: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9396 - loss: 0.1635 - val_accuracy: 0.9417 - val_loss: 0.1800 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9322 - loss: 0.1894\n",
      "Epoch 90: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9309 - loss: 0.1932 - val_accuracy: 0.9167 - val_loss: 0.2107 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9134 - loss: 0.2237\n",
      "Epoch 91: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9139 - loss: 0.2230 - val_accuracy: 0.9250 - val_loss: 0.1638 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9432 - loss: 0.1522\n",
      "Epoch 92: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9423 - loss: 0.1536 - val_accuracy: 0.9500 - val_loss: 0.1710 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9296 - loss: 0.1592\n",
      "Epoch 93: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9303 - loss: 0.1595 - val_accuracy: 0.9250 - val_loss: 0.1934 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9243 - loss: 0.1816\n",
      "Epoch 94: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9234 - loss: 0.1822 - val_accuracy: 0.9333 - val_loss: 0.1780 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9280 - loss: 0.1803\n",
      "Epoch 95: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9288 - loss: 0.1790 - val_accuracy: 0.9333 - val_loss: 0.2343 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9121 - loss: 0.2201\n",
      "Epoch 96: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9133 - loss: 0.2180 - val_accuracy: 0.9333 - val_loss: 0.1888 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9481 - loss: 0.1677\n",
      "Epoch 97: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9484 - loss: 0.1671 - val_accuracy: 0.9167 - val_loss: 0.2235 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9127 - loss: 0.1841\n",
      "Epoch 98: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9134 - loss: 0.1835 - val_accuracy: 0.9250 - val_loss: 0.1744 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9192 - loss: 0.1831\n",
      "Epoch 99: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9193 - loss: 0.1838 - val_accuracy: 0.9500 - val_loss: 0.2091 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8935 - loss: 0.2302\n",
      "Epoch 100: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8945 - loss: 0.2284 - val_accuracy: 0.9417 - val_loss: 0.1680 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9563 - loss: 0.1614\n",
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3442 - loss: 2.4612\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.3462 - loss: 2.4176 - val_accuracy: 0.7083 - val_loss: 0.7321 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6565 - loss: 0.6500\n",
      "Epoch 2: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6567 - loss: 0.6468 - val_accuracy: 0.6750 - val_loss: 0.5923 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6574 - loss: 0.5544\n",
      "Epoch 3: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6625 - loss: 0.5517 - val_accuracy: 0.5750 - val_loss: 0.6671 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6314 - loss: 0.5493\n",
      "Epoch 4: val_accuracy improved from 0.70833 to 0.74167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.6321 - loss: 0.5489 - val_accuracy: 0.7417 - val_loss: 0.5189 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7679 - loss: 0.4650\n",
      "Epoch 5: val_accuracy did not improve from 0.74167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7675 - loss: 0.4662 - val_accuracy: 0.7333 - val_loss: 0.4691 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7807 - loss: 0.4575\n",
      "Epoch 6: val_accuracy did not improve from 0.74167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.7801 - loss: 0.4590 - val_accuracy: 0.6167 - val_loss: 0.6458 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7307 - loss: 0.4899\n",
      "Epoch 7: val_accuracy did not improve from 0.74167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.7340 - loss: 0.4869 - val_accuracy: 0.7083 - val_loss: 0.5053 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8004 - loss: 0.4274\n",
      "Epoch 8: val_accuracy did not improve from 0.74167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8007 - loss: 0.4264 - val_accuracy: 0.7250 - val_loss: 0.5266 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8270 - loss: 0.3757\n",
      "Epoch 9: val_accuracy improved from 0.74167 to 0.84167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - accuracy: 0.8281 - loss: 0.3742 - val_accuracy: 0.8417 - val_loss: 0.3698 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8480 - loss: 0.3762\n",
      "Epoch 10: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.8474 - loss: 0.3770 - val_accuracy: 0.8333 - val_loss: 0.3739 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8654 - loss: 0.3391\n",
      "Epoch 11: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8664 - loss: 0.3369 - val_accuracy: 0.7667 - val_loss: 0.4932 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8429 - loss: 0.3976\n",
      "Epoch 12: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.8427 - loss: 0.3980 - val_accuracy: 0.7667 - val_loss: 0.4841 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8226 - loss: 0.4002\n",
      "Epoch 13: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.8243 - loss: 0.3986 - val_accuracy: 0.8167 - val_loss: 0.4224 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8389 - loss: 0.3502\n",
      "Epoch 14: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.8397 - loss: 0.3494 - val_accuracy: 0.8083 - val_loss: 0.4424 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.8503 - loss: 0.3252\n",
      "Epoch 15: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.8507 - loss: 0.3251 - val_accuracy: 0.8250 - val_loss: 0.4291 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8472 - loss: 0.3498\n",
      "Epoch 16: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.8483 - loss: 0.3488 - val_accuracy: 0.8083 - val_loss: 0.4124 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8836 - loss: 0.3036\n",
      "Epoch 17: val_accuracy improved from 0.84167 to 0.86667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - accuracy: 0.8824 - loss: 0.3063 - val_accuracy: 0.8667 - val_loss: 0.3423 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8731 - loss: 0.3412\n",
      "Epoch 18: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8730 - loss: 0.3402 - val_accuracy: 0.8667 - val_loss: 0.3257 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8373 - loss: 0.3617\n",
      "Epoch 19: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.8383 - loss: 0.3595 - val_accuracy: 0.8083 - val_loss: 0.4538 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8817 - loss: 0.2904\n",
      "Epoch 20: val_accuracy improved from 0.86667 to 0.88333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - accuracy: 0.8816 - loss: 0.2908 - val_accuracy: 0.8833 - val_loss: 0.2849 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8751 - loss: 0.2681\n",
      "Epoch 21: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8754 - loss: 0.2690 - val_accuracy: 0.8417 - val_loss: 0.3345 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8768 - loss: 0.2758\n",
      "Epoch 22: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.8767 - loss: 0.2752 - val_accuracy: 0.8583 - val_loss: 0.3065 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8932 - loss: 0.2773\n",
      "Epoch 23: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8925 - loss: 0.2788 - val_accuracy: 0.8667 - val_loss: 0.3056 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8710 - loss: 0.2816\n",
      "Epoch 24: val_accuracy improved from 0.88333 to 0.91667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.8717 - loss: 0.2816 - val_accuracy: 0.9167 - val_loss: 0.2709 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8737 - loss: 0.2874\n",
      "Epoch 25: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8739 - loss: 0.2876 - val_accuracy: 0.9083 - val_loss: 0.2705 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8680 - loss: 0.3131\n",
      "Epoch 26: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.8689 - loss: 0.3111 - val_accuracy: 0.8583 - val_loss: 0.3195 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8969 - loss: 0.2680\n",
      "Epoch 27: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.8958 - loss: 0.2694 - val_accuracy: 0.9167 - val_loss: 0.2519 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8767 - loss: 0.2846\n",
      "Epoch 28: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.8773 - loss: 0.2830 - val_accuracy: 0.9000 - val_loss: 0.2783 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9154 - loss: 0.2219\n",
      "Epoch 29: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9144 - loss: 0.2238 - val_accuracy: 0.9167 - val_loss: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9046 - loss: 0.2483\n",
      "Epoch 30: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9038 - loss: 0.2484 - val_accuracy: 0.8917 - val_loss: 0.2658 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.8853 - loss: 0.2641\n",
      "Epoch 31: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8851 - loss: 0.2645 - val_accuracy: 0.8917 - val_loss: 0.3307 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8658 - loss: 0.2568\n",
      "Epoch 32: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.8669 - loss: 0.2569 - val_accuracy: 0.9000 - val_loss: 0.2509 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8760 - loss: 0.2765\n",
      "Epoch 33: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.8758 - loss: 0.2763 - val_accuracy: 0.8750 - val_loss: 0.2934 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8648 - loss: 0.3195\n",
      "Epoch 34: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.8653 - loss: 0.3185 - val_accuracy: 0.8250 - val_loss: 0.3789 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8953 - loss: 0.2785\n",
      "Epoch 35: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.8952 - loss: 0.2788 - val_accuracy: 0.9167 - val_loss: 0.2216 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8963 - loss: 0.2324\n",
      "Epoch 36: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.8955 - loss: 0.2344 - val_accuracy: 0.8417 - val_loss: 0.3597 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8851 - loss: 0.2733\n",
      "Epoch 37: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.8846 - loss: 0.2740 - val_accuracy: 0.9083 - val_loss: 0.2196 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9004 - loss: 0.2471\n",
      "Epoch 38: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9006 - loss: 0.2474 - val_accuracy: 0.8917 - val_loss: 0.2984 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8963 - loss: 0.2826\n",
      "Epoch 39: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.8961 - loss: 0.2820 - val_accuracy: 0.9083 - val_loss: 0.2585 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9271 - loss: 0.2155\n",
      "Epoch 40: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9270 - loss: 0.2156 - val_accuracy: 0.9000 - val_loss: 0.2179 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8923 - loss: 0.2431\n",
      "Epoch 41: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8931 - loss: 0.2420 - val_accuracy: 0.9000 - val_loss: 0.2839 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8801 - loss: 0.2692 \n",
      "Epoch 42: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.8814 - loss: 0.2675 - val_accuracy: 0.9000 - val_loss: 0.2403 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8960 - loss: 0.2334\n",
      "Epoch 43: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8962 - loss: 0.2336 - val_accuracy: 0.8917 - val_loss: 0.2492 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8935 - loss: 0.2521\n",
      "Epoch 44: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.8940 - loss: 0.2507 - val_accuracy: 0.9083 - val_loss: 0.2091 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9042 - loss: 0.2014\n",
      "Epoch 45: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9045 - loss: 0.2008 - val_accuracy: 0.9167 - val_loss: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9033 - loss: 0.2269\n",
      "Epoch 46: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.9040 - loss: 0.2258 - val_accuracy: 0.8667 - val_loss: 0.2524 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9184 - loss: 0.2141\n",
      "Epoch 47: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9182 - loss: 0.2142 - val_accuracy: 0.8333 - val_loss: 0.3933 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8916 - loss: 0.2480\n",
      "Epoch 48: val_accuracy improved from 0.91667 to 0.92500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - accuracy: 0.8913 - loss: 0.2480 - val_accuracy: 0.9250 - val_loss: 0.1909 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8842 - loss: 0.2779\n",
      "Epoch 49: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8858 - loss: 0.2744 - val_accuracy: 0.8667 - val_loss: 0.2863 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9312 - loss: 0.2033\n",
      "Epoch 50: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9300 - loss: 0.2056 - val_accuracy: 0.9083 - val_loss: 0.2547 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8789 - loss: 0.2525\n",
      "Epoch 51: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.8813 - loss: 0.2510 - val_accuracy: 0.9083 - val_loss: 0.2418 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9139 - loss: 0.2097\n",
      "Epoch 52: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9134 - loss: 0.2106 - val_accuracy: 0.9000 - val_loss: 0.2234 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8947 - loss: 0.2345\n",
      "Epoch 53: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.8958 - loss: 0.2335 - val_accuracy: 0.8917 - val_loss: 0.2730 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9279 - loss: 0.1806\n",
      "Epoch 54: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.9273 - loss: 0.1816 - val_accuracy: 0.8667 - val_loss: 0.3646 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9128 - loss: 0.2058\n",
      "Epoch 55: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9126 - loss: 0.2060 - val_accuracy: 0.9083 - val_loss: 0.2351 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9187 - loss: 0.1858\n",
      "Epoch 56: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.9188 - loss: 0.1861 - val_accuracy: 0.8750 - val_loss: 0.2914 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9209 - loss: 0.1879\n",
      "Epoch 57: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.9206 - loss: 0.1881 - val_accuracy: 0.9083 - val_loss: 0.2235 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9203 - loss: 0.2024\n",
      "Epoch 58: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9205 - loss: 0.2018 - val_accuracy: 0.8500 - val_loss: 0.3265 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8889 - loss: 0.2340\n",
      "Epoch 59: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8887 - loss: 0.2342 - val_accuracy: 0.9000 - val_loss: 0.2568 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9458 - loss: 0.1685\n",
      "Epoch 60: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.9451 - loss: 0.1696 - val_accuracy: 0.8917 - val_loss: 0.2394 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9085 - loss: 0.2289\n",
      "Epoch 61: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9083 - loss: 0.2280 - val_accuracy: 0.8417 - val_loss: 0.3469 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9055 - loss: 0.2370\n",
      "Epoch 62: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9058 - loss: 0.2363 - val_accuracy: 0.9000 - val_loss: 0.2355 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9023 - loss: 0.2318\n",
      "Epoch 63: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.9029 - loss: 0.2314 - val_accuracy: 0.9250 - val_loss: 0.1741 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9266 - loss: 0.1933\n",
      "Epoch 64: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9264 - loss: 0.1939 - val_accuracy: 0.9000 - val_loss: 0.2685 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9231 - loss: 0.1971\n",
      "Epoch 65: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.9216 - loss: 0.1996 - val_accuracy: 0.8917 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9314 - loss: 0.1818\n",
      "Epoch 66: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9318 - loss: 0.1822 - val_accuracy: 0.8917 - val_loss: 0.2134 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9072 - loss: 0.2247\n",
      "Epoch 67: val_accuracy improved from 0.92500 to 0.93333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - accuracy: 0.9083 - loss: 0.2232 - val_accuracy: 0.9333 - val_loss: 0.2189 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9259 - loss: 0.1896\n",
      "Epoch 68: val_accuracy improved from 0.93333 to 0.94167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.9256 - loss: 0.1908 - val_accuracy: 0.9417 - val_loss: 0.1920 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9190 - loss: 0.1890\n",
      "Epoch 69: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9182 - loss: 0.1909 - val_accuracy: 0.9000 - val_loss: 0.2112 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9011 - loss: 0.2288\n",
      "Epoch 70: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9014 - loss: 0.2281 - val_accuracy: 0.8167 - val_loss: 0.4713 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9046 - loss: 0.2523\n",
      "Epoch 71: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.9053 - loss: 0.2499 - val_accuracy: 0.8250 - val_loss: 0.3739 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8950 - loss: 0.2403\n",
      "Epoch 72: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8952 - loss: 0.2405 - val_accuracy: 0.8333 - val_loss: 0.4078 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8876 - loss: 0.2655\n",
      "Epoch 73: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.8890 - loss: 0.2631 - val_accuracy: 0.8917 - val_loss: 0.2927 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8897 - loss: 0.2124\n",
      "Epoch 74: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.8910 - loss: 0.2121 - val_accuracy: 0.9083 - val_loss: 0.1988 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9232 - loss: 0.1859\n",
      "Epoch 75: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9228 - loss: 0.1865 - val_accuracy: 0.8917 - val_loss: 0.2768 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9218 - loss: 0.1947\n",
      "Epoch 76: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9219 - loss: 0.1944 - val_accuracy: 0.8917 - val_loss: 0.2750 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9229 - loss: 0.1865\n",
      "Epoch 77: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9242 - loss: 0.1849 - val_accuracy: 0.9000 - val_loss: 0.2595 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9223 - loss: 0.1864\n",
      "Epoch 78: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9226 - loss: 0.1860 - val_accuracy: 0.9167 - val_loss: 0.1590 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9376 - loss: 0.1629\n",
      "Epoch 79: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9372 - loss: 0.1644 - val_accuracy: 0.9083 - val_loss: 0.2296 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9554 - loss: 0.1547\n",
      "Epoch 80: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9551 - loss: 0.1546 - val_accuracy: 0.8833 - val_loss: 0.2217 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9243 - loss: 0.1989\n",
      "Epoch 81: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9245 - loss: 0.1984 - val_accuracy: 0.9083 - val_loss: 0.2072 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9396 - loss: 0.1686\n",
      "Epoch 82: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9390 - loss: 0.1699 - val_accuracy: 0.9083 - val_loss: 0.2423 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9410 - loss: 0.2094\n",
      "Epoch 83: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9402 - loss: 0.2100 - val_accuracy: 0.9083 - val_loss: 0.2607 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9203 - loss: 0.1963\n",
      "Epoch 84: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9205 - loss: 0.1967 - val_accuracy: 0.8750 - val_loss: 0.2326 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8774 - loss: 0.2407\n",
      "Epoch 85: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8782 - loss: 0.2400 - val_accuracy: 0.8917 - val_loss: 0.2166 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8951 - loss: 0.2501\n",
      "Epoch 86: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.8956 - loss: 0.2492 - val_accuracy: 0.9083 - val_loss: 0.2039 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9052 - loss: 0.2080\n",
      "Epoch 87: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9056 - loss: 0.2066 - val_accuracy: 0.8750 - val_loss: 0.2757 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9523 - loss: 0.1357\n",
      "Epoch 88: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9515 - loss: 0.1373 - val_accuracy: 0.9083 - val_loss: 0.2764 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9048 - loss: 0.2066\n",
      "Epoch 89: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9050 - loss: 0.2064 - val_accuracy: 0.9000 - val_loss: 0.2468 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9339 - loss: 0.1636\n",
      "Epoch 90: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9330 - loss: 0.1650 - val_accuracy: 0.9167 - val_loss: 0.2393 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9395 - loss: 0.1707\n",
      "Epoch 91: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9396 - loss: 0.1703 - val_accuracy: 0.9167 - val_loss: 0.2382 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9182 - loss: 0.1988\n",
      "Epoch 92: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9183 - loss: 0.1983 - val_accuracy: 0.9000 - val_loss: 0.2049 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9394 - loss: 0.1551\n",
      "Epoch 93: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9395 - loss: 0.1556 - val_accuracy: 0.9250 - val_loss: 0.2045 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9205 - loss: 0.1769\n",
      "Epoch 94: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9211 - loss: 0.1758 - val_accuracy: 0.9167 - val_loss: 0.1757 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9299 - loss: 0.1755\n",
      "Epoch 95: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9302 - loss: 0.1748 - val_accuracy: 0.9250 - val_loss: 0.2243 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9485 - loss: 0.1645\n",
      "Epoch 96: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.9473 - loss: 0.1665 - val_accuracy: 0.8917 - val_loss: 0.2746 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9244 - loss: 0.1576\n",
      "Epoch 97: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9234 - loss: 0.1596 - val_accuracy: 0.8333 - val_loss: 0.3841 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9347 - loss: 0.1883\n",
      "Epoch 98: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9348 - loss: 0.1877 - val_accuracy: 0.8917 - val_loss: 0.2554 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9185 - loss: 0.1912\n",
      "Epoch 99: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.9191 - loss: 0.1911 - val_accuracy: 0.9083 - val_loss: 0.3035 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9154 - loss: 0.1924\n",
      "Epoch 100: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9158 - loss: 0.1920 - val_accuracy: 0.8833 - val_loss: 0.2976 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8829 - loss: 0.2925\n",
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.3035 - loss: 3.1648\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step - accuracy: 0.3091 - loss: 3.0935 - val_accuracy: 0.5750 - val_loss: 0.8740 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6479 - loss: 0.6382\n",
      "Epoch 2: val_accuracy improved from 0.57500 to 0.71667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - accuracy: 0.6483 - loss: 0.6347 - val_accuracy: 0.7167 - val_loss: 0.5299 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7241 - loss: 0.5213\n",
      "Epoch 3: val_accuracy did not improve from 0.71667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7246 - loss: 0.5213 - val_accuracy: 0.6750 - val_loss: 0.6699 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7281 - loss: 0.5024\n",
      "Epoch 4: val_accuracy improved from 0.71667 to 0.81667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - accuracy: 0.7247 - loss: 0.5042 - val_accuracy: 0.8167 - val_loss: 0.4636 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7539 - loss: 0.4674\n",
      "Epoch 5: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.7536 - loss: 0.4686 - val_accuracy: 0.7083 - val_loss: 0.4639 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7461 - loss: 0.5133\n",
      "Epoch 6: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7460 - loss: 0.5123 - val_accuracy: 0.7167 - val_loss: 0.4842 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7277 - loss: 0.4996\n",
      "Epoch 7: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7296 - loss: 0.4984 - val_accuracy: 0.8083 - val_loss: 0.3778 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7785 - loss: 0.4174\n",
      "Epoch 8: val_accuracy improved from 0.81667 to 0.85000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7796 - loss: 0.4173 - val_accuracy: 0.8500 - val_loss: 0.3712 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8314 - loss: 0.3737\n",
      "Epoch 9: val_accuracy improved from 0.85000 to 0.87500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.8317 - loss: 0.3724 - val_accuracy: 0.8750 - val_loss: 0.2805 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8616 - loss: 0.3422\n",
      "Epoch 10: val_accuracy improved from 0.87500 to 0.91667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8612 - loss: 0.3422 - val_accuracy: 0.9167 - val_loss: 0.2952 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8408 - loss: 0.3337\n",
      "Epoch 11: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8416 - loss: 0.3327 - val_accuracy: 0.8583 - val_loss: 0.2974 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8480 - loss: 0.3214\n",
      "Epoch 12: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 0.8489 - loss: 0.3211 - val_accuracy: 0.9000 - val_loss: 0.2388 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8805 - loss: 0.2749\n",
      "Epoch 13: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.8798 - loss: 0.2761 - val_accuracy: 0.9000 - val_loss: 0.2335 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8786 - loss: 0.2723\n",
      "Epoch 14: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8779 - loss: 0.2737 - val_accuracy: 0.9000 - val_loss: 0.2411 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8652 - loss: 0.2674\n",
      "Epoch 15: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.8647 - loss: 0.2701 - val_accuracy: 0.8417 - val_loss: 0.4294 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8809 - loss: 0.3098\n",
      "Epoch 16: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.8804 - loss: 0.3092 - val_accuracy: 0.8417 - val_loss: 0.3819 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8277 - loss: 0.3961\n",
      "Epoch 17: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.8286 - loss: 0.3944 - val_accuracy: 0.8500 - val_loss: 0.3967 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8828 - loss: 0.3142\n",
      "Epoch 18: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.8814 - loss: 0.3154 - val_accuracy: 0.8500 - val_loss: 0.3168 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8670 - loss: 0.2838\n",
      "Epoch 19: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.8674 - loss: 0.2837 - val_accuracy: 0.8583 - val_loss: 0.2723 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8582 - loss: 0.3049\n",
      "Epoch 20: val_accuracy improved from 0.91667 to 0.92500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - accuracy: 0.8595 - loss: 0.3025 - val_accuracy: 0.9250 - val_loss: 0.2502 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8809 - loss: 0.2866\n",
      "Epoch 21: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.8817 - loss: 0.2840 - val_accuracy: 0.8750 - val_loss: 0.3398 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8853 - loss: 0.2429\n",
      "Epoch 22: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.8855 - loss: 0.2432 - val_accuracy: 0.8833 - val_loss: 0.2907 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9055 - loss: 0.2414\n",
      "Epoch 23: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9048 - loss: 0.2433 - val_accuracy: 0.8833 - val_loss: 0.3028 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8294 - loss: 0.4148\n",
      "Epoch 24: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.8301 - loss: 0.4127 - val_accuracy: 0.7750 - val_loss: 0.4694 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8553 - loss: 0.3363\n",
      "Epoch 25: val_accuracy improved from 0.92500 to 0.93333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - accuracy: 0.8558 - loss: 0.3346 - val_accuracy: 0.9333 - val_loss: 0.2068 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8955 - loss: 0.2280\n",
      "Epoch 26: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.8950 - loss: 0.2292 - val_accuracy: 0.9167 - val_loss: 0.2255 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9173 - loss: 0.2217\n",
      "Epoch 27: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9167 - loss: 0.2227 - val_accuracy: 0.9000 - val_loss: 0.2574 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8688 - loss: 0.2570\n",
      "Epoch 28: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.8699 - loss: 0.2567 - val_accuracy: 0.9250 - val_loss: 0.2184 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8902 - loss: 0.2763\n",
      "Epoch 29: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.8909 - loss: 0.2749 - val_accuracy: 0.9167 - val_loss: 0.2230 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8925 - loss: 0.2439\n",
      "Epoch 30: val_accuracy improved from 0.93333 to 0.94167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - accuracy: 0.8932 - loss: 0.2425 - val_accuracy: 0.9417 - val_loss: 0.1812 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8954 - loss: 0.2399\n",
      "Epoch 31: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8952 - loss: 0.2388 - val_accuracy: 0.8583 - val_loss: 0.3210 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8913 - loss: 0.2049\n",
      "Epoch 32: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8917 - loss: 0.2058 - val_accuracy: 0.9417 - val_loss: 0.1594 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8998 - loss: 0.2569\n",
      "Epoch 33: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.9000 - loss: 0.2565 - val_accuracy: 0.9250 - val_loss: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9115 - loss: 0.2327\n",
      "Epoch 34: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.9119 - loss: 0.2319 - val_accuracy: 0.9000 - val_loss: 0.2536 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9210 - loss: 0.2086\n",
      "Epoch 35: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9200 - loss: 0.2097 - val_accuracy: 0.9000 - val_loss: 0.2443 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8742 - loss: 0.2739\n",
      "Epoch 36: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8749 - loss: 0.2733 - val_accuracy: 0.9083 - val_loss: 0.2080 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8942 - loss: 0.2550\n",
      "Epoch 37: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8939 - loss: 0.2542 - val_accuracy: 0.9167 - val_loss: 0.2207 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8680 - loss: 0.3006\n",
      "Epoch 38: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8688 - loss: 0.2987 - val_accuracy: 0.9333 - val_loss: 0.2007 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8936 - loss: 0.2503\n",
      "Epoch 39: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8939 - loss: 0.2506 - val_accuracy: 0.9333 - val_loss: 0.2033 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8897 - loss: 0.2299\n",
      "Epoch 40: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8892 - loss: 0.2337 - val_accuracy: 0.9167 - val_loss: 0.2131 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8871 - loss: 0.2153\n",
      "Epoch 41: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8870 - loss: 0.2164 - val_accuracy: 0.9333 - val_loss: 0.1961 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9037 - loss: 0.2117\n",
      "Epoch 42: val_accuracy improved from 0.94167 to 0.95000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9033 - loss: 0.2131 - val_accuracy: 0.9500 - val_loss: 0.1881 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9188 - loss: 0.2217\n",
      "Epoch 43: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9162 - loss: 0.2277 - val_accuracy: 0.9417 - val_loss: 0.1940 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8768 - loss: 0.2523\n",
      "Epoch 44: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8778 - loss: 0.2512 - val_accuracy: 0.9083 - val_loss: 0.2189 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8976 - loss: 0.2386\n",
      "Epoch 45: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8987 - loss: 0.2368 - val_accuracy: 0.9167 - val_loss: 0.1885 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9037 - loss: 0.2072\n",
      "Epoch 46: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9035 - loss: 0.2102 - val_accuracy: 0.8500 - val_loss: 0.3380 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8993 - loss: 0.2481\n",
      "Epoch 47: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9001 - loss: 0.2479 - val_accuracy: 0.9250 - val_loss: 0.2527 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8627 - loss: 0.2599\n",
      "Epoch 48: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8644 - loss: 0.2593 - val_accuracy: 0.9500 - val_loss: 0.1916 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9231 - loss: 0.2201\n",
      "Epoch 49: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9227 - loss: 0.2202 - val_accuracy: 0.9250 - val_loss: 0.1931 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9169 - loss: 0.2086\n",
      "Epoch 50: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9174 - loss: 0.2076 - val_accuracy: 0.9333 - val_loss: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9218 - loss: 0.1700\n",
      "Epoch 51: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9212 - loss: 0.1712 - val_accuracy: 0.9417 - val_loss: 0.1724 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8895 - loss: 0.2346\n",
      "Epoch 52: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8897 - loss: 0.2342 - val_accuracy: 0.8833 - val_loss: 0.2936 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9153 - loss: 0.2355\n",
      "Epoch 53: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9161 - loss: 0.2328 - val_accuracy: 0.9083 - val_loss: 0.3232 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9386 - loss: 0.1852\n",
      "Epoch 54: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9375 - loss: 0.1862 - val_accuracy: 0.9167 - val_loss: 0.2315 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9355 - loss: 0.1887\n",
      "Epoch 55: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9354 - loss: 0.1886 - val_accuracy: 0.9333 - val_loss: 0.1615 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9255 - loss: 0.1707\n",
      "Epoch 56: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9258 - loss: 0.1704 - val_accuracy: 0.9083 - val_loss: 0.2930 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8975 - loss: 0.2281 \n",
      "Epoch 57: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8983 - loss: 0.2262 - val_accuracy: 0.9333 - val_loss: 0.2225 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8797 - loss: 0.2198\n",
      "Epoch 58: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.8806 - loss: 0.2196 - val_accuracy: 0.9333 - val_loss: 0.1879 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8987 - loss: 0.2078\n",
      "Epoch 59: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8998 - loss: 0.2073 - val_accuracy: 0.8833 - val_loss: 0.3597 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9062 - loss: 0.2370\n",
      "Epoch 60: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.9071 - loss: 0.2345 - val_accuracy: 0.8750 - val_loss: 0.2998 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8879 - loss: 0.2035\n",
      "Epoch 61: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.8882 - loss: 0.2040 - val_accuracy: 0.9083 - val_loss: 0.2369 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9065 - loss: 0.2149\n",
      "Epoch 62: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.9065 - loss: 0.2151 - val_accuracy: 0.9333 - val_loss: 0.1858 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8865 - loss: 0.2298\n",
      "Epoch 63: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.8864 - loss: 0.2310 - val_accuracy: 0.9500 - val_loss: 0.1867 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9057 - loss: 0.2166\n",
      "Epoch 64: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.9060 - loss: 0.2169 - val_accuracy: 0.9167 - val_loss: 0.2461 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9064 - loss: 0.2238\n",
      "Epoch 65: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.9066 - loss: 0.2225 - val_accuracy: 0.9333 - val_loss: 0.2216 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9035 - loss: 0.2221\n",
      "Epoch 66: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9033 - loss: 0.2231 - val_accuracy: 0.9250 - val_loss: 0.1930 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9243 - loss: 0.1801\n",
      "Epoch 67: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9238 - loss: 0.1811 - val_accuracy: 0.9167 - val_loss: 0.2025 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9315 - loss: 0.1470\n",
      "Epoch 68: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9312 - loss: 0.1484 - val_accuracy: 0.9250 - val_loss: 0.2112 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9188 - loss: 0.1811\n",
      "Epoch 69: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9184 - loss: 0.1831 - val_accuracy: 0.9083 - val_loss: 0.2761 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9324 - loss: 0.1810\n",
      "Epoch 70: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.9322 - loss: 0.1814 - val_accuracy: 0.9500 - val_loss: 0.1966 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9066 - loss: 0.2030\n",
      "Epoch 71: val_accuracy improved from 0.95000 to 0.95833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - accuracy: 0.9073 - loss: 0.2014 - val_accuracy: 0.9583 - val_loss: 0.1715 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9252 - loss: 0.1888\n",
      "Epoch 72: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9248 - loss: 0.1892 - val_accuracy: 0.9500 - val_loss: 0.1620 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8851 - loss: 0.2241\n",
      "Epoch 73: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8860 - loss: 0.2239 - val_accuracy: 0.9083 - val_loss: 0.2662 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9343 - loss: 0.1878\n",
      "Epoch 74: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9343 - loss: 0.1869 - val_accuracy: 0.8833 - val_loss: 0.3267 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9121 - loss: 0.1768\n",
      "Epoch 75: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9129 - loss: 0.1775 - val_accuracy: 0.9083 - val_loss: 0.1958 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9311 - loss: 0.1609\n",
      "Epoch 76: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9302 - loss: 0.1625 - val_accuracy: 0.9500 - val_loss: 0.1616 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9366 - loss: 0.1420\n",
      "Epoch 77: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9362 - loss: 0.1419 - val_accuracy: 0.9583 - val_loss: 0.1657 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9401 - loss: 0.1391\n",
      "Epoch 78: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9385 - loss: 0.1423 - val_accuracy: 0.9417 - val_loss: 0.2234 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9253 - loss: 0.2158\n",
      "Epoch 79: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9255 - loss: 0.2145 - val_accuracy: 0.9417 - val_loss: 0.2019 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9401 - loss: 0.1733\n",
      "Epoch 80: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9395 - loss: 0.1730 - val_accuracy: 0.9333 - val_loss: 0.1611 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9320 - loss: 0.1630\n",
      "Epoch 81: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9319 - loss: 0.1615 - val_accuracy: 0.9500 - val_loss: 0.1809 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9103 - loss: 0.2300\n",
      "Epoch 82: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9114 - loss: 0.2272 - val_accuracy: 0.9500 - val_loss: 0.1710 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9167 - loss: 0.1941\n",
      "Epoch 83: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9167 - loss: 0.1930 - val_accuracy: 0.9333 - val_loss: 0.2026 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9361 - loss: 0.1780\n",
      "Epoch 84: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9356 - loss: 0.1777 - val_accuracy: 0.9083 - val_loss: 0.2084 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9180 - loss: 0.1849\n",
      "Epoch 85: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9199 - loss: 0.1829 - val_accuracy: 0.9333 - val_loss: 0.1705 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9393 - loss: 0.1420\n",
      "Epoch 86: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9398 - loss: 0.1416 - val_accuracy: 0.9500 - val_loss: 0.1681 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9324 - loss: 0.1485\n",
      "Epoch 87: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9327 - loss: 0.1485 - val_accuracy: 0.8833 - val_loss: 0.2323 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9420 - loss: 0.1530\n",
      "Epoch 88: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9418 - loss: 0.1542 - val_accuracy: 0.9083 - val_loss: 0.3010 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9240 - loss: 0.1916\n",
      "Epoch 89: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9230 - loss: 0.1932 - val_accuracy: 0.9500 - val_loss: 0.1759 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9114 - loss: 0.2435\n",
      "Epoch 90: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9118 - loss: 0.2418 - val_accuracy: 0.9167 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9270 - loss: 0.2280\n",
      "Epoch 91: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9270 - loss: 0.2261 - val_accuracy: 0.9333 - val_loss: 0.1629 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9407 - loss: 0.1425\n",
      "Epoch 92: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9396 - loss: 0.1445 - val_accuracy: 0.9167 - val_loss: 0.2480 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9133 - loss: 0.1765\n",
      "Epoch 93: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9144 - loss: 0.1751 - val_accuracy: 0.9000 - val_loss: 0.2248 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9434 - loss: 0.1371\n",
      "Epoch 94: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9426 - loss: 0.1375 - val_accuracy: 0.9000 - val_loss: 0.2789 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9321 - loss: 0.1638\n",
      "Epoch 95: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9326 - loss: 0.1633 - val_accuracy: 0.9083 - val_loss: 0.2050 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9457 - loss: 0.1291\n",
      "Epoch 96: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9449 - loss: 0.1301 - val_accuracy: 0.9083 - val_loss: 0.2245 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9385 - loss: 0.1553\n",
      "Epoch 97: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9388 - loss: 0.1540 - val_accuracy: 0.9333 - val_loss: 0.1917 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9318 - loss: 0.1904\n",
      "Epoch 98: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9308 - loss: 0.1923 - val_accuracy: 0.9333 - val_loss: 0.1671 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9254 - loss: 0.2124\n",
      "Epoch 99: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9259 - loss: 0.2102 - val_accuracy: 0.9250 - val_loss: 0.2083 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9322 - loss: 0.1514\n",
      "Epoch 100: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9318 - loss: 0.1537 - val_accuracy: 0.9250 - val_loss: 0.1836 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9508 - loss: 0.1921\n",
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3778 - loss: 4.5421\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.3798 - loss: 4.4303 - val_accuracy: 0.5500 - val_loss: 0.9938 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6732 - loss: 0.7187\n",
      "Epoch 2: val_accuracy improved from 0.55000 to 0.67500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.6724 - loss: 0.7135 - val_accuracy: 0.6750 - val_loss: 0.5858 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6501 - loss: 0.6459\n",
      "Epoch 3: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.6500 - loss: 0.6443 - val_accuracy: 0.6583 - val_loss: 0.5841 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.6569 - loss: 0.5094\n",
      "Epoch 4: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.6582 - loss: 0.5103 - val_accuracy: 0.6667 - val_loss: 0.5938 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7114 - loss: 0.5276\n",
      "Epoch 5: val_accuracy improved from 0.67500 to 0.69167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.7110 - loss: 0.5277 - val_accuracy: 0.6917 - val_loss: 0.5758 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7217 - loss: 0.4983\n",
      "Epoch 6: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 0.7218 - loss: 0.4989 - val_accuracy: 0.6417 - val_loss: 0.5768 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7806 - loss: 0.4685\n",
      "Epoch 7: val_accuracy improved from 0.69167 to 0.75000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 175ms/step - accuracy: 0.7817 - loss: 0.4664 - val_accuracy: 0.7500 - val_loss: 0.4509 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8439 - loss: 0.3896\n",
      "Epoch 8: val_accuracy improved from 0.75000 to 0.85000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - accuracy: 0.8423 - loss: 0.3914 - val_accuracy: 0.8500 - val_loss: 0.3860 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8678 - loss: 0.3617\n",
      "Epoch 9: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.8678 - loss: 0.3617 - val_accuracy: 0.8167 - val_loss: 0.4052 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8600 - loss: 0.3643\n",
      "Epoch 10: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8599 - loss: 0.3637 - val_accuracy: 0.8000 - val_loss: 0.4119 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8283 - loss: 0.3751\n",
      "Epoch 11: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.8294 - loss: 0.3728 - val_accuracy: 0.8417 - val_loss: 0.3695 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8585 - loss: 0.3487\n",
      "Epoch 12: val_accuracy improved from 0.85000 to 0.85833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - accuracy: 0.8586 - loss: 0.3479 - val_accuracy: 0.8583 - val_loss: 0.3476 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8429 - loss: 0.3470\n",
      "Epoch 13: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.8422 - loss: 0.3470 - val_accuracy: 0.6750 - val_loss: 0.6514 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8762 - loss: 0.3108\n",
      "Epoch 14: val_accuracy improved from 0.85833 to 0.87500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 183ms/step - accuracy: 0.8761 - loss: 0.3111 - val_accuracy: 0.8750 - val_loss: 0.3326 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9230 - loss: 0.2554\n",
      "Epoch 15: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.9220 - loss: 0.2557 - val_accuracy: 0.7667 - val_loss: 0.5382 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8331 - loss: 0.3781\n",
      "Epoch 16: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.8327 - loss: 0.3790 - val_accuracy: 0.8000 - val_loss: 0.4383 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8651 - loss: 0.3203\n",
      "Epoch 17: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.8661 - loss: 0.3188 - val_accuracy: 0.8083 - val_loss: 0.4252 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8714 - loss: 0.3023\n",
      "Epoch 18: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.8726 - loss: 0.3008 - val_accuracy: 0.8167 - val_loss: 0.4593 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8896 - loss: 0.2794\n",
      "Epoch 19: val_accuracy improved from 0.87500 to 0.88333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - accuracy: 0.8882 - loss: 0.2821 - val_accuracy: 0.8833 - val_loss: 0.3338 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8582 - loss: 0.3244\n",
      "Epoch 20: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8593 - loss: 0.3226 - val_accuracy: 0.8000 - val_loss: 0.4014 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8975 - loss: 0.2719\n",
      "Epoch 21: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.8977 - loss: 0.2711 - val_accuracy: 0.8333 - val_loss: 0.3515 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9144 - loss: 0.2381\n",
      "Epoch 22: val_accuracy improved from 0.88333 to 0.90000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - accuracy: 0.9139 - loss: 0.2390 - val_accuracy: 0.9000 - val_loss: 0.2750 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8750 - loss: 0.2819\n",
      "Epoch 23: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8758 - loss: 0.2809 - val_accuracy: 0.8167 - val_loss: 0.4637 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8861 - loss: 0.3072\n",
      "Epoch 24: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8863 - loss: 0.3060 - val_accuracy: 0.8333 - val_loss: 0.4325 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8760 - loss: 0.2764\n",
      "Epoch 25: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.8773 - loss: 0.2754 - val_accuracy: 0.8833 - val_loss: 0.2979 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9299 - loss: 0.1970\n",
      "Epoch 26: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9287 - loss: 0.1989 - val_accuracy: 0.8583 - val_loss: 0.2981 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9071 - loss: 0.2560\n",
      "Epoch 27: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.9076 - loss: 0.2544 - val_accuracy: 0.8000 - val_loss: 0.3282 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9079 - loss: 0.2380\n",
      "Epoch 28: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9072 - loss: 0.2403 - val_accuracy: 0.8167 - val_loss: 0.4106 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9004 - loss: 0.2670\n",
      "Epoch 29: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.9002 - loss: 0.2671 - val_accuracy: 0.8750 - val_loss: 0.3639 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.8988 - loss: 0.2693\n",
      "Epoch 30: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.8988 - loss: 0.2678 - val_accuracy: 0.8167 - val_loss: 0.4470 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8719 - loss: 0.3379\n",
      "Epoch 31: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.8722 - loss: 0.3364 - val_accuracy: 0.8667 - val_loss: 0.3180 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9010 - loss: 0.2876\n",
      "Epoch 32: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9008 - loss: 0.2874 - val_accuracy: 0.8333 - val_loss: 0.3733 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8704 - loss: 0.2895\n",
      "Epoch 33: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8719 - loss: 0.2870 - val_accuracy: 0.8250 - val_loss: 0.3171 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8823 - loss: 0.2859\n",
      "Epoch 34: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8826 - loss: 0.2843 - val_accuracy: 0.8500 - val_loss: 0.3303 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9048 - loss: 0.2278\n",
      "Epoch 35: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9041 - loss: 0.2286 - val_accuracy: 0.8333 - val_loss: 0.3214 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9067 - loss: 0.2132\n",
      "Epoch 36: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9066 - loss: 0.2147 - val_accuracy: 0.8917 - val_loss: 0.2324 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9195 - loss: 0.2136\n",
      "Epoch 37: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9191 - loss: 0.2139 - val_accuracy: 0.8500 - val_loss: 0.3419 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9325 - loss: 0.1900\n",
      "Epoch 38: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9318 - loss: 0.1923 - val_accuracy: 0.8167 - val_loss: 0.3838 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9015 - loss: 0.2310\n",
      "Epoch 39: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9029 - loss: 0.2293 - val_accuracy: 0.8083 - val_loss: 0.3648 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8997 - loss: 0.2320\n",
      "Epoch 40: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8998 - loss: 0.2311 - val_accuracy: 0.8583 - val_loss: 0.2799 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9350 - loss: 0.1913\n",
      "Epoch 41: val_accuracy improved from 0.90000 to 0.90833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.9337 - loss: 0.1929 - val_accuracy: 0.9083 - val_loss: 0.2610 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8932 - loss: 0.2555\n",
      "Epoch 42: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8929 - loss: 0.2551 - val_accuracy: 0.7917 - val_loss: 0.4762 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9071 - loss: 0.2119\n",
      "Epoch 43: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9071 - loss: 0.2117 - val_accuracy: 0.8667 - val_loss: 0.2820 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9030 - loss: 0.2302\n",
      "Epoch 44: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9030 - loss: 0.2307 - val_accuracy: 0.8333 - val_loss: 0.3250 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8887 - loss: 0.2328\n",
      "Epoch 45: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.8899 - loss: 0.2313 - val_accuracy: 0.8500 - val_loss: 0.3347 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9176 - loss: 0.2020\n",
      "Epoch 46: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9174 - loss: 0.2029 - val_accuracy: 0.8333 - val_loss: 0.3789 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9004 - loss: 0.2561\n",
      "Epoch 47: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8999 - loss: 0.2569 - val_accuracy: 0.8417 - val_loss: 0.3735 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9067 - loss: 0.2474\n",
      "Epoch 48: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9068 - loss: 0.2473 - val_accuracy: 0.8500 - val_loss: 0.2906 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9141 - loss: 0.1972\n",
      "Epoch 49: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9139 - loss: 0.1973 - val_accuracy: 0.7750 - val_loss: 0.5383 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8852 - loss: 0.2692\n",
      "Epoch 50: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8856 - loss: 0.2686 - val_accuracy: 0.7917 - val_loss: 0.4352 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8842 - loss: 0.2611\n",
      "Epoch 51: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.8850 - loss: 0.2601 - val_accuracy: 0.8417 - val_loss: 0.3665 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9325 - loss: 0.1904\n",
      "Epoch 52: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9312 - loss: 0.1915 - val_accuracy: 0.8667 - val_loss: 0.2718 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9147 - loss: 0.2283\n",
      "Epoch 53: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9151 - loss: 0.2270 - val_accuracy: 0.9083 - val_loss: 0.2669 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9078 - loss: 0.2236\n",
      "Epoch 54: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9085 - loss: 0.2227 - val_accuracy: 0.8583 - val_loss: 0.2906 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9268 - loss: 0.1885\n",
      "Epoch 55: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9265 - loss: 0.1899 - val_accuracy: 0.8583 - val_loss: 0.3371 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9093 - loss: 0.1845\n",
      "Epoch 56: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9090 - loss: 0.1847 - val_accuracy: 0.8583 - val_loss: 0.2884 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9153 - loss: 0.1839\n",
      "Epoch 57: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9160 - loss: 0.1839 - val_accuracy: 0.8417 - val_loss: 0.3235 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9258 - loss: 0.1854\n",
      "Epoch 58: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9260 - loss: 0.1853 - val_accuracy: 0.8417 - val_loss: 0.3629 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9148 - loss: 0.1892\n",
      "Epoch 59: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9145 - loss: 0.1902 - val_accuracy: 0.8667 - val_loss: 0.3143 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9115 - loss: 0.2235\n",
      "Epoch 60: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9121 - loss: 0.2224 - val_accuracy: 0.8583 - val_loss: 0.3273 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9247 - loss: 0.1825\n",
      "Epoch 61: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.9238 - loss: 0.1835 - val_accuracy: 0.8250 - val_loss: 0.3606 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9103 - loss: 0.2093\n",
      "Epoch 62: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.9106 - loss: 0.2096 - val_accuracy: 0.8417 - val_loss: 0.3876 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9154 - loss: 0.1882\n",
      "Epoch 63: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9156 - loss: 0.1887 - val_accuracy: 0.8833 - val_loss: 0.2706 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9473 - loss: 0.1463\n",
      "Epoch 64: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.9463 - loss: 0.1489 - val_accuracy: 0.8250 - val_loss: 0.3472 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9301 - loss: 0.1870\n",
      "Epoch 65: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9299 - loss: 0.1871 - val_accuracy: 0.8167 - val_loss: 0.3524 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9270 - loss: 0.1660\n",
      "Epoch 66: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9266 - loss: 0.1674 - val_accuracy: 0.8500 - val_loss: 0.3997 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9282 - loss: 0.1864 \n",
      "Epoch 67: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9281 - loss: 0.1867 - val_accuracy: 0.8917 - val_loss: 0.2935 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9317 - loss: 0.1989\n",
      "Epoch 68: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9317 - loss: 0.1983 - val_accuracy: 0.8667 - val_loss: 0.2836 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8950 - loss: 0.2290\n",
      "Epoch 69: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.8961 - loss: 0.2280 - val_accuracy: 0.8750 - val_loss: 0.2837 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9337 - loss: 0.1859\n",
      "Epoch 70: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9334 - loss: 0.1869 - val_accuracy: 0.8667 - val_loss: 0.3075 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9302 - loss: 0.1545\n",
      "Epoch 71: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.9305 - loss: 0.1548 - val_accuracy: 0.8333 - val_loss: 0.3888 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9115 - loss: 0.2195\n",
      "Epoch 72: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9122 - loss: 0.2167 - val_accuracy: 0.8583 - val_loss: 0.3157 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9237 - loss: 0.2144\n",
      "Epoch 73: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.9236 - loss: 0.2141 - val_accuracy: 0.8583 - val_loss: 0.3147 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9420 - loss: 0.1831\n",
      "Epoch 74: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.9420 - loss: 0.1826 - val_accuracy: 0.8500 - val_loss: 0.4560 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9094 - loss: 0.2407\n",
      "Epoch 75: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.9099 - loss: 0.2386 - val_accuracy: 0.8917 - val_loss: 0.2413 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9280 - loss: 0.1956\n",
      "Epoch 76: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.9279 - loss: 0.1958 - val_accuracy: 0.8500 - val_loss: 0.3034 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9365 - loss: 0.1521\n",
      "Epoch 77: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - accuracy: 0.9359 - loss: 0.1538 - val_accuracy: 0.8500 - val_loss: 0.3266 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9231 - loss: 0.1659\n",
      "Epoch 78: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9227 - loss: 0.1669 - val_accuracy: 0.8250 - val_loss: 0.4766 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8848 - loss: 0.2568\n",
      "Epoch 79: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8861 - loss: 0.2542 - val_accuracy: 0.7667 - val_loss: 0.5461 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9095 - loss: 0.2560\n",
      "Epoch 80: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9101 - loss: 0.2545 - val_accuracy: 0.8417 - val_loss: 0.3730 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9122 - loss: 0.2263\n",
      "Epoch 81: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.9129 - loss: 0.2247 - val_accuracy: 0.8167 - val_loss: 0.4047 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9300 - loss: 0.2067\n",
      "Epoch 82: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9309 - loss: 0.2045 - val_accuracy: 0.8667 - val_loss: 0.3102 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9337 - loss: 0.1838\n",
      "Epoch 83: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - accuracy: 0.9339 - loss: 0.1828 - val_accuracy: 0.8917 - val_loss: 0.2724 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9315 - loss: 0.1693\n",
      "Epoch 84: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9323 - loss: 0.1690 - val_accuracy: 0.8250 - val_loss: 0.3591 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9330 - loss: 0.1590\n",
      "Epoch 85: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - accuracy: 0.9324 - loss: 0.1606 - val_accuracy: 0.8750 - val_loss: 0.2940 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9492 - loss: 0.1540\n",
      "Epoch 86: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9488 - loss: 0.1541 - val_accuracy: 0.8500 - val_loss: 0.3936 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9096 - loss: 0.2223\n",
      "Epoch 87: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.9097 - loss: 0.2208 - val_accuracy: 0.8667 - val_loss: 0.2847 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9185 - loss: 0.2158\n",
      "Epoch 88: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.9194 - loss: 0.2143 - val_accuracy: 0.8417 - val_loss: 0.4565 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9332 - loss: 0.1567\n",
      "Epoch 89: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9342 - loss: 0.1550 - val_accuracy: 0.8333 - val_loss: 0.4130 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9343 - loss: 0.1816\n",
      "Epoch 90: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.9344 - loss: 0.1804 - val_accuracy: 0.8667 - val_loss: 0.3773 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9330 - loss: 0.1737\n",
      "Epoch 91: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9326 - loss: 0.1754 - val_accuracy: 0.8667 - val_loss: 0.2790 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9027 - loss: 0.1916\n",
      "Epoch 92: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9034 - loss: 0.1920 - val_accuracy: 0.8750 - val_loss: 0.2830 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9179 - loss: 0.1822\n",
      "Epoch 93: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.9182 - loss: 0.1821 - val_accuracy: 0.8500 - val_loss: 0.3576 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9412 - loss: 0.1358\n",
      "Epoch 94: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.9402 - loss: 0.1380 - val_accuracy: 0.8750 - val_loss: 0.2718 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9118 - loss: 0.2041\n",
      "Epoch 95: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9133 - loss: 0.2012 - val_accuracy: 0.9000 - val_loss: 0.2941 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9515 - loss: 0.1421\n",
      "Epoch 96: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.9510 - loss: 0.1426 - val_accuracy: 0.8417 - val_loss: 0.3562 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9453 - loss: 0.1235\n",
      "Epoch 97: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.9443 - loss: 0.1259 - val_accuracy: 0.8167 - val_loss: 0.3797 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9346 - loss: 0.1560\n",
      "Epoch 98: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9343 - loss: 0.1558 - val_accuracy: 0.8250 - val_loss: 0.4313 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9411 - loss: 0.1574\n",
      "Epoch 99: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.9410 - loss: 0.1573 - val_accuracy: 0.8417 - val_loss: 0.3617 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9603 - loss: 0.1137\n",
      "Epoch 100: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9598 - loss: 0.1150 - val_accuracy: 0.8417 - val_loss: 0.4531 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8442 - loss: 0.3618\n",
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3864 - loss: 4.1700\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.3901 - loss: 4.0709 - val_accuracy: 0.7583 - val_loss: 0.7246 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7108 - loss: 0.6043\n",
      "Epoch 2: val_accuracy did not improve from 0.75833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.7120 - loss: 0.6010 - val_accuracy: 0.7083 - val_loss: 0.4910 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7834 - loss: 0.4540\n",
      "Epoch 3: val_accuracy improved from 0.75833 to 0.77500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.7825 - loss: 0.4542 - val_accuracy: 0.7750 - val_loss: 0.4219 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8037 - loss: 0.4326\n",
      "Epoch 4: val_accuracy improved from 0.77500 to 0.84167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8043 - loss: 0.4323 - val_accuracy: 0.8417 - val_loss: 0.3548 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8638 - loss: 0.3247\n",
      "Epoch 5: val_accuracy improved from 0.84167 to 0.86667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8629 - loss: 0.3270 - val_accuracy: 0.8667 - val_loss: 0.3671 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8244 - loss: 0.4361\n",
      "Epoch 6: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.8251 - loss: 0.4334 - val_accuracy: 0.8583 - val_loss: 0.3427 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8965 - loss: 0.3274\n",
      "Epoch 7: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.8954 - loss: 0.3283 - val_accuracy: 0.8417 - val_loss: 0.3990 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8019 - loss: 0.4175\n",
      "Epoch 8: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8031 - loss: 0.4157 - val_accuracy: 0.8167 - val_loss: 0.3732 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8213 - loss: 0.3781\n",
      "Epoch 9: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.8205 - loss: 0.3800 - val_accuracy: 0.7500 - val_loss: 0.4854 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8488 - loss: 0.3573\n",
      "Epoch 10: val_accuracy improved from 0.86667 to 0.87500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.8492 - loss: 0.3581 - val_accuracy: 0.8750 - val_loss: 0.3268 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8565 - loss: 0.3141\n",
      "Epoch 11: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8569 - loss: 0.3141 - val_accuracy: 0.8750 - val_loss: 0.3440 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8961 - loss: 0.2715\n",
      "Epoch 12: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.8943 - loss: 0.2726 - val_accuracy: 0.8333 - val_loss: 0.3486 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8484 - loss: 0.3463\n",
      "Epoch 13: val_accuracy improved from 0.87500 to 0.90000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8494 - loss: 0.3443 - val_accuracy: 0.9000 - val_loss: 0.2920 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9023 - loss: 0.2499\n",
      "Epoch 14: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9016 - loss: 0.2516 - val_accuracy: 0.8750 - val_loss: 0.2989 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8823 - loss: 0.2816\n",
      "Epoch 15: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8816 - loss: 0.2835 - val_accuracy: 0.8583 - val_loss: 0.3113 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9103 - loss: 0.2429\n",
      "Epoch 16: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9086 - loss: 0.2467 - val_accuracy: 0.8083 - val_loss: 0.5494 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7957 - loss: 0.4369\n",
      "Epoch 17: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.7981 - loss: 0.4339 - val_accuracy: 0.8833 - val_loss: 0.3353 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8543 - loss: 0.3214\n",
      "Epoch 18: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.8559 - loss: 0.3195 - val_accuracy: 0.8750 - val_loss: 0.3216 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8674 - loss: 0.3238\n",
      "Epoch 19: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - accuracy: 0.8676 - loss: 0.3240 - val_accuracy: 0.8583 - val_loss: 0.3457 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8732 - loss: 0.2912\n",
      "Epoch 20: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.8738 - loss: 0.2903 - val_accuracy: 0.8583 - val_loss: 0.3469 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8745 - loss: 0.2758\n",
      "Epoch 21: val_accuracy improved from 0.90000 to 0.92500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - accuracy: 0.8744 - loss: 0.2779 - val_accuracy: 0.9250 - val_loss: 0.2525 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8742 - loss: 0.2950\n",
      "Epoch 22: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.8744 - loss: 0.2951 - val_accuracy: 0.8667 - val_loss: 0.3140 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8876 - loss: 0.2937\n",
      "Epoch 23: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.8875 - loss: 0.2930 - val_accuracy: 0.8917 - val_loss: 0.2671 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8871 - loss: 0.2656\n",
      "Epoch 24: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.8872 - loss: 0.2658 - val_accuracy: 0.8417 - val_loss: 0.3451 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8849 - loss: 0.2946\n",
      "Epoch 25: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.8852 - loss: 0.2927 - val_accuracy: 0.9167 - val_loss: 0.2470 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9041 - loss: 0.2386\n",
      "Epoch 26: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9045 - loss: 0.2381 - val_accuracy: 0.8917 - val_loss: 0.2808 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8874 - loss: 0.2426\n",
      "Epoch 27: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.8878 - loss: 0.2432 - val_accuracy: 0.8750 - val_loss: 0.2942 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.8869 - loss: 0.2555\n",
      "Epoch 28: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.8871 - loss: 0.2560 - val_accuracy: 0.8750 - val_loss: 0.2931 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.9068 - loss: 0.2301\n",
      "Epoch 29: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - accuracy: 0.9067 - loss: 0.2305 - val_accuracy: 0.8917 - val_loss: 0.3135 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9204 - loss: 0.2245\n",
      "Epoch 30: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9200 - loss: 0.2246 - val_accuracy: 0.8917 - val_loss: 0.2459 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9039 - loss: 0.2237\n",
      "Epoch 31: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.9038 - loss: 0.2244 - val_accuracy: 0.9250 - val_loss: 0.2572 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9077 - loss: 0.2453\n",
      "Epoch 32: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9079 - loss: 0.2449 - val_accuracy: 0.8667 - val_loss: 0.2725 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8935 - loss: 0.2599\n",
      "Epoch 33: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.8914 - loss: 0.2625 - val_accuracy: 0.9083 - val_loss: 0.2562 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8834 - loss: 0.2919\n",
      "Epoch 34: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.8833 - loss: 0.2911 - val_accuracy: 0.8917 - val_loss: 0.3089 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9101 - loss: 0.2528\n",
      "Epoch 35: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.9096 - loss: 0.2530 - val_accuracy: 0.8083 - val_loss: 0.4056 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.8738 - loss: 0.2830\n",
      "Epoch 36: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.8742 - loss: 0.2825 - val_accuracy: 0.8333 - val_loss: 0.4292 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8930 - loss: 0.2597\n",
      "Epoch 37: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8939 - loss: 0.2581 - val_accuracy: 0.8667 - val_loss: 0.2666 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8989 - loss: 0.2516\n",
      "Epoch 38: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.8995 - loss: 0.2499 - val_accuracy: 0.9167 - val_loss: 0.2342 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9005 - loss: 0.2568\n",
      "Epoch 39: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9020 - loss: 0.2536 - val_accuracy: 0.8917 - val_loss: 0.2561 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8964 - loss: 0.2296\n",
      "Epoch 40: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.8966 - loss: 0.2303 - val_accuracy: 0.8917 - val_loss: 0.2486 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9443 - loss: 0.1645\n",
      "Epoch 41: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9414 - loss: 0.1699 - val_accuracy: 0.8833 - val_loss: 0.2685 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9063 - loss: 0.2251\n",
      "Epoch 42: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9048 - loss: 0.2279 - val_accuracy: 0.8833 - val_loss: 0.3473 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8877 - loss: 0.2876\n",
      "Epoch 43: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8890 - loss: 0.2849 - val_accuracy: 0.8667 - val_loss: 0.3393 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9118 - loss: 0.2294\n",
      "Epoch 44: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9117 - loss: 0.2286 - val_accuracy: 0.9083 - val_loss: 0.2156 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9290 - loss: 0.1973\n",
      "Epoch 45: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9287 - loss: 0.1982 - val_accuracy: 0.9000 - val_loss: 0.2270 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9214 - loss: 0.2187\n",
      "Epoch 46: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9215 - loss: 0.2188 - val_accuracy: 0.8833 - val_loss: 0.2641 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9142 - loss: 0.2153\n",
      "Epoch 47: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9134 - loss: 0.2164 - val_accuracy: 0.9167 - val_loss: 0.2182 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9076 - loss: 0.2473\n",
      "Epoch 48: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9085 - loss: 0.2456 - val_accuracy: 0.9250 - val_loss: 0.2267 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9168 - loss: 0.2021\n",
      "Epoch 49: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9160 - loss: 0.2040 - val_accuracy: 0.9083 - val_loss: 0.2380 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9304 - loss: 0.2005\n",
      "Epoch 50: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9305 - loss: 0.2009 - val_accuracy: 0.9083 - val_loss: 0.2436 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9229 - loss: 0.1897\n",
      "Epoch 51: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9234 - loss: 0.1896 - val_accuracy: 0.9083 - val_loss: 0.2104 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9112 - loss: 0.2225\n",
      "Epoch 52: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.9108 - loss: 0.2227 - val_accuracy: 0.8667 - val_loss: 0.2400 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9142 - loss: 0.1884\n",
      "Epoch 53: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9138 - loss: 0.1907 - val_accuracy: 0.8750 - val_loss: 0.3185 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9324 - loss: 0.1820\n",
      "Epoch 54: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9317 - loss: 0.1836 - val_accuracy: 0.8833 - val_loss: 0.2774 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9192 - loss: 0.1912\n",
      "Epoch 55: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.9191 - loss: 0.1917 - val_accuracy: 0.9000 - val_loss: 0.2310 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9265 - loss: 0.1922\n",
      "Epoch 56: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - accuracy: 0.9260 - loss: 0.1934 - val_accuracy: 0.8583 - val_loss: 0.2440 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9136 - loss: 0.2206\n",
      "Epoch 57: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9140 - loss: 0.2196 - val_accuracy: 0.9000 - val_loss: 0.1973 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9250 - loss: 0.2044\n",
      "Epoch 58: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9245 - loss: 0.2050 - val_accuracy: 0.8750 - val_loss: 0.3104 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9319 - loss: 0.1507\n",
      "Epoch 59: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.9317 - loss: 0.1527 - val_accuracy: 0.8667 - val_loss: 0.2829 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9293 - loss: 0.1858\n",
      "Epoch 60: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9289 - loss: 0.1866 - val_accuracy: 0.9250 - val_loss: 0.2602 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8971 - loss: 0.2716\n",
      "Epoch 61: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.8973 - loss: 0.2700 - val_accuracy: 0.8917 - val_loss: 0.2439 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9226 - loss: 0.1950\n",
      "Epoch 62: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.9228 - loss: 0.1946 - val_accuracy: 0.8917 - val_loss: 0.2513 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9324 - loss: 0.1671\n",
      "Epoch 63: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.9316 - loss: 0.1685 - val_accuracy: 0.9250 - val_loss: 0.1983 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9259 - loss: 0.1789\n",
      "Epoch 64: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.9260 - loss: 0.1787 - val_accuracy: 0.9167 - val_loss: 0.2315 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9206 - loss: 0.2056\n",
      "Epoch 65: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.9219 - loss: 0.2034 - val_accuracy: 0.9000 - val_loss: 0.2715 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9227 - loss: 0.1978\n",
      "Epoch 66: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9227 - loss: 0.1973 - val_accuracy: 0.9083 - val_loss: 0.2178 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9138 - loss: 0.2288\n",
      "Epoch 67: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.9150 - loss: 0.2260 - val_accuracy: 0.8833 - val_loss: 0.2415 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9449 - loss: 0.1526\n",
      "Epoch 68: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.9442 - loss: 0.1542 - val_accuracy: 0.8417 - val_loss: 0.3499 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9377 - loss: 0.1732\n",
      "Epoch 69: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9370 - loss: 0.1748 - val_accuracy: 0.8750 - val_loss: 0.2722 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9102 - loss: 0.1915\n",
      "Epoch 70: val_accuracy improved from 0.92500 to 0.93333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9105 - loss: 0.1904 - val_accuracy: 0.9333 - val_loss: 0.1788 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9250 - loss: 0.1708\n",
      "Epoch 71: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9250 - loss: 0.1709 - val_accuracy: 0.9083 - val_loss: 0.2070 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9272 - loss: 0.1726\n",
      "Epoch 72: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.9268 - loss: 0.1736 - val_accuracy: 0.9333 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9392 - loss: 0.1460\n",
      "Epoch 73: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9392 - loss: 0.1463 - val_accuracy: 0.8750 - val_loss: 0.2567 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9239 - loss: 0.2171\n",
      "Epoch 74: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.9236 - loss: 0.2167 - val_accuracy: 0.9083 - val_loss: 0.2203 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9252 - loss: 0.1808\n",
      "Epoch 75: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9246 - loss: 0.1820 - val_accuracy: 0.8500 - val_loss: 0.2653 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9152 - loss: 0.1871\n",
      "Epoch 76: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.9156 - loss: 0.1869 - val_accuracy: 0.9250 - val_loss: 0.2057 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9156 - loss: 0.1894\n",
      "Epoch 77: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9160 - loss: 0.1895 - val_accuracy: 0.9083 - val_loss: 0.2378 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9090 - loss: 0.2010\n",
      "Epoch 78: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.9097 - loss: 0.2009 - val_accuracy: 0.9083 - val_loss: 0.2124 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9027 - loss: 0.2497\n",
      "Epoch 79: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.9035 - loss: 0.2479 - val_accuracy: 0.9167 - val_loss: 0.2016 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9232 - loss: 0.1505\n",
      "Epoch 80: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.9224 - loss: 0.1527 - val_accuracy: 0.8833 - val_loss: 0.3200 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9059 - loss: 0.2178\n",
      "Epoch 81: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9057 - loss: 0.2194 - val_accuracy: 0.8833 - val_loss: 0.2677 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9162 - loss: 0.1915\n",
      "Epoch 82: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9169 - loss: 0.1906 - val_accuracy: 0.9333 - val_loss: 0.1946 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8919 - loss: 0.2563\n",
      "Epoch 83: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.8924 - loss: 0.2559 - val_accuracy: 0.8917 - val_loss: 0.2356 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9297 - loss: 0.1747\n",
      "Epoch 84: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9291 - loss: 0.1753 - val_accuracy: 0.9000 - val_loss: 0.2265 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9270 - loss: 0.1868\n",
      "Epoch 85: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9267 - loss: 0.1860 - val_accuracy: 0.8917 - val_loss: 0.2293 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9444 - loss: 0.1397\n",
      "Epoch 86: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.9445 - loss: 0.1402 - val_accuracy: 0.8917 - val_loss: 0.2769 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9343 - loss: 0.1627\n",
      "Epoch 87: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.9341 - loss: 0.1630 - val_accuracy: 0.9083 - val_loss: 0.2141 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9309 - loss: 0.1980\n",
      "Epoch 88: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9306 - loss: 0.1973 - val_accuracy: 0.9000 - val_loss: 0.2037 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9223 - loss: 0.1953\n",
      "Epoch 89: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.9221 - loss: 0.1950 - val_accuracy: 0.8917 - val_loss: 0.2323 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9250 - loss: 0.1767\n",
      "Epoch 90: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9258 - loss: 0.1764 - val_accuracy: 0.9167 - val_loss: 0.1921 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9335 - loss: 0.1593\n",
      "Epoch 91: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9335 - loss: 0.1598 - val_accuracy: 0.8833 - val_loss: 0.2385 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9359 - loss: 0.1386\n",
      "Epoch 92: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.9358 - loss: 0.1395 - val_accuracy: 0.9167 - val_loss: 0.2112 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9475 - loss: 0.1569\n",
      "Epoch 93: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.9474 - loss: 0.1570 - val_accuracy: 0.9000 - val_loss: 0.2516 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9597 - loss: 0.1246\n",
      "Epoch 94: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9583 - loss: 0.1273 - val_accuracy: 0.9000 - val_loss: 0.3014 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9363 - loss: 0.1646\n",
      "Epoch 95: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.9361 - loss: 0.1649 - val_accuracy: 0.9083 - val_loss: 0.2342 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9378 - loss: 0.1622\n",
      "Epoch 96: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.9378 - loss: 0.1615 - val_accuracy: 0.9000 - val_loss: 0.2417 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9405 - loss: 0.1482\n",
      "Epoch 97: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.9407 - loss: 0.1478 - val_accuracy: 0.8917 - val_loss: 0.2245 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9328 - loss: 0.1415\n",
      "Epoch 98: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9320 - loss: 0.1434 - val_accuracy: 0.9000 - val_loss: 0.3033 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9132 - loss: 0.1930\n",
      "Epoch 99: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.9135 - loss: 0.1936 - val_accuracy: 0.8917 - val_loss: 0.2443 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9499 - loss: 0.1554\n",
      "Epoch 100: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.9484 - loss: 0.1568 - val_accuracy: 0.9250 - val_loss: 0.1941 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9073 - loss: 0.2260\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3978 - loss: 3.4200\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76667, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.4009 - loss: 3.3539 - val_accuracy: 0.7667 - val_loss: 0.7710 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6731 - loss: 0.6268\n",
      "Epoch 2: val_accuracy did not improve from 0.76667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.6750 - loss: 0.6216 - val_accuracy: 0.5833 - val_loss: 0.5889 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7306 - loss: 0.5463\n",
      "Epoch 3: val_accuracy improved from 0.76667 to 0.84167, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7311 - loss: 0.5446 - val_accuracy: 0.8417 - val_loss: 0.4891 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7971 - loss: 0.4545\n",
      "Epoch 4: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7964 - loss: 0.4550 - val_accuracy: 0.7917 - val_loss: 0.4234 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8013 - loss: 0.4069\n",
      "Epoch 5: val_accuracy improved from 0.84167 to 0.85833, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.8009 - loss: 0.4095 - val_accuracy: 0.8583 - val_loss: 0.3719 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8183 - loss: 0.4032\n",
      "Epoch 6: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.8194 - loss: 0.4019 - val_accuracy: 0.8417 - val_loss: 0.3467 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8324 - loss: 0.3766\n",
      "Epoch 7: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8340 - loss: 0.3749 - val_accuracy: 0.8583 - val_loss: 0.3098 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8279 - loss: 0.3676\n",
      "Epoch 8: val_accuracy improved from 0.85833 to 0.89167, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.8279 - loss: 0.3680 - val_accuracy: 0.8917 - val_loss: 0.3417 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8675 - loss: 0.3235\n",
      "Epoch 9: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8665 - loss: 0.3244 - val_accuracy: 0.8833 - val_loss: 0.2781 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8343 - loss: 0.3515\n",
      "Epoch 10: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.8360 - loss: 0.3500 - val_accuracy: 0.8750 - val_loss: 0.2917 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8878 - loss: 0.2911\n",
      "Epoch 11: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.8871 - loss: 0.2923 - val_accuracy: 0.8583 - val_loss: 0.3222 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8847 - loss: 0.3146\n",
      "Epoch 12: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.8845 - loss: 0.3145 - val_accuracy: 0.8917 - val_loss: 0.2860 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8730 - loss: 0.3006\n",
      "Epoch 13: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.8727 - loss: 0.3018 - val_accuracy: 0.8917 - val_loss: 0.2692 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8988 - loss: 0.2604\n",
      "Epoch 14: val_accuracy improved from 0.89167 to 0.90833, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.8977 - loss: 0.2627 - val_accuracy: 0.9083 - val_loss: 0.2674 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8663 - loss: 0.3061\n",
      "Epoch 15: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.8675 - loss: 0.3046 - val_accuracy: 0.8667 - val_loss: 0.3050 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8785 - loss: 0.2682\n",
      "Epoch 16: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.8781 - loss: 0.2690 - val_accuracy: 0.8667 - val_loss: 0.3478 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8976 - loss: 0.2741\n",
      "Epoch 17: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8974 - loss: 0.2742 - val_accuracy: 0.8833 - val_loss: 0.2521 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8924 - loss: 0.2641\n",
      "Epoch 18: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.8924 - loss: 0.2638 - val_accuracy: 0.8833 - val_loss: 0.3089 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8843 - loss: 0.2589\n",
      "Epoch 19: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8841 - loss: 0.2602 - val_accuracy: 0.8667 - val_loss: 0.2561 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8988 - loss: 0.2450\n",
      "Epoch 20: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8984 - loss: 0.2459 - val_accuracy: 0.8750 - val_loss: 0.2818 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8757 - loss: 0.2757\n",
      "Epoch 21: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.8761 - loss: 0.2759 - val_accuracy: 0.8917 - val_loss: 0.2744 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8669 - loss: 0.3228\n",
      "Epoch 22: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8672 - loss: 0.3220 - val_accuracy: 0.9000 - val_loss: 0.2738 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8846 - loss: 0.3086\n",
      "Epoch 23: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.8853 - loss: 0.3065 - val_accuracy: 0.8917 - val_loss: 0.2167 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9247 - loss: 0.2324\n",
      "Epoch 24: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9239 - loss: 0.2335 - val_accuracy: 0.8833 - val_loss: 0.2328 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8903 - loss: 0.2651\n",
      "Epoch 25: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.8907 - loss: 0.2638 - val_accuracy: 0.9000 - val_loss: 0.2201 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9024 - loss: 0.2302\n",
      "Epoch 26: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.9029 - loss: 0.2297 - val_accuracy: 0.8750 - val_loss: 0.3133 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9182 - loss: 0.2395\n",
      "Epoch 27: val_accuracy improved from 0.90833 to 0.92500, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.9178 - loss: 0.2400 - val_accuracy: 0.9250 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9237 - loss: 0.2029\n",
      "Epoch 28: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9233 - loss: 0.2039 - val_accuracy: 0.9083 - val_loss: 0.2162 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8936 - loss: 0.2304\n",
      "Epoch 29: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.8939 - loss: 0.2306 - val_accuracy: 0.9083 - val_loss: 0.2083 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9049 - loss: 0.2176\n",
      "Epoch 30: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9055 - loss: 0.2171 - val_accuracy: 0.8750 - val_loss: 0.2826 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8802 - loss: 0.2783\n",
      "Epoch 31: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.8810 - loss: 0.2777 - val_accuracy: 0.9083 - val_loss: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9010 - loss: 0.2417\n",
      "Epoch 32: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9013 - loss: 0.2413 - val_accuracy: 0.9083 - val_loss: 0.2202 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8876 - loss: 0.2653\n",
      "Epoch 33: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.8877 - loss: 0.2656 - val_accuracy: 0.8750 - val_loss: 0.2369 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9198 - loss: 0.2115\n",
      "Epoch 34: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9195 - loss: 0.2119 - val_accuracy: 0.9250 - val_loss: 0.1905 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9186 - loss: 0.2087\n",
      "Epoch 35: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9184 - loss: 0.2097 - val_accuracy: 0.9000 - val_loss: 0.2488 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9028 - loss: 0.2434\n",
      "Epoch 36: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9038 - loss: 0.2414 - val_accuracy: 0.8917 - val_loss: 0.2436 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9379 - loss: 0.1709\n",
      "Epoch 37: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9365 - loss: 0.1729 - val_accuracy: 0.9083 - val_loss: 0.2084 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9210 - loss: 0.1756\n",
      "Epoch 38: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9208 - loss: 0.1763 - val_accuracy: 0.8917 - val_loss: 0.2506 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8979 - loss: 0.2078\n",
      "Epoch 39: val_accuracy improved from 0.92500 to 0.95000, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.8981 - loss: 0.2085 - val_accuracy: 0.9500 - val_loss: 0.1818 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8973 - loss: 0.2374\n",
      "Epoch 40: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8979 - loss: 0.2368 - val_accuracy: 0.8833 - val_loss: 0.2574 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8930 - loss: 0.2465\n",
      "Epoch 41: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.8931 - loss: 0.2464 - val_accuracy: 0.8667 - val_loss: 0.2755 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9229 - loss: 0.2017\n",
      "Epoch 42: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9225 - loss: 0.2028 - val_accuracy: 0.9083 - val_loss: 0.2056 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8965 - loss: 0.2408\n",
      "Epoch 43: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.8971 - loss: 0.2393 - val_accuracy: 0.9167 - val_loss: 0.1885 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9154 - loss: 0.2202\n",
      "Epoch 44: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9152 - loss: 0.2202 - val_accuracy: 0.9250 - val_loss: 0.2048 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9148 - loss: 0.2071\n",
      "Epoch 45: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9143 - loss: 0.2075 - val_accuracy: 0.9250 - val_loss: 0.1738 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9384 - loss: 0.1689\n",
      "Epoch 46: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9368 - loss: 0.1709 - val_accuracy: 0.8917 - val_loss: 0.2160 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9318 - loss: 0.1796\n",
      "Epoch 47: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.9313 - loss: 0.1802 - val_accuracy: 0.8917 - val_loss: 0.1904 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9150 - loss: 0.1934\n",
      "Epoch 48: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9146 - loss: 0.1945 - val_accuracy: 0.9333 - val_loss: 0.1867 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9194 - loss: 0.1762\n",
      "Epoch 49: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9190 - loss: 0.1771 - val_accuracy: 0.9417 - val_loss: 0.1731 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9089 - loss: 0.2231\n",
      "Epoch 50: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9091 - loss: 0.2238 - val_accuracy: 0.9333 - val_loss: 0.1907 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9358 - loss: 0.1682\n",
      "Epoch 51: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9353 - loss: 0.1688 - val_accuracy: 0.9167 - val_loss: 0.1894 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9245 - loss: 0.1812\n",
      "Epoch 52: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9236 - loss: 0.1830 - val_accuracy: 0.9000 - val_loss: 0.2365 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9227 - loss: 0.1972\n",
      "Epoch 53: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9218 - loss: 0.1984 - val_accuracy: 0.9000 - val_loss: 0.2417 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9362 - loss: 0.1517\n",
      "Epoch 54: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.9355 - loss: 0.1534 - val_accuracy: 0.9083 - val_loss: 0.1957 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9204 - loss: 0.2129\n",
      "Epoch 55: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9204 - loss: 0.2117 - val_accuracy: 0.9417 - val_loss: 0.1524 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9454 - loss: 0.1589\n",
      "Epoch 56: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9447 - loss: 0.1605 - val_accuracy: 0.9083 - val_loss: 0.1843 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9388 - loss: 0.1650\n",
      "Epoch 57: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9381 - loss: 0.1658 - val_accuracy: 0.9000 - val_loss: 0.2254 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9192 - loss: 0.1910\n",
      "Epoch 58: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9194 - loss: 0.1902 - val_accuracy: 0.9417 - val_loss: 0.1553 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9175 - loss: 0.1861\n",
      "Epoch 59: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9181 - loss: 0.1863 - val_accuracy: 0.9167 - val_loss: 0.2089 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.9195 - loss: 0.2220\n",
      "Epoch 60: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.9196 - loss: 0.2219 - val_accuracy: 0.8500 - val_loss: 0.2689 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8854 - loss: 0.2692\n",
      "Epoch 61: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.8862 - loss: 0.2682 - val_accuracy: 0.9250 - val_loss: 0.2280 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9332 - loss: 0.1836\n",
      "Epoch 62: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.9320 - loss: 0.1855 - val_accuracy: 0.9000 - val_loss: 0.2522 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9308 - loss: 0.1673\n",
      "Epoch 63: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9307 - loss: 0.1683 - val_accuracy: 0.9083 - val_loss: 0.1942 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9245 - loss: 0.2107\n",
      "Epoch 64: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.9248 - loss: 0.2097 - val_accuracy: 0.9167 - val_loss: 0.1940 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.9337 - loss: 0.1719\n",
      "Epoch 65: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9341 - loss: 0.1717 - val_accuracy: 0.9500 - val_loss: 0.1222 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9200 - loss: 0.1631\n",
      "Epoch 66: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9206 - loss: 0.1626 - val_accuracy: 0.9333 - val_loss: 0.1833 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9318 - loss: 0.1624\n",
      "Epoch 67: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.9310 - loss: 0.1644 - val_accuracy: 0.9333 - val_loss: 0.2019 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9407 - loss: 0.1692\n",
      "Epoch 68: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9397 - loss: 0.1704 - val_accuracy: 0.8917 - val_loss: 0.2512 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9206 - loss: 0.2107\n",
      "Epoch 69: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.9209 - loss: 0.2095 - val_accuracy: 0.9250 - val_loss: 0.1727 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9306 - loss: 0.1887\n",
      "Epoch 70: val_accuracy improved from 0.95000 to 0.95833, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - accuracy: 0.9307 - loss: 0.1881 - val_accuracy: 0.9583 - val_loss: 0.1286 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9422 - loss: 0.1595\n",
      "Epoch 71: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9417 - loss: 0.1600 - val_accuracy: 0.9417 - val_loss: 0.1437 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9459 - loss: 0.1499\n",
      "Epoch 72: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.9454 - loss: 0.1510 - val_accuracy: 0.9333 - val_loss: 0.2196 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9056 - loss: 0.2278\n",
      "Epoch 73: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.9065 - loss: 0.2260 - val_accuracy: 0.9167 - val_loss: 0.1710 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9314 - loss: 0.1662\n",
      "Epoch 74: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9315 - loss: 0.1661 - val_accuracy: 0.9417 - val_loss: 0.1699 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9161 - loss: 0.2149\n",
      "Epoch 75: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9164 - loss: 0.2142 - val_accuracy: 0.9500 - val_loss: 0.1588 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8988 - loss: 0.1742\n",
      "Epoch 76: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.8995 - loss: 0.1741 - val_accuracy: 0.9417 - val_loss: 0.1583 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9439 - loss: 0.1547\n",
      "Epoch 77: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.9437 - loss: 0.1560 - val_accuracy: 0.9333 - val_loss: 0.2374 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9378 - loss: 0.1859\n",
      "Epoch 78: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.9375 - loss: 0.1853 - val_accuracy: 0.9417 - val_loss: 0.1424 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9453 - loss: 0.1702\n",
      "Epoch 79: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9452 - loss: 0.1704 - val_accuracy: 0.9250 - val_loss: 0.1697 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9181 - loss: 0.1754\n",
      "Epoch 80: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - accuracy: 0.9180 - loss: 0.1763 - val_accuracy: 0.9250 - val_loss: 0.1790 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9256 - loss: 0.1984\n",
      "Epoch 81: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.9261 - loss: 0.1973 - val_accuracy: 0.9583 - val_loss: 0.1521 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9328 - loss: 0.1674\n",
      "Epoch 82: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.9332 - loss: 0.1664 - val_accuracy: 0.9500 - val_loss: 0.1483 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9209 - loss: 0.1749\n",
      "Epoch 83: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.9213 - loss: 0.1739 - val_accuracy: 0.9417 - val_loss: 0.2165 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.9422 - loss: 0.1892\n",
      "Epoch 84: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9416 - loss: 0.1894 - val_accuracy: 0.9333 - val_loss: 0.1490 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9271 - loss: 0.1733\n",
      "Epoch 85: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9275 - loss: 0.1727 - val_accuracy: 0.9250 - val_loss: 0.1811 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9291 - loss: 0.1732\n",
      "Epoch 86: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.9290 - loss: 0.1746 - val_accuracy: 0.9500 - val_loss: 0.1502 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9432 - loss: 0.1624\n",
      "Epoch 87: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.9430 - loss: 0.1625 - val_accuracy: 0.9417 - val_loss: 0.2422 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9501 - loss: 0.1337\n",
      "Epoch 88: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9495 - loss: 0.1345 - val_accuracy: 0.9583 - val_loss: 0.1140 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9571 - loss: 0.1212\n",
      "Epoch 89: val_accuracy improved from 0.95833 to 0.96667, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.9564 - loss: 0.1223 - val_accuracy: 0.9667 - val_loss: 0.1051 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9272 - loss: 0.1844\n",
      "Epoch 90: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.9266 - loss: 0.1858 - val_accuracy: 0.9167 - val_loss: 0.2073 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8970 - loss: 0.2014\n",
      "Epoch 91: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.8980 - loss: 0.2001 - val_accuracy: 0.9667 - val_loss: 0.1159 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.9255 - loss: 0.1698\n",
      "Epoch 92: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - accuracy: 0.9256 - loss: 0.1704 - val_accuracy: 0.9583 - val_loss: 0.1260 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9294 - loss: 0.1702\n",
      "Epoch 93: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9297 - loss: 0.1696 - val_accuracy: 0.9417 - val_loss: 0.1618 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9509 - loss: 0.1362\n",
      "Epoch 94: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9511 - loss: 0.1360 - val_accuracy: 0.9417 - val_loss: 0.1605 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9364 - loss: 0.1848\n",
      "Epoch 95: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9363 - loss: 0.1841 - val_accuracy: 0.9333 - val_loss: 0.1644 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9330 - loss: 0.1522\n",
      "Epoch 96: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9335 - loss: 0.1517 - val_accuracy: 0.9250 - val_loss: 0.1476 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9359 - loss: 0.1521\n",
      "Epoch 97: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9354 - loss: 0.1530 - val_accuracy: 0.9500 - val_loss: 0.1248 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9257 - loss: 0.1471\n",
      "Epoch 98: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.9262 - loss: 0.1470 - val_accuracy: 0.9333 - val_loss: 0.1464 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9300 - loss: 0.2029\n",
      "Epoch 99: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9306 - loss: 0.2003 - val_accuracy: 0.9500 - val_loss: 0.1302 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9192 - loss: 0.2214\n",
      "Epoch 100: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.9197 - loss: 0.2196 - val_accuracy: 0.9417 - val_loss: 0.1325 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 356ms/step - accuracy: 0.9352 - loss: 0.1786\n",
      "Accuracy on the test dataset: 95.00%\n",
      "Cross-Validation accuracy: [0.9583333134651184, 0.8999999761581421, 0.949999988079071, 0.8500000238418579, 0.9166666865348816]\n",
      "Average validation accuracy: 91.50%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000203826662A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 254ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000203826662A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 313ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "EPOCHS = 100\n",
    "RANDOM_SEED = 1024\n",
    "\n",
    "# Set up the directories\n",
    "train_dir = \"../Images_data/training_test_reduced/training_set\"\n",
    "test_dir = \"../Images_data/training_test_reduced/test_set\"\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data normalization for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    seed=RANDOM_SEED,\n",
    "    shuffle=False  # No shuffling to maintain order for evaluation\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "    drop = 0.25\n",
    "    kernel_initializer = 'he_uniform'\n",
    "    #kernel_initializer = 'glorot_uniform'  # Using glorot uniform initializer\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same', input_shape=(32, 32, 3)),\n",
    "        Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop),\n",
    "    \n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu', kernel_initializer=kernel_initializer),\n",
    "        Dropout(drop),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    opt = Adam(use_ema=True)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < int(0.3 * epoch):\n",
    "        return lr\n",
    "    else:\n",
    "        return lr # * np.exp(-1)\n",
    "\n",
    "# Function to load images and labels into numpy arrays\n",
    "def load_data(image_paths, labels, target_size):\n",
    "    data = []\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        data.append(img_array)\n",
    "    return np.array(data), to_categorical(np.array(labels), num_classes=3)\n",
    "\n",
    "# Cross-validation settings\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Get the list of all images and labels in the training directory\n",
    "image_paths = []\n",
    "labels = []\n",
    "classes = sorted(os.listdir(train_dir))\n",
    "class_indices = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(train_dir, cls)\n",
    "    if os.path.isdir(cls_dir):\n",
    "        for img in os.listdir(cls_dir):\n",
    "            img_path = os.path.join(cls_dir, img)\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(class_indices[cls])\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Cross-validation loop\n",
    "cv_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(image_paths):\n",
    "    train_data_paths = image_paths[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "    val_data_paths = image_paths[val_index]\n",
    "    val_labels = labels[val_index]\n",
    "    \n",
    "    # Load data for the current fold\n",
    "    train_data, train_labels = load_data(train_data_paths, train_labels, target_size=(32, 32))\n",
    "    val_data, val_labels = load_data(val_data_paths, val_labels, target_size=(32, 32))\n",
    "    \n",
    "    # Create ImageDataGenerators for the current fold\n",
    "    train_generator = train_datagen.flow(train_data, train_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "    validation_generator = train_datagen.flow(val_data, val_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('saved_models/best_model_fold.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    log_csv = CSVLogger(f'saved_logs/my_logs_fold.csv', separator=',', append=False)\n",
    "    callbacks_list = [checkpoint, log_csv, LearningRateScheduler(scheduler)]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    _, val_acc = model.evaluate(validation_generator)\n",
    "    cv_scores.append(val_acc)\n",
    "\n",
    "\n",
    "# Train final model on all training data and evaluate on test data\n",
    "train_data, train_labels = load_data(image_paths, labels, target_size=(32, 32))\n",
    "train_generator = train_datagen.flow(train_data, train_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "\n",
    "model = create_model()\n",
    "checkpoint = ModelCheckpoint('saved_models/best_model_final.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "log_csv = CSVLogger('saved_logs/my_logs_final.csv', separator=',', append=False)\n",
    "callbacks_list = [checkpoint, log_csv, LearningRateScheduler(scheduler)]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "_, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Accuracy on the test dataset: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Calculate average validation accuracy\n",
    "avg_val_acc = np.mean(cv_scores)\n",
    "print(f\"Cross-Validation accuracy: {cv_scores}\")\n",
    "print(f\"Average validation accuracy: {avg_val_acc * 100:.2f}%\")\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_test = model.predict(test_generator)\n",
    "prediction_test = np.argmax(y_pred_test, axis=1)\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "# Parallelizing confusion matrix computation using ThreadPoolExecutor\n",
    "def compute_confusion_matrix(ground_truth, prediction_test):\n",
    "    return confusion_matrix(ground_truth, prediction_test)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    cm = executor.submit(compute_confusion_matrix, ground_truth, prediction_test).result()\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code + CV + ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "EPOCHS = 1\n",
    "RANDOM_SEED = 1024\n",
    "\n",
    "# Set up the directories\n",
    "train_dir = \"../Images_data/training_test_reduced/training_set\"\n",
    "test_dir = \"../Images_data/training_test_reduced/test_set\"\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data normalization for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    seed=RANDOM_SEED,\n",
    "    shuffle=False  # No shuffling to maintain order for evaluation\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "    drop = 0.25\n",
    "    kernel_initializer = 'he_uniform'\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same', input_shape=(32, 32, 3)),\n",
    "        Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop),\n",
    "    \n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu', kernel_initializer=kernel_initializer),\n",
    "        Dropout(drop),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    opt = Adam(use_ema=True)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < int(0.3 * epoch):\n",
    "        return lr\n",
    "    else:\n",
    "        return lr # * np.exp(-1)\n",
    "\n",
    "# Function to load images and labels into numpy arrays\n",
    "def load_data(image_paths, labels, target_size):\n",
    "    data = []\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        data.append(img_array)\n",
    "    return np.array(data), to_categorical(np.array(labels), num_classes=3)\n",
    "\n",
    "# Cross-validation settings\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Get the list of all images and labels in the training directory\n",
    "image_paths = []\n",
    "labels = []\n",
    "classes = sorted(os.listdir(train_dir))\n",
    "class_indices = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(train_dir, cls)\n",
    "    if os.path.isdir(cls_dir):\n",
    "        for img in os.listdir(cls_dir):\n",
    "            img_path = os.path.join(cls_dir, img)\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(class_indices[cls])\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Cross-validation loop\n",
    "cv_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(image_paths):\n",
    "    train_data_paths = image_paths[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "    val_data_paths = image_paths[val_index]\n",
    "    val_labels = labels[val_index]\n",
    "    \n",
    "    # Load data for the current fold\n",
    "    train_data, train_labels = load_data(train_data_paths, train_labels, target_size=(32, 32))\n",
    "    val_data, val_labels = load_data(val_data_paths, val_labels, target_size=(32, 32))\n",
    "    \n",
    "    # Create ImageDataGenerators for the current fold\n",
    "    train_generator = train_datagen.flow(train_data, train_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "    validation_generator = train_datagen.flow(val_data, val_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('saved_models/best_model_fold.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    log_csv = CSVLogger(f'saved_logs/my_logs_fold.csv', separator=',', append=False)\n",
    "    callbacks_list = [checkpoint, log_csv, LearningRateScheduler(scheduler)]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    _, val_acc = model.evaluate(validation_generator)\n",
    "    cv_scores.append(val_acc)\n",
    "\n",
    "\n",
    "# Train final model on all training data and evaluate on test data\n",
    "train_data, train_labels = load_data(image_paths, labels, target_size=(32, 32))\n",
    "train_generator = train_datagen.flow(train_data, train_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "\n",
    "model = create_model()\n",
    "checkpoint = ModelCheckpoint('saved_models/best_model_final.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "log_csv = CSVLogger('saved_logs/my_logs_final.csv', separator=',', append=False)\n",
    "callbacks_list = [checkpoint, log_csv, LearningRateScheduler(scheduler)]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "_, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Accuracy on the test dataset: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Calculate average validation accuracy\n",
    "avg_val_acc = np.mean(cv_scores)\n",
    "print(f\"Cross-Validation accuracy: {cv_scores}\")\n",
    "print(f\"Average validation accuracy: {avg_val_acc * 100:.2f}%\")\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_test = model.predict(test_generator)\n",
    "prediction_test = np.argmax(y_pred_test, axis=1)\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "# Parallelizing confusion matrix computation using ThreadPoolExecutor\n",
    "def compute_confusion_matrix(ground_truth, prediction_test):\n",
    "    return confusion_matrix(ground_truth, prediction_test)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    cm = executor.submit(compute_confusion_matrix, ground_truth, prediction_test).result()\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(ground_truth, y_pred_test[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPC Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy-VS\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.3438 - loss: 1.5475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy-VS\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3432 - loss: 4.4281\n",
      "Epoch 1: val_accuracy improved from -inf to 0.44167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.3451 - loss: 4.2116 - val_accuracy: 0.4417 - val_loss: 1.0839 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3914 - loss: 1.0759\n",
      "Epoch 2: val_accuracy improved from 0.44167 to 0.69167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.3941 - loss: 1.0739 - val_accuracy: 0.6917 - val_loss: 0.8963 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6301 - loss: 0.7559\n",
      "Epoch 3: val_accuracy improved from 0.69167 to 0.71667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6334 - loss: 0.7444 - val_accuracy: 0.7167 - val_loss: 0.5876 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6610 - loss: 0.6542\n",
      "Epoch 4: val_accuracy improved from 0.71667 to 0.73333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6632 - loss: 0.6507 - val_accuracy: 0.7333 - val_loss: 0.5086 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6749 - loss: 0.5929\n",
      "Epoch 5: val_accuracy improved from 0.73333 to 0.85000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6783 - loss: 0.5873 - val_accuracy: 0.8500 - val_loss: 0.4054 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7696 - loss: 0.4754\n",
      "Epoch 6: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7688 - loss: 0.4758 - val_accuracy: 0.8083 - val_loss: 0.3602 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7567 - loss: 0.4810\n",
      "Epoch 7: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7587 - loss: 0.4790 - val_accuracy: 0.8417 - val_loss: 0.3750 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8090 - loss: 0.4097\n",
      "Epoch 8: val_accuracy improved from 0.85000 to 0.85833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8123 - loss: 0.4072 - val_accuracy: 0.8583 - val_loss: 0.3424 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8032 - loss: 0.4231\n",
      "Epoch 9: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8038 - loss: 0.4240 - val_accuracy: 0.8333 - val_loss: 0.4058 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7907 - loss: 0.4646\n",
      "Epoch 10: val_accuracy improved from 0.85833 to 0.91667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7923 - loss: 0.4620 - val_accuracy: 0.9167 - val_loss: 0.2594 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7853 - loss: 0.4662\n",
      "Epoch 11: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7848 - loss: 0.4670 - val_accuracy: 0.8917 - val_loss: 0.3284 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7688 - loss: 0.5170\n",
      "Epoch 12: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7693 - loss: 0.5151 - val_accuracy: 0.8333 - val_loss: 0.3565 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7569 - loss: 0.4158\n",
      "Epoch 13: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7600 - loss: 0.4145 - val_accuracy: 0.8500 - val_loss: 0.3251 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8239 - loss: 0.4151\n",
      "Epoch 14: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8240 - loss: 0.4138 - val_accuracy: 0.8833 - val_loss: 0.2736 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8454 - loss: 0.3495\n",
      "Epoch 15: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8450 - loss: 0.3501 - val_accuracy: 0.8250 - val_loss: 0.3321 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7988 - loss: 0.4596\n",
      "Epoch 16: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8002 - loss: 0.4566 - val_accuracy: 0.8833 - val_loss: 0.2789 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8413 - loss: 0.3486\n",
      "Epoch 17: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8413 - loss: 0.3518 - val_accuracy: 0.9000 - val_loss: 0.2418 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8204 - loss: 0.3464\n",
      "Epoch 18: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8239 - loss: 0.3464 - val_accuracy: 0.8917 - val_loss: 0.2558 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8763 - loss: 0.3245\n",
      "Epoch 19: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8754 - loss: 0.3260 - val_accuracy: 0.8833 - val_loss: 0.2604 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8639 - loss: 0.3072\n",
      "Epoch 20: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8635 - loss: 0.3074 - val_accuracy: 0.8833 - val_loss: 0.3382 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8260 - loss: 0.3592\n",
      "Epoch 21: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8267 - loss: 0.3578 - val_accuracy: 0.8917 - val_loss: 0.2368 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8669 - loss: 0.2923\n",
      "Epoch 22: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8682 - loss: 0.2911 - val_accuracy: 0.8917 - val_loss: 0.2365 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8804 - loss: 0.2921\n",
      "Epoch 23: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8797 - loss: 0.2934 - val_accuracy: 0.8583 - val_loss: 0.2842 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8709 - loss: 0.3374\n",
      "Epoch 24: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8711 - loss: 0.3349 - val_accuracy: 0.9000 - val_loss: 0.2343 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9173 - loss: 0.2184\n",
      "Epoch 25: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9156 - loss: 0.2218 - val_accuracy: 0.9083 - val_loss: 0.2436 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8731 - loss: 0.3291\n",
      "Epoch 26: val_accuracy improved from 0.91667 to 0.94167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8740 - loss: 0.3262 - val_accuracy: 0.9417 - val_loss: 0.1776 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8618 - loss: 0.3041\n",
      "Epoch 27: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8637 - loss: 0.3027 - val_accuracy: 0.9250 - val_loss: 0.2143 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8592 - loss: 0.3198\n",
      "Epoch 28: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8600 - loss: 0.3193 - val_accuracy: 0.9167 - val_loss: 0.2123 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8714 - loss: 0.2929\n",
      "Epoch 29: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8716 - loss: 0.2941 - val_accuracy: 0.8750 - val_loss: 0.2581 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8884 - loss: 0.2891\n",
      "Epoch 30: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8887 - loss: 0.2887 - val_accuracy: 0.9167 - val_loss: 0.2078 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8948 - loss: 0.2616\n",
      "Epoch 31: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8912 - loss: 0.2680 - val_accuracy: 0.9167 - val_loss: 0.2226 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8018 - loss: 0.3809\n",
      "Epoch 32: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8041 - loss: 0.3787 - val_accuracy: 0.8833 - val_loss: 0.2496 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8571 - loss: 0.2938\n",
      "Epoch 33: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8583 - loss: 0.2952 - val_accuracy: 0.9000 - val_loss: 0.1928 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8896 - loss: 0.2769\n",
      "Epoch 34: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8902 - loss: 0.2757 - val_accuracy: 0.9000 - val_loss: 0.2324 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8897 - loss: 0.2771\n",
      "Epoch 35: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8892 - loss: 0.2797 - val_accuracy: 0.9083 - val_loss: 0.2585 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8925 - loss: 0.2715\n",
      "Epoch 36: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8914 - loss: 0.2767 - val_accuracy: 0.8917 - val_loss: 0.2468 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8551 - loss: 0.3518\n",
      "Epoch 37: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8564 - loss: 0.3501 - val_accuracy: 0.9083 - val_loss: 0.2410 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8792 - loss: 0.3079\n",
      "Epoch 38: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8805 - loss: 0.3033 - val_accuracy: 0.9000 - val_loss: 0.2408 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8958 - loss: 0.3021\n",
      "Epoch 39: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8953 - loss: 0.3000 - val_accuracy: 0.9167 - val_loss: 0.2090 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8866 - loss: 0.2601\n",
      "Epoch 40: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8875 - loss: 0.2595 - val_accuracy: 0.9083 - val_loss: 0.2146 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9202 - loss: 0.2254\n",
      "Epoch 41: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9174 - loss: 0.2276 - val_accuracy: 0.9167 - val_loss: 0.2251 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9224 - loss: 0.2160\n",
      "Epoch 42: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9210 - loss: 0.2175 - val_accuracy: 0.9250 - val_loss: 0.1798 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9266 - loss: 0.1992\n",
      "Epoch 43: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9235 - loss: 0.2016 - val_accuracy: 0.9167 - val_loss: 0.2023 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8804 - loss: 0.3025\n",
      "Epoch 44: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8808 - loss: 0.3011 - val_accuracy: 0.9417 - val_loss: 0.2177 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9010 - loss: 0.2978\n",
      "Epoch 45: val_accuracy improved from 0.94167 to 0.95833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9010 - loss: 0.2956 - val_accuracy: 0.9583 - val_loss: 0.1555 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8907 - loss: 0.2593\n",
      "Epoch 46: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8922 - loss: 0.2587 - val_accuracy: 0.9333 - val_loss: 0.1758 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9176 - loss: 0.1982\n",
      "Epoch 47: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9166 - loss: 0.2005 - val_accuracy: 0.9167 - val_loss: 0.2055 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8960 - loss: 0.2598\n",
      "Epoch 48: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8967 - loss: 0.2591 - val_accuracy: 0.9333 - val_loss: 0.2180 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9131 - loss: 0.2329\n",
      "Epoch 49: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9125 - loss: 0.2333 - val_accuracy: 0.9250 - val_loss: 0.2091 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8999 - loss: 0.2688\n",
      "Epoch 50: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8991 - loss: 0.2695 - val_accuracy: 0.9500 - val_loss: 0.1782 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8839 - loss: 0.2718\n",
      "Epoch 51: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8847 - loss: 0.2699 - val_accuracy: 0.8917 - val_loss: 0.2146 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9148 - loss: 0.2079\n",
      "Epoch 52: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9144 - loss: 0.2088 - val_accuracy: 0.9250 - val_loss: 0.2249 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9260 - loss: 0.1791\n",
      "Epoch 53: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9245 - loss: 0.1821 - val_accuracy: 0.9500 - val_loss: 0.1577 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8835 - loss: 0.2518\n",
      "Epoch 54: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8853 - loss: 0.2501 - val_accuracy: 0.9417 - val_loss: 0.1479 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9104 - loss: 0.2306\n",
      "Epoch 55: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9095 - loss: 0.2325 - val_accuracy: 0.9083 - val_loss: 0.2897 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9067 - loss: 0.2433\n",
      "Epoch 56: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9060 - loss: 0.2448 - val_accuracy: 0.8750 - val_loss: 0.3282 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8958 - loss: 0.2593\n",
      "Epoch 57: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8949 - loss: 0.2609 - val_accuracy: 0.9333 - val_loss: 0.1999 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9306 - loss: 0.2039\n",
      "Epoch 58: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9283 - loss: 0.2062 - val_accuracy: 0.9500 - val_loss: 0.1641 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8732 - loss: 0.2996\n",
      "Epoch 59: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8734 - loss: 0.2973 - val_accuracy: 0.9500 - val_loss: 0.1656 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8940 - loss: 0.2678\n",
      "Epoch 60: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8943 - loss: 0.2648 - val_accuracy: 0.9333 - val_loss: 0.1952 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8980 - loss: 0.2361\n",
      "Epoch 61: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8987 - loss: 0.2351 - val_accuracy: 0.9500 - val_loss: 0.1423 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9292 - loss: 0.1876\n",
      "Epoch 62: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9287 - loss: 0.1882 - val_accuracy: 0.9167 - val_loss: 0.2179 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9145 - loss: 0.2163\n",
      "Epoch 63: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9138 - loss: 0.2177 - val_accuracy: 0.8750 - val_loss: 0.2653 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9015 - loss: 0.2654\n",
      "Epoch 64: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8994 - loss: 0.2666 - val_accuracy: 0.9333 - val_loss: 0.1491 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9198 - loss: 0.2277\n",
      "Epoch 65: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9192 - loss: 0.2277 - val_accuracy: 0.9333 - val_loss: 0.1965 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9035 - loss: 0.2620\n",
      "Epoch 66: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9022 - loss: 0.2634 - val_accuracy: 0.9500 - val_loss: 0.1709 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8932 - loss: 0.2392\n",
      "Epoch 67: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8932 - loss: 0.2392 - val_accuracy: 0.9333 - val_loss: 0.1561 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9264 - loss: 0.1991\n",
      "Epoch 68: val_accuracy improved from 0.95833 to 0.96667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9264 - loss: 0.1990 - val_accuracy: 0.9667 - val_loss: 0.1012 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9175 - loss: 0.2002\n",
      "Epoch 69: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9158 - loss: 0.2042 - val_accuracy: 0.9417 - val_loss: 0.1606 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9161 - loss: 0.2199\n",
      "Epoch 70: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9135 - loss: 0.2216 - val_accuracy: 0.9333 - val_loss: 0.1858 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9104 - loss: 0.2050\n",
      "Epoch 71: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9110 - loss: 0.2047 - val_accuracy: 0.9417 - val_loss: 0.1702 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9228 - loss: 0.1945\n",
      "Epoch 72: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9218 - loss: 0.1953 - val_accuracy: 0.9333 - val_loss: 0.1577 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9175 - loss: 0.1838\n",
      "Epoch 73: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9172 - loss: 0.1847 - val_accuracy: 0.9417 - val_loss: 0.1506 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9287 - loss: 0.2104\n",
      "Epoch 74: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9275 - loss: 0.2110 - val_accuracy: 0.9000 - val_loss: 0.2376 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8697 - loss: 0.3241\n",
      "Epoch 75: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8738 - loss: 0.3166 - val_accuracy: 0.9417 - val_loss: 0.1861 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8848 - loss: 0.2374\n",
      "Epoch 76: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8858 - loss: 0.2367 - val_accuracy: 0.9583 - val_loss: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9249 - loss: 0.1784\n",
      "Epoch 77: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9241 - loss: 0.1807 - val_accuracy: 0.9083 - val_loss: 0.1935 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9077 - loss: 0.2263\n",
      "Epoch 78: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9074 - loss: 0.2269 - val_accuracy: 0.8833 - val_loss: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9092 - loss: 0.2162\n",
      "Epoch 79: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9088 - loss: 0.2169 - val_accuracy: 0.9250 - val_loss: 0.1622 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9307 - loss: 0.1926\n",
      "Epoch 80: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9302 - loss: 0.1922 - val_accuracy: 0.9333 - val_loss: 0.1484 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9032 - loss: 0.2050\n",
      "Epoch 81: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9059 - loss: 0.2021 - val_accuracy: 0.9167 - val_loss: 0.1793 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9169 - loss: 0.2108\n",
      "Epoch 82: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9159 - loss: 0.2125 - val_accuracy: 0.9417 - val_loss: 0.1498 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9008 - loss: 0.2149\n",
      "Epoch 83: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9010 - loss: 0.2159 - val_accuracy: 0.9583 - val_loss: 0.1691 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9331 - loss: 0.1949\n",
      "Epoch 84: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9319 - loss: 0.1963 - val_accuracy: 0.8833 - val_loss: 0.2402 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9414 - loss: 0.1473\n",
      "Epoch 85: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9405 - loss: 0.1499 - val_accuracy: 0.9500 - val_loss: 0.1285 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9297 - loss: 0.1835\n",
      "Epoch 86: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9299 - loss: 0.1842 - val_accuracy: 0.9167 - val_loss: 0.2198 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9305 - loss: 0.1661\n",
      "Epoch 87: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9308 - loss: 0.1667 - val_accuracy: 0.9583 - val_loss: 0.1932 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9453 - loss: 0.1881\n",
      "Epoch 88: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9450 - loss: 0.1875 - val_accuracy: 0.9083 - val_loss: 0.1824 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9244 - loss: 0.1832\n",
      "Epoch 89: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9245 - loss: 0.1825 - val_accuracy: 0.9333 - val_loss: 0.1588 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9327 - loss: 0.2000\n",
      "Epoch 90: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9329 - loss: 0.1984 - val_accuracy: 0.9417 - val_loss: 0.1396 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8884 - loss: 0.2163\n",
      "Epoch 91: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8914 - loss: 0.2138 - val_accuracy: 0.9417 - val_loss: 0.1857 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9175 - loss: 0.1632\n",
      "Epoch 92: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9185 - loss: 0.1627 - val_accuracy: 0.9250 - val_loss: 0.1978 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9402 - loss: 0.1591\n",
      "Epoch 93: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9392 - loss: 0.1601 - val_accuracy: 0.9583 - val_loss: 0.1042 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9408 - loss: 0.1567\n",
      "Epoch 94: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9396 - loss: 0.1586 - val_accuracy: 0.9167 - val_loss: 0.2145 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9235 - loss: 0.1942\n",
      "Epoch 95: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9239 - loss: 0.1942 - val_accuracy: 0.9667 - val_loss: 0.1122 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9207 - loss: 0.2060\n",
      "Epoch 96: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9206 - loss: 0.2046 - val_accuracy: 0.9583 - val_loss: 0.1280 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9371 - loss: 0.1704\n",
      "Epoch 97: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9370 - loss: 0.1708 - val_accuracy: 0.9167 - val_loss: 0.2256 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9371 - loss: 0.1608\n",
      "Epoch 98: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9376 - loss: 0.1598 - val_accuracy: 0.9417 - val_loss: 0.1883 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9390 - loss: 0.1525\n",
      "Epoch 99: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9389 - loss: 0.1532 - val_accuracy: 0.9500 - val_loss: 0.1408 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8903 - loss: 0.3030\n",
      "Epoch 100: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8907 - loss: 0.2974 - val_accuracy: 0.9250 - val_loss: 0.2260 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9390 - loss: 0.1656\n",
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2908 - loss: 4.8653\n",
      "Epoch 1: val_accuracy improved from -inf to 0.38333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.2940 - loss: 4.7417 - val_accuracy: 0.3833 - val_loss: 0.9981 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5264 - loss: 0.8685\n",
      "Epoch 2: val_accuracy improved from 0.38333 to 0.70000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.5371 - loss: 0.8518 - val_accuracy: 0.7000 - val_loss: 0.5664 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6927 - loss: 0.5462\n",
      "Epoch 3: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6944 - loss: 0.5455 - val_accuracy: 0.6667 - val_loss: 0.5352 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6999 - loss: 0.5569\n",
      "Epoch 4: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7002 - loss: 0.5548 - val_accuracy: 0.6667 - val_loss: 0.5285 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7511 - loss: 0.4503\n",
      "Epoch 5: val_accuracy improved from 0.70000 to 0.70833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7505 - loss: 0.4511 - val_accuracy: 0.7083 - val_loss: 0.5216 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7471 - loss: 0.4757\n",
      "Epoch 6: val_accuracy improved from 0.70833 to 0.80000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7474 - loss: 0.4755 - val_accuracy: 0.8000 - val_loss: 0.5149 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7528 - loss: 0.5282\n",
      "Epoch 7: val_accuracy improved from 0.80000 to 0.82500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7533 - loss: 0.5256 - val_accuracy: 0.8250 - val_loss: 0.4444 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8102 - loss: 0.4539\n",
      "Epoch 8: val_accuracy did not improve from 0.82500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8106 - loss: 0.4522 - val_accuracy: 0.8250 - val_loss: 0.4146 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8090 - loss: 0.4318\n",
      "Epoch 9: val_accuracy did not improve from 0.82500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8070 - loss: 0.4336 - val_accuracy: 0.6333 - val_loss: 0.5670 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8039 - loss: 0.4084\n",
      "Epoch 10: val_accuracy improved from 0.82500 to 0.84167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8055 - loss: 0.4061 - val_accuracy: 0.8417 - val_loss: 0.4255 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8343 - loss: 0.4077\n",
      "Epoch 11: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8342 - loss: 0.4058 - val_accuracy: 0.8417 - val_loss: 0.3584 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8150 - loss: 0.4304\n",
      "Epoch 12: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8148 - loss: 0.4311 - val_accuracy: 0.7750 - val_loss: 0.4812 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8047 - loss: 0.3915\n",
      "Epoch 13: val_accuracy improved from 0.84167 to 0.85833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8062 - loss: 0.3893 - val_accuracy: 0.8583 - val_loss: 0.3663 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8605 - loss: 0.3409\n",
      "Epoch 14: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8608 - loss: 0.3409 - val_accuracy: 0.8500 - val_loss: 0.3548 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8807 - loss: 0.2958\n",
      "Epoch 15: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8795 - loss: 0.2979 - val_accuracy: 0.7917 - val_loss: 0.4396 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8392 - loss: 0.3523\n",
      "Epoch 16: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8392 - loss: 0.3521 - val_accuracy: 0.8500 - val_loss: 0.3467 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8805 - loss: 0.3008\n",
      "Epoch 17: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8804 - loss: 0.3006 - val_accuracy: 0.8417 - val_loss: 0.3905 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8605 - loss: 0.3512\n",
      "Epoch 18: val_accuracy did not improve from 0.85833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8600 - loss: 0.3530 - val_accuracy: 0.8000 - val_loss: 0.4305 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7777 - loss: 0.4154\n",
      "Epoch 19: val_accuracy improved from 0.85833 to 0.86667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7794 - loss: 0.4149 - val_accuracy: 0.8667 - val_loss: 0.3531 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8609 - loss: 0.3418\n",
      "Epoch 20: val_accuracy improved from 0.86667 to 0.88333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8624 - loss: 0.3386 - val_accuracy: 0.8833 - val_loss: 0.3158 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8637 - loss: 0.3239\n",
      "Epoch 21: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8641 - loss: 0.3227 - val_accuracy: 0.8833 - val_loss: 0.2933 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8864 - loss: 0.2576\n",
      "Epoch 22: val_accuracy improved from 0.88333 to 0.89167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8857 - loss: 0.2586 - val_accuracy: 0.8917 - val_loss: 0.2370 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8985 - loss: 0.2960\n",
      "Epoch 23: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8984 - loss: 0.2952 - val_accuracy: 0.8750 - val_loss: 0.3020 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8770 - loss: 0.2877\n",
      "Epoch 24: val_accuracy improved from 0.89167 to 0.90000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8775 - loss: 0.2867 - val_accuracy: 0.9000 - val_loss: 0.2976 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8779 - loss: 0.3172\n",
      "Epoch 25: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8772 - loss: 0.3179 - val_accuracy: 0.8833 - val_loss: 0.3086 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8941 - loss: 0.2661\n",
      "Epoch 26: val_accuracy improved from 0.90000 to 0.91667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8937 - loss: 0.2664 - val_accuracy: 0.9167 - val_loss: 0.2819 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8450 - loss: 0.3500\n",
      "Epoch 27: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8487 - loss: 0.3446 - val_accuracy: 0.8083 - val_loss: 0.4380 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8523 - loss: 0.3610\n",
      "Epoch 28: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8537 - loss: 0.3574 - val_accuracy: 0.8083 - val_loss: 0.3632 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8823 - loss: 0.3101\n",
      "Epoch 29: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8832 - loss: 0.3071 - val_accuracy: 0.9000 - val_loss: 0.2645 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8531 - loss: 0.2884\n",
      "Epoch 30: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8530 - loss: 0.2895 - val_accuracy: 0.8583 - val_loss: 0.3048 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8807 - loss: 0.2998\n",
      "Epoch 31: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8809 - loss: 0.2984 - val_accuracy: 0.8583 - val_loss: 0.3488 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8862 - loss: 0.2731\n",
      "Epoch 32: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8861 - loss: 0.2729 - val_accuracy: 0.9167 - val_loss: 0.2882 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8369 - loss: 0.3180\n",
      "Epoch 33: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8389 - loss: 0.3164 - val_accuracy: 0.8833 - val_loss: 0.2802 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8501 - loss: 0.3198\n",
      "Epoch 34: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8502 - loss: 0.3197 - val_accuracy: 0.9083 - val_loss: 0.2873 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8604 - loss: 0.3123\n",
      "Epoch 35: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8628 - loss: 0.3081 - val_accuracy: 0.8750 - val_loss: 0.2618 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8805 - loss: 0.2802\n",
      "Epoch 36: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8801 - loss: 0.2813 - val_accuracy: 0.8833 - val_loss: 0.2920 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9076 - loss: 0.2464\n",
      "Epoch 37: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9069 - loss: 0.2477 - val_accuracy: 0.8833 - val_loss: 0.2575 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9110 - loss: 0.2310\n",
      "Epoch 38: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9096 - loss: 0.2325 - val_accuracy: 0.8750 - val_loss: 0.2702 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9015 - loss: 0.2419\n",
      "Epoch 39: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9018 - loss: 0.2420 - val_accuracy: 0.9000 - val_loss: 0.2535 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8987 - loss: 0.2607\n",
      "Epoch 40: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8994 - loss: 0.2602 - val_accuracy: 0.9000 - val_loss: 0.1992 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8783 - loss: 0.2598\n",
      "Epoch 41: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8768 - loss: 0.2619 - val_accuracy: 0.9000 - val_loss: 0.3283 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8638 - loss: 0.3253\n",
      "Epoch 42: val_accuracy improved from 0.91667 to 0.93333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8649 - loss: 0.3227 - val_accuracy: 0.9333 - val_loss: 0.2390 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8788 - loss: 0.2650\n",
      "Epoch 43: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8796 - loss: 0.2640 - val_accuracy: 0.9000 - val_loss: 0.2448 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8831 - loss: 0.2320\n",
      "Epoch 44: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8830 - loss: 0.2327 - val_accuracy: 0.9167 - val_loss: 0.2063 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9047 - loss: 0.2325\n",
      "Epoch 45: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9045 - loss: 0.2325 - val_accuracy: 0.9083 - val_loss: 0.2259 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8908 - loss: 0.2649\n",
      "Epoch 46: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8917 - loss: 0.2612 - val_accuracy: 0.9167 - val_loss: 0.3098 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8716 - loss: 0.3684\n",
      "Epoch 47: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8723 - loss: 0.3610 - val_accuracy: 0.9000 - val_loss: 0.2796 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9141 - loss: 0.2298\n",
      "Epoch 48: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9131 - loss: 0.2316 - val_accuracy: 0.9000 - val_loss: 0.2612 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8897 - loss: 0.2624\n",
      "Epoch 49: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8896 - loss: 0.2603 - val_accuracy: 0.8833 - val_loss: 0.2644 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9123 - loss: 0.2134\n",
      "Epoch 50: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9116 - loss: 0.2149 - val_accuracy: 0.8833 - val_loss: 0.2338 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9072 - loss: 0.2286\n",
      "Epoch 51: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9071 - loss: 0.2309 - val_accuracy: 0.8667 - val_loss: 0.3349 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8868 - loss: 0.2745\n",
      "Epoch 52: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8874 - loss: 0.2704 - val_accuracy: 0.9083 - val_loss: 0.2164 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9076 - loss: 0.2093\n",
      "Epoch 53: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9046 - loss: 0.2151 - val_accuracy: 0.9083 - val_loss: 0.2254 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8676 - loss: 0.2968\n",
      "Epoch 54: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8717 - loss: 0.2916 - val_accuracy: 0.8917 - val_loss: 0.2474 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8942 - loss: 0.2621\n",
      "Epoch 55: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8955 - loss: 0.2595 - val_accuracy: 0.9000 - val_loss: 0.2558 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8831 - loss: 0.2614\n",
      "Epoch 56: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8852 - loss: 0.2573 - val_accuracy: 0.8917 - val_loss: 0.2309 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8854 - loss: 0.2312\n",
      "Epoch 57: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8888 - loss: 0.2268 - val_accuracy: 0.9083 - val_loss: 0.2203 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9201 - loss: 0.1797\n",
      "Epoch 58: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9183 - loss: 0.1852 - val_accuracy: 0.8917 - val_loss: 0.2153 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9108 - loss: 0.2422\n",
      "Epoch 59: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9081 - loss: 0.2459 - val_accuracy: 0.9167 - val_loss: 0.2398 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9031 - loss: 0.2070\n",
      "Epoch 60: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9028 - loss: 0.2081 - val_accuracy: 0.8833 - val_loss: 0.2527 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9098 - loss: 0.1949\n",
      "Epoch 61: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9094 - loss: 0.1962 - val_accuracy: 0.9333 - val_loss: 0.2294 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9287 - loss: 0.1921\n",
      "Epoch 62: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9298 - loss: 0.1914 - val_accuracy: 0.9000 - val_loss: 0.2269 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9156 - loss: 0.2258\n",
      "Epoch 63: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9144 - loss: 0.2265 - val_accuracy: 0.9000 - val_loss: 0.1994 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9276 - loss: 0.1905\n",
      "Epoch 64: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9275 - loss: 0.1910 - val_accuracy: 0.9083 - val_loss: 0.2175 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9052 - loss: 0.2341\n",
      "Epoch 65: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9050 - loss: 0.2345 - val_accuracy: 0.9250 - val_loss: 0.1875 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9044 - loss: 0.2227\n",
      "Epoch 66: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9044 - loss: 0.2223 - val_accuracy: 0.8750 - val_loss: 0.2311 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8981 - loss: 0.2513\n",
      "Epoch 67: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8991 - loss: 0.2488 - val_accuracy: 0.9083 - val_loss: 0.2238 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9133 - loss: 0.2215\n",
      "Epoch 68: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9124 - loss: 0.2226 - val_accuracy: 0.9167 - val_loss: 0.2027 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9283 - loss: 0.2044\n",
      "Epoch 69: val_accuracy improved from 0.93333 to 0.94167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9282 - loss: 0.2043 - val_accuracy: 0.9417 - val_loss: 0.1797 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8880 - loss: 0.2620\n",
      "Epoch 70: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8896 - loss: 0.2595 - val_accuracy: 0.8917 - val_loss: 0.1990 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9493 - loss: 0.1666\n",
      "Epoch 71: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9462 - loss: 0.1701 - val_accuracy: 0.8750 - val_loss: 0.2708 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8933 - loss: 0.2192\n",
      "Epoch 72: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8932 - loss: 0.2212 - val_accuracy: 0.9083 - val_loss: 0.2429 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9369 - loss: 0.1805\n",
      "Epoch 73: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9356 - loss: 0.1824 - val_accuracy: 0.9083 - val_loss: 0.2103 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8935 - loss: 0.2423\n",
      "Epoch 74: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8933 - loss: 0.2421 - val_accuracy: 0.9083 - val_loss: 0.1845 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9071 - loss: 0.2197\n",
      "Epoch 75: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9059 - loss: 0.2225 - val_accuracy: 0.9000 - val_loss: 0.2320 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9230 - loss: 0.2077\n",
      "Epoch 76: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9226 - loss: 0.2084 - val_accuracy: 0.8833 - val_loss: 0.2436 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9063 - loss: 0.1979\n",
      "Epoch 77: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9076 - loss: 0.1967 - val_accuracy: 0.9250 - val_loss: 0.1718 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9240 - loss: 0.2051\n",
      "Epoch 78: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9262 - loss: 0.2011 - val_accuracy: 0.9083 - val_loss: 0.1819 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9442 - loss: 0.1696\n",
      "Epoch 79: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9426 - loss: 0.1722 - val_accuracy: 0.9333 - val_loss: 0.2168 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8975 - loss: 0.2387\n",
      "Epoch 80: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8978 - loss: 0.2386 - val_accuracy: 0.9083 - val_loss: 0.1888 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9414 - loss: 0.1668\n",
      "Epoch 81: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9408 - loss: 0.1675 - val_accuracy: 0.9333 - val_loss: 0.1912 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8868 - loss: 0.2833\n",
      "Epoch 82: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8882 - loss: 0.2808 - val_accuracy: 0.9167 - val_loss: 0.2453 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9041 - loss: 0.2194\n",
      "Epoch 83: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9044 - loss: 0.2189 - val_accuracy: 0.9250 - val_loss: 0.2367 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9216 - loss: 0.1875\n",
      "Epoch 84: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9210 - loss: 0.1882 - val_accuracy: 0.9167 - val_loss: 0.2006 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9132 - loss: 0.1860\n",
      "Epoch 85: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9129 - loss: 0.1862 - val_accuracy: 0.9167 - val_loss: 0.1886 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9365 - loss: 0.1458\n",
      "Epoch 86: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9357 - loss: 0.1468 - val_accuracy: 0.9167 - val_loss: 0.2028 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9401 - loss: 0.1421\n",
      "Epoch 87: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9393 - loss: 0.1434 - val_accuracy: 0.9250 - val_loss: 0.1738 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9068 - loss: 0.2188\n",
      "Epoch 88: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9075 - loss: 0.2153 - val_accuracy: 0.9083 - val_loss: 0.2011 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9233 - loss: 0.2107\n",
      "Epoch 89: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9233 - loss: 0.2104 - val_accuracy: 0.9167 - val_loss: 0.1891 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9185 - loss: 0.2285\n",
      "Epoch 90: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9187 - loss: 0.2267 - val_accuracy: 0.8917 - val_loss: 0.2767 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9331 - loss: 0.1666\n",
      "Epoch 91: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9327 - loss: 0.1669 - val_accuracy: 0.8750 - val_loss: 0.2887 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9210 - loss: 0.1820\n",
      "Epoch 92: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9211 - loss: 0.1821 - val_accuracy: 0.9417 - val_loss: 0.1520 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9345 - loss: 0.1622\n",
      "Epoch 93: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9340 - loss: 0.1637 - val_accuracy: 0.9000 - val_loss: 0.1818 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9247 - loss: 0.1762\n",
      "Epoch 94: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9245 - loss: 0.1773 - val_accuracy: 0.9417 - val_loss: 0.1296 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9432 - loss: 0.1474\n",
      "Epoch 95: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9420 - loss: 0.1487 - val_accuracy: 0.8833 - val_loss: 0.2125 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9459 - loss: 0.1602\n",
      "Epoch 96: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9444 - loss: 0.1615 - val_accuracy: 0.9250 - val_loss: 0.1582 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9202 - loss: 0.1993\n",
      "Epoch 97: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9219 - loss: 0.1969 - val_accuracy: 0.8917 - val_loss: 0.2047 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9102 - loss: 0.2020\n",
      "Epoch 98: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9115 - loss: 0.2016 - val_accuracy: 0.8833 - val_loss: 0.2330 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9258 - loss: 0.1818\n",
      "Epoch 99: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9265 - loss: 0.1804 - val_accuracy: 0.9167 - val_loss: 0.2499 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9023 - loss: 0.2324\n",
      "Epoch 100: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9020 - loss: 0.2328 - val_accuracy: 0.8583 - val_loss: 0.3055 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8894 - loss: 0.2189\n",
      "Epoch 1/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3473 - loss: 4.5912\n",
      "Epoch 1: val_accuracy improved from -inf to 0.40833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.3515 - loss: 4.3593 - val_accuracy: 0.4083 - val_loss: 1.0444 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5543 - loss: 0.9425\n",
      "Epoch 2: val_accuracy improved from 0.40833 to 0.67500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5663 - loss: 0.9212 - val_accuracy: 0.6750 - val_loss: 0.5044 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6737 - loss: 0.5868\n",
      "Epoch 3: val_accuracy improved from 0.67500 to 0.74167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6747 - loss: 0.5866 - val_accuracy: 0.7417 - val_loss: 0.5077 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7004 - loss: 0.4943\n",
      "Epoch 4: val_accuracy improved from 0.74167 to 0.80833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7029 - loss: 0.4942 - val_accuracy: 0.8083 - val_loss: 0.4759 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7900 - loss: 0.4554\n",
      "Epoch 5: val_accuracy did not improve from 0.80833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7888 - loss: 0.4579 - val_accuracy: 0.7333 - val_loss: 0.4600 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7861 - loss: 0.4571\n",
      "Epoch 6: val_accuracy did not improve from 0.80833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7861 - loss: 0.4586 - val_accuracy: 0.7583 - val_loss: 0.5938 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7654 - loss: 0.5757\n",
      "Epoch 7: val_accuracy did not improve from 0.80833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7656 - loss: 0.5727 - val_accuracy: 0.6833 - val_loss: 0.5386 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7526 - loss: 0.4588\n",
      "Epoch 8: val_accuracy did not improve from 0.80833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7549 - loss: 0.4581 - val_accuracy: 0.8083 - val_loss: 0.3698 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8167 - loss: 0.3995\n",
      "Epoch 9: val_accuracy did not improve from 0.80833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8156 - loss: 0.4008 - val_accuracy: 0.7833 - val_loss: 0.3988 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7975 - loss: 0.4306\n",
      "Epoch 10: val_accuracy did not improve from 0.80833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7996 - loss: 0.4278 - val_accuracy: 0.8000 - val_loss: 0.3792 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8316 - loss: 0.3674\n",
      "Epoch 11: val_accuracy improved from 0.80833 to 0.88333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8305 - loss: 0.3710 - val_accuracy: 0.8833 - val_loss: 0.2928 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8155 - loss: 0.3940\n",
      "Epoch 12: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8172 - loss: 0.3909 - val_accuracy: 0.7583 - val_loss: 0.4296 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8375 - loss: 0.3650\n",
      "Epoch 13: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8380 - loss: 0.3640 - val_accuracy: 0.8083 - val_loss: 0.3585 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8639 - loss: 0.3174\n",
      "Epoch 14: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8642 - loss: 0.3174 - val_accuracy: 0.8833 - val_loss: 0.3325 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8599 - loss: 0.3095\n",
      "Epoch 15: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8592 - loss: 0.3110 - val_accuracy: 0.8750 - val_loss: 0.2992 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8121 - loss: 0.4234\n",
      "Epoch 16: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8101 - loss: 0.4267 - val_accuracy: 0.8167 - val_loss: 0.4222 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8371 - loss: 0.3966\n",
      "Epoch 17: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8390 - loss: 0.3932 - val_accuracy: 0.8667 - val_loss: 0.2837 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8451 - loss: 0.3444\n",
      "Epoch 18: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8465 - loss: 0.3405 - val_accuracy: 0.8750 - val_loss: 0.2886 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8583 - loss: 0.3187\n",
      "Epoch 19: val_accuracy did not improve from 0.88333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8583 - loss: 0.3182 - val_accuracy: 0.8500 - val_loss: 0.3149 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8802 - loss: 0.2903\n",
      "Epoch 20: val_accuracy improved from 0.88333 to 0.90833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8796 - loss: 0.2907 - val_accuracy: 0.9083 - val_loss: 0.2448 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8425 - loss: 0.3521\n",
      "Epoch 21: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8448 - loss: 0.3490 - val_accuracy: 0.8667 - val_loss: 0.3022 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8803 - loss: 0.2750\n",
      "Epoch 22: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8801 - loss: 0.2760 - val_accuracy: 0.8583 - val_loss: 0.3006 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8806 - loss: 0.2681\n",
      "Epoch 23: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8805 - loss: 0.2692 - val_accuracy: 0.8917 - val_loss: 0.2987 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8570 - loss: 0.3665\n",
      "Epoch 24: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8577 - loss: 0.3616 - val_accuracy: 0.8250 - val_loss: 0.4130 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8395 - loss: 0.3528\n",
      "Epoch 25: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8424 - loss: 0.3514 - val_accuracy: 0.8583 - val_loss: 0.3246 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8493 - loss: 0.3171\n",
      "Epoch 26: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8497 - loss: 0.3191 - val_accuracy: 0.9000 - val_loss: 0.2745 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8843 - loss: 0.2941\n",
      "Epoch 27: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8838 - loss: 0.2956 - val_accuracy: 0.8833 - val_loss: 0.2906 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8677 - loss: 0.3257\n",
      "Epoch 28: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8679 - loss: 0.3249 - val_accuracy: 0.9000 - val_loss: 0.2307 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8534 - loss: 0.3040\n",
      "Epoch 29: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8550 - loss: 0.3019 - val_accuracy: 0.8917 - val_loss: 0.3197 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8871 - loss: 0.2709\n",
      "Epoch 30: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8869 - loss: 0.2709 - val_accuracy: 0.9000 - val_loss: 0.2883 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8837 - loss: 0.2636\n",
      "Epoch 31: val_accuracy did not improve from 0.90833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8836 - loss: 0.2644 - val_accuracy: 0.8583 - val_loss: 0.2638 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9199 - loss: 0.2083\n",
      "Epoch 32: val_accuracy improved from 0.90833 to 0.91667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9171 - loss: 0.2126 - val_accuracy: 0.9167 - val_loss: 0.1742 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8949 - loss: 0.2584\n",
      "Epoch 33: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8952 - loss: 0.2578 - val_accuracy: 0.9083 - val_loss: 0.2655 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9124 - loss: 0.2105\n",
      "Epoch 34: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9116 - loss: 0.2116 - val_accuracy: 0.8583 - val_loss: 0.2811 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9168 - loss: 0.2025\n",
      "Epoch 35: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9149 - loss: 0.2060 - val_accuracy: 0.8750 - val_loss: 0.3077 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8845 - loss: 0.2498\n",
      "Epoch 36: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8850 - loss: 0.2500 - val_accuracy: 0.9167 - val_loss: 0.2175 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8989 - loss: 0.2499\n",
      "Epoch 37: val_accuracy improved from 0.91667 to 0.94167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8999 - loss: 0.2504 - val_accuracy: 0.9417 - val_loss: 0.2310 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9162 - loss: 0.2496\n",
      "Epoch 38: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9152 - loss: 0.2484 - val_accuracy: 0.9083 - val_loss: 0.2598 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8895 - loss: 0.2565\n",
      "Epoch 39: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8856 - loss: 0.2629 - val_accuracy: 0.9250 - val_loss: 0.2453 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8979 - loss: 0.2674\n",
      "Epoch 40: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8975 - loss: 0.2675 - val_accuracy: 0.9333 - val_loss: 0.1948 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9071 - loss: 0.2469\n",
      "Epoch 41: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9066 - loss: 0.2481 - val_accuracy: 0.8667 - val_loss: 0.2737 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9216 - loss: 0.2038\n",
      "Epoch 42: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9210 - loss: 0.2052 - val_accuracy: 0.8917 - val_loss: 0.2359 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9112 - loss: 0.2057\n",
      "Epoch 43: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9101 - loss: 0.2064 - val_accuracy: 0.9333 - val_loss: 0.1928 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9310 - loss: 0.1868\n",
      "Epoch 44: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9302 - loss: 0.1883 - val_accuracy: 0.9167 - val_loss: 0.2088 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9231 - loss: 0.2232\n",
      "Epoch 45: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9226 - loss: 0.2241 - val_accuracy: 0.8750 - val_loss: 0.2644 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8815 - loss: 0.2540\n",
      "Epoch 46: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8849 - loss: 0.2500 - val_accuracy: 0.9167 - val_loss: 0.1856 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9100 - loss: 0.2215\n",
      "Epoch 47: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9100 - loss: 0.2207 - val_accuracy: 0.9417 - val_loss: 0.2033 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9024 - loss: 0.2379\n",
      "Epoch 48: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9023 - loss: 0.2376 - val_accuracy: 0.9250 - val_loss: 0.2068 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9039 - loss: 0.2483\n",
      "Epoch 49: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9044 - loss: 0.2473 - val_accuracy: 0.9250 - val_loss: 0.2278 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9303 - loss: 0.1632\n",
      "Epoch 50: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9295 - loss: 0.1656 - val_accuracy: 0.9083 - val_loss: 0.2805 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9214 - loss: 0.2034\n",
      "Epoch 51: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9209 - loss: 0.2045 - val_accuracy: 0.9417 - val_loss: 0.1740 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9309 - loss: 0.2006\n",
      "Epoch 52: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9297 - loss: 0.2021 - val_accuracy: 0.9083 - val_loss: 0.2384 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9253 - loss: 0.1808\n",
      "Epoch 53: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9246 - loss: 0.1830 - val_accuracy: 0.9250 - val_loss: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9492 - loss: 0.1583\n",
      "Epoch 54: val_accuracy improved from 0.94167 to 0.95000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9481 - loss: 0.1600 - val_accuracy: 0.9500 - val_loss: 0.1836 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9180 - loss: 0.2221\n",
      "Epoch 55: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9155 - loss: 0.2241 - val_accuracy: 0.9417 - val_loss: 0.1712 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9277 - loss: 0.2126\n",
      "Epoch 56: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9265 - loss: 0.2132 - val_accuracy: 0.9083 - val_loss: 0.2108 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9000 - loss: 0.2410\n",
      "Epoch 57: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9023 - loss: 0.2385 - val_accuracy: 0.9083 - val_loss: 0.2446 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9251 - loss: 0.1996\n",
      "Epoch 58: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9254 - loss: 0.1993 - val_accuracy: 0.8917 - val_loss: 0.3489 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8808 - loss: 0.2412\n",
      "Epoch 59: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8834 - loss: 0.2378 - val_accuracy: 0.9000 - val_loss: 0.2948 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9404 - loss: 0.1781\n",
      "Epoch 60: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9402 - loss: 0.1783 - val_accuracy: 0.9167 - val_loss: 0.2820 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9151 - loss: 0.1915\n",
      "Epoch 61: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9153 - loss: 0.1911 - val_accuracy: 0.9333 - val_loss: 0.1819 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9330 - loss: 0.1773\n",
      "Epoch 62: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9329 - loss: 0.1777 - val_accuracy: 0.9167 - val_loss: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9250 - loss: 0.1665\n",
      "Epoch 63: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9250 - loss: 0.1685 - val_accuracy: 0.9083 - val_loss: 0.1964 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8988 - loss: 0.2329\n",
      "Epoch 64: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8988 - loss: 0.2334 - val_accuracy: 0.9083 - val_loss: 0.2625 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9129 - loss: 0.2351\n",
      "Epoch 65: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9120 - loss: 0.2359 - val_accuracy: 0.9083 - val_loss: 0.2571 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8824 - loss: 0.2906\n",
      "Epoch 66: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8841 - loss: 0.2845 - val_accuracy: 0.9417 - val_loss: 0.1673 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9058 - loss: 0.2078\n",
      "Epoch 67: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9067 - loss: 0.2060 - val_accuracy: 0.9250 - val_loss: 0.1824 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8970 - loss: 0.2485\n",
      "Epoch 68: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8976 - loss: 0.2466 - val_accuracy: 0.9000 - val_loss: 0.2894 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9043 - loss: 0.2089\n",
      "Epoch 69: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9045 - loss: 0.2085 - val_accuracy: 0.9083 - val_loss: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9339 - loss: 0.1497\n",
      "Epoch 70: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9343 - loss: 0.1500 - val_accuracy: 0.9417 - val_loss: 0.2017 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9271 - loss: 0.1723\n",
      "Epoch 71: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9267 - loss: 0.1732 - val_accuracy: 0.9250 - val_loss: 0.2029 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9305 - loss: 0.2026\n",
      "Epoch 72: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9301 - loss: 0.2033 - val_accuracy: 0.9250 - val_loss: 0.2235 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9289 - loss: 0.1940\n",
      "Epoch 73: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9275 - loss: 0.1958 - val_accuracy: 0.9083 - val_loss: 0.2311 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8943 - loss: 0.2547\n",
      "Epoch 74: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8968 - loss: 0.2495 - val_accuracy: 0.9250 - val_loss: 0.2290 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9042 - loss: 0.1937\n",
      "Epoch 75: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9043 - loss: 0.1950 - val_accuracy: 0.8167 - val_loss: 0.3525 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9383 - loss: 0.1582\n",
      "Epoch 76: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9353 - loss: 0.1623 - val_accuracy: 0.9417 - val_loss: 0.1853 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9491 - loss: 0.1361\n",
      "Epoch 77: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9477 - loss: 0.1384 - val_accuracy: 0.8833 - val_loss: 0.3194 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9006 - loss: 0.2197\n",
      "Epoch 78: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9034 - loss: 0.2173 - val_accuracy: 0.9000 - val_loss: 0.2830 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9200 - loss: 0.1784\n",
      "Epoch 79: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9204 - loss: 0.1771 - val_accuracy: 0.9417 - val_loss: 0.1568 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9144 - loss: 0.1985\n",
      "Epoch 80: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9141 - loss: 0.1980 - val_accuracy: 0.9167 - val_loss: 0.2035 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9363 - loss: 0.1621\n",
      "Epoch 81: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9362 - loss: 0.1625 - val_accuracy: 0.9333 - val_loss: 0.2263 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9111 - loss: 0.2138\n",
      "Epoch 82: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9114 - loss: 0.2132 - val_accuracy: 0.9417 - val_loss: 0.1596 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9506 - loss: 0.1228\n",
      "Epoch 83: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9504 - loss: 0.1234 - val_accuracy: 0.9333 - val_loss: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9519 - loss: 0.1304\n",
      "Epoch 84: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9482 - loss: 0.1402 - val_accuracy: 0.9250 - val_loss: 0.2133 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9387 - loss: 0.1905\n",
      "Epoch 85: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9383 - loss: 0.1897 - val_accuracy: 0.9000 - val_loss: 0.2580 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9379 - loss: 0.1636\n",
      "Epoch 86: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9370 - loss: 0.1646 - val_accuracy: 0.9167 - val_loss: 0.2710 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9416 - loss: 0.1342\n",
      "Epoch 87: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9415 - loss: 0.1349 - val_accuracy: 0.9167 - val_loss: 0.1764 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9520 - loss: 0.1532\n",
      "Epoch 88: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9515 - loss: 0.1543 - val_accuracy: 0.9083 - val_loss: 0.3077 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9161 - loss: 0.1827\n",
      "Epoch 89: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9157 - loss: 0.1838 - val_accuracy: 0.8833 - val_loss: 0.2889 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9249 - loss: 0.1800\n",
      "Epoch 90: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9255 - loss: 0.1796 - val_accuracy: 0.9417 - val_loss: 0.1587 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9326 - loss: 0.1577\n",
      "Epoch 91: val_accuracy improved from 0.95000 to 0.95833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9324 - loss: 0.1587 - val_accuracy: 0.9583 - val_loss: 0.1371 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9578 - loss: 0.1148\n",
      "Epoch 92: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9571 - loss: 0.1158 - val_accuracy: 0.9333 - val_loss: 0.2397 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9344 - loss: 0.1648\n",
      "Epoch 93: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9348 - loss: 0.1626 - val_accuracy: 0.9000 - val_loss: 0.3186 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9371 - loss: 0.1596\n",
      "Epoch 94: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9369 - loss: 0.1590 - val_accuracy: 0.8750 - val_loss: 0.4747 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9334 - loss: 0.1778\n",
      "Epoch 95: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9331 - loss: 0.1781 - val_accuracy: 0.9083 - val_loss: 0.1922 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9438 - loss: 0.1263\n",
      "Epoch 96: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9434 - loss: 0.1271 - val_accuracy: 0.9250 - val_loss: 0.2138 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9186 - loss: 0.1650\n",
      "Epoch 97: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9189 - loss: 0.1641 - val_accuracy: 0.9250 - val_loss: 0.2024 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9305 - loss: 0.1878\n",
      "Epoch 98: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9309 - loss: 0.1854 - val_accuracy: 0.9250 - val_loss: 0.2892 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9349 - loss: 0.1511\n",
      "Epoch 99: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9354 - loss: 0.1503 - val_accuracy: 0.9250 - val_loss: 0.2213 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9731 - loss: 0.0916\n",
      "Epoch 100: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9720 - loss: 0.0936 - val_accuracy: 0.9083 - val_loss: 0.2089 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9187 - loss: 0.2398\n",
      "Epoch 1/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3591 - loss: 3.0581\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.3618 - loss: 2.9459 - val_accuracy: 0.5083 - val_loss: 1.0094 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5903 - loss: 0.7811\n",
      "Epoch 2: val_accuracy improved from 0.50833 to 0.59167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.5946 - loss: 0.7747 - val_accuracy: 0.5917 - val_loss: 0.6465 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7707 - loss: 0.4727\n",
      "Epoch 3: val_accuracy improved from 0.59167 to 0.67500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7694 - loss: 0.4734 - val_accuracy: 0.6750 - val_loss: 0.5209 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7576 - loss: 0.4377\n",
      "Epoch 4: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7597 - loss: 0.4394 - val_accuracy: 0.6667 - val_loss: 0.5342 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7666 - loss: 0.4844\n",
      "Epoch 5: val_accuracy improved from 0.67500 to 0.73333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7678 - loss: 0.4825 - val_accuracy: 0.7333 - val_loss: 0.4855 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8426 - loss: 0.4037\n",
      "Epoch 6: val_accuracy improved from 0.73333 to 0.76667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8371 - loss: 0.4074 - val_accuracy: 0.7667 - val_loss: 0.4666 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8155 - loss: 0.3935\n",
      "Epoch 7: val_accuracy did not improve from 0.76667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8164 - loss: 0.3944 - val_accuracy: 0.7167 - val_loss: 0.4990 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8092 - loss: 0.4216\n",
      "Epoch 8: val_accuracy improved from 0.76667 to 0.81667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8080 - loss: 0.4243 - val_accuracy: 0.8167 - val_loss: 0.4835 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8527 - loss: 0.3803\n",
      "Epoch 9: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8518 - loss: 0.3782 - val_accuracy: 0.7917 - val_loss: 0.4119 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8694 - loss: 0.3029\n",
      "Epoch 10: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8684 - loss: 0.3048 - val_accuracy: 0.7667 - val_loss: 0.4740 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8659 - loss: 0.3111\n",
      "Epoch 11: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8666 - loss: 0.3096 - val_accuracy: 0.7083 - val_loss: 0.6583 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8175 - loss: 0.4342\n",
      "Epoch 12: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8172 - loss: 0.4310 - val_accuracy: 0.8083 - val_loss: 0.4829 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8219 - loss: 0.3920\n",
      "Epoch 13: val_accuracy did not improve from 0.81667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8234 - loss: 0.3902 - val_accuracy: 0.7917 - val_loss: 0.4372 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8551 - loss: 0.3344\n",
      "Epoch 14: val_accuracy improved from 0.81667 to 0.82500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8556 - loss: 0.3342 - val_accuracy: 0.8250 - val_loss: 0.3927 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8676 - loss: 0.3204\n",
      "Epoch 15: val_accuracy did not improve from 0.82500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8696 - loss: 0.3156 - val_accuracy: 0.8083 - val_loss: 0.3757 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8757 - loss: 0.2942\n",
      "Epoch 16: val_accuracy did not improve from 0.82500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8782 - loss: 0.2887 - val_accuracy: 0.7917 - val_loss: 0.4395 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8835 - loss: 0.2690\n",
      "Epoch 17: val_accuracy improved from 0.82500 to 0.85000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8858 - loss: 0.2656 - val_accuracy: 0.8500 - val_loss: 0.3418 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9219 - loss: 0.1976\n",
      "Epoch 18: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9202 - loss: 0.2004 - val_accuracy: 0.8333 - val_loss: 0.3298 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9018 - loss: 0.2464\n",
      "Epoch 19: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9015 - loss: 0.2468 - val_accuracy: 0.8417 - val_loss: 0.3021 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8814 - loss: 0.2608\n",
      "Epoch 20: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8822 - loss: 0.2593 - val_accuracy: 0.8250 - val_loss: 0.4407 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9011 - loss: 0.2481\n",
      "Epoch 21: val_accuracy did not improve from 0.85000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9013 - loss: 0.2473 - val_accuracy: 0.8250 - val_loss: 0.4156 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8850 - loss: 0.2393\n",
      "Epoch 22: val_accuracy improved from 0.85000 to 0.87500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8866 - loss: 0.2382 - val_accuracy: 0.8750 - val_loss: 0.3180 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8919 - loss: 0.2476\n",
      "Epoch 23: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8925 - loss: 0.2465 - val_accuracy: 0.8500 - val_loss: 0.3019 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8714 - loss: 0.3010\n",
      "Epoch 24: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8714 - loss: 0.3009 - val_accuracy: 0.8500 - val_loss: 0.3445 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9161 - loss: 0.2184\n",
      "Epoch 25: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9164 - loss: 0.2175 - val_accuracy: 0.8667 - val_loss: 0.3001 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9404 - loss: 0.1749\n",
      "Epoch 26: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9375 - loss: 0.1798 - val_accuracy: 0.8583 - val_loss: 0.3119 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9166 - loss: 0.2196\n",
      "Epoch 27: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9148 - loss: 0.2240 - val_accuracy: 0.8500 - val_loss: 0.3332 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9103 - loss: 0.2509\n",
      "Epoch 28: val_accuracy improved from 0.87500 to 0.88333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9096 - loss: 0.2504 - val_accuracy: 0.8833 - val_loss: 0.2878 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9075 - loss: 0.2260\n",
      "Epoch 29: val_accuracy improved from 0.88333 to 0.89167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9074 - loss: 0.2259 - val_accuracy: 0.8917 - val_loss: 0.2574 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8764 - loss: 0.2945\n",
      "Epoch 30: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8772 - loss: 0.2922 - val_accuracy: 0.8667 - val_loss: 0.3117 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8997 - loss: 0.2106\n",
      "Epoch 31: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9010 - loss: 0.2103 - val_accuracy: 0.8250 - val_loss: 0.4005 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9244 - loss: 0.1986\n",
      "Epoch 32: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9237 - loss: 0.1995 - val_accuracy: 0.8667 - val_loss: 0.2930 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9489 - loss: 0.1578\n",
      "Epoch 33: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9476 - loss: 0.1596 - val_accuracy: 0.8583 - val_loss: 0.3437 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9214 - loss: 0.1980\n",
      "Epoch 34: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9205 - loss: 0.1999 - val_accuracy: 0.8167 - val_loss: 0.3958 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9246 - loss: 0.1644\n",
      "Epoch 35: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9242 - loss: 0.1674 - val_accuracy: 0.8417 - val_loss: 0.4028 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9243 - loss: 0.1794\n",
      "Epoch 36: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9241 - loss: 0.1818 - val_accuracy: 0.8917 - val_loss: 0.2511 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9057 - loss: 0.2200\n",
      "Epoch 37: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9060 - loss: 0.2215 - val_accuracy: 0.6833 - val_loss: 0.6599 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8846 - loss: 0.2688\n",
      "Epoch 38: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8865 - loss: 0.2666 - val_accuracy: 0.8250 - val_loss: 0.4271 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8929 - loss: 0.2427\n",
      "Epoch 39: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8933 - loss: 0.2417 - val_accuracy: 0.8750 - val_loss: 0.3211 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9109 - loss: 0.2232\n",
      "Epoch 40: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9116 - loss: 0.2221 - val_accuracy: 0.8583 - val_loss: 0.2729 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9147 - loss: 0.2071\n",
      "Epoch 41: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9152 - loss: 0.2048 - val_accuracy: 0.8583 - val_loss: 0.2877 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9283 - loss: 0.1711\n",
      "Epoch 42: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9279 - loss: 0.1730 - val_accuracy: 0.8333 - val_loss: 0.4019 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9449 - loss: 0.1488\n",
      "Epoch 43: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9445 - loss: 0.1507 - val_accuracy: 0.8750 - val_loss: 0.2909 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9263 - loss: 0.1780\n",
      "Epoch 44: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9268 - loss: 0.1776 - val_accuracy: 0.8417 - val_loss: 0.3360 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9420 - loss: 0.1582\n",
      "Epoch 45: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9414 - loss: 0.1590 - val_accuracy: 0.8500 - val_loss: 0.3203 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9189 - loss: 0.2128\n",
      "Epoch 46: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9202 - loss: 0.2076 - val_accuracy: 0.8167 - val_loss: 0.3736 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9456 - loss: 0.1508\n",
      "Epoch 47: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9438 - loss: 0.1539 - val_accuracy: 0.8750 - val_loss: 0.2628 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9331 - loss: 0.1543\n",
      "Epoch 48: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9328 - loss: 0.1552 - val_accuracy: 0.8500 - val_loss: 0.3813 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9335 - loss: 0.1737\n",
      "Epoch 49: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9334 - loss: 0.1742 - val_accuracy: 0.8250 - val_loss: 0.4514 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9258 - loss: 0.2053\n",
      "Epoch 50: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9249 - loss: 0.2098 - val_accuracy: 0.8667 - val_loss: 0.3497 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8771 - loss: 0.3664\n",
      "Epoch 51: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8792 - loss: 0.3597 - val_accuracy: 0.8417 - val_loss: 0.3120 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9060 - loss: 0.2476\n",
      "Epoch 52: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9058 - loss: 0.2475 - val_accuracy: 0.8833 - val_loss: 0.3055 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9142 - loss: 0.1936\n",
      "Epoch 53: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9143 - loss: 0.1948 - val_accuracy: 0.7667 - val_loss: 0.5452 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.2125\n",
      "Epoch 54: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9099 - loss: 0.2117 - val_accuracy: 0.8250 - val_loss: 0.4129 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9193 - loss: 0.1711\n",
      "Epoch 55: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9198 - loss: 0.1717 - val_accuracy: 0.8500 - val_loss: 0.3463 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9533 - loss: 0.1513\n",
      "Epoch 56: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9518 - loss: 0.1538 - val_accuracy: 0.8083 - val_loss: 0.4063 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9338 - loss: 0.1840\n",
      "Epoch 57: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9330 - loss: 0.1851 - val_accuracy: 0.8583 - val_loss: 0.3140 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9595 - loss: 0.1285\n",
      "Epoch 58: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9567 - loss: 0.1342 - val_accuracy: 0.8500 - val_loss: 0.3262 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9354 - loss: 0.1653\n",
      "Epoch 59: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9356 - loss: 0.1661 - val_accuracy: 0.8417 - val_loss: 0.3447 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9228 - loss: 0.1891\n",
      "Epoch 60: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9228 - loss: 0.1891 - val_accuracy: 0.8083 - val_loss: 0.3746 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9330 - loss: 0.2098\n",
      "Epoch 61: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9334 - loss: 0.2086 - val_accuracy: 0.8417 - val_loss: 0.3056 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9472 - loss: 0.1600\n",
      "Epoch 62: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9455 - loss: 0.1622 - val_accuracy: 0.8500 - val_loss: 0.3231 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9259 - loss: 0.1680\n",
      "Epoch 63: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9261 - loss: 0.1687 - val_accuracy: 0.8500 - val_loss: 0.2997 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9284 - loss: 0.2011\n",
      "Epoch 64: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9291 - loss: 0.1994 - val_accuracy: 0.8417 - val_loss: 0.3570 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9207 - loss: 0.1761\n",
      "Epoch 65: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9215 - loss: 0.1756 - val_accuracy: 0.8250 - val_loss: 0.3318 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9322 - loss: 0.1749\n",
      "Epoch 66: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9316 - loss: 0.1752 - val_accuracy: 0.8250 - val_loss: 0.3914 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9421 - loss: 0.1539\n",
      "Epoch 67: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9416 - loss: 0.1542 - val_accuracy: 0.8667 - val_loss: 0.3178 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9470 - loss: 0.1751\n",
      "Epoch 68: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9466 - loss: 0.1757 - val_accuracy: 0.8333 - val_loss: 0.3578 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9249 - loss: 0.1991\n",
      "Epoch 69: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9262 - loss: 0.1963 - val_accuracy: 0.8250 - val_loss: 0.4029 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9434 - loss: 0.1585\n",
      "Epoch 70: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9419 - loss: 0.1580 - val_accuracy: 0.8583 - val_loss: 0.3100 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9217 - loss: 0.2141\n",
      "Epoch 71: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9223 - loss: 0.2121 - val_accuracy: 0.8583 - val_loss: 0.3527 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9366 - loss: 0.1874\n",
      "Epoch 72: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9359 - loss: 0.1851 - val_accuracy: 0.8250 - val_loss: 0.3429 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9183 - loss: 0.1931\n",
      "Epoch 73: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9195 - loss: 0.1918 - val_accuracy: 0.7833 - val_loss: 0.4491 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9546 - loss: 0.1374\n",
      "Epoch 74: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9540 - loss: 0.1375 - val_accuracy: 0.8500 - val_loss: 0.3711 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9282 - loss: 0.2532\n",
      "Epoch 75: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9275 - loss: 0.2479 - val_accuracy: 0.8417 - val_loss: 0.3732 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9176 - loss: 0.1969\n",
      "Epoch 76: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9184 - loss: 0.1955 - val_accuracy: 0.8333 - val_loss: 0.4093 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9258 - loss: 0.1863\n",
      "Epoch 77: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9270 - loss: 0.1855 - val_accuracy: 0.7833 - val_loss: 0.5417 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9447 - loss: 0.1456\n",
      "Epoch 78: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9445 - loss: 0.1458 - val_accuracy: 0.8167 - val_loss: 0.4704 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9384 - loss: 0.1766\n",
      "Epoch 79: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9388 - loss: 0.1758 - val_accuracy: 0.7917 - val_loss: 0.5280 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9238 - loss: 0.1866\n",
      "Epoch 80: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9248 - loss: 0.1854 - val_accuracy: 0.8417 - val_loss: 0.4043 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9366 - loss: 0.1467\n",
      "Epoch 81: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9367 - loss: 0.1470 - val_accuracy: 0.8083 - val_loss: 0.4676 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9283 - loss: 0.1725\n",
      "Epoch 82: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9283 - loss: 0.1722 - val_accuracy: 0.8167 - val_loss: 0.4063 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9348 - loss: 0.1610\n",
      "Epoch 83: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9355 - loss: 0.1594 - val_accuracy: 0.7583 - val_loss: 0.5108 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9411 - loss: 0.1502\n",
      "Epoch 84: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9411 - loss: 0.1498 - val_accuracy: 0.8833 - val_loss: 0.2593 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9437 - loss: 0.1525\n",
      "Epoch 85: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9437 - loss: 0.1525 - val_accuracy: 0.7667 - val_loss: 0.5712 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9139 - loss: 0.1913\n",
      "Epoch 86: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9146 - loss: 0.1904 - val_accuracy: 0.8667 - val_loss: 0.2772 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9406 - loss: 0.1622\n",
      "Epoch 87: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9400 - loss: 0.1630 - val_accuracy: 0.7000 - val_loss: 0.6696 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9301 - loss: 0.1636\n",
      "Epoch 88: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9305 - loss: 0.1629 - val_accuracy: 0.8500 - val_loss: 0.4742 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9599 - loss: 0.1065\n",
      "Epoch 89: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9585 - loss: 0.1086 - val_accuracy: 0.8333 - val_loss: 0.4716 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9322 - loss: 0.1832\n",
      "Epoch 90: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9321 - loss: 0.1824 - val_accuracy: 0.7833 - val_loss: 0.4865 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8942 - loss: 0.3381\n",
      "Epoch 91: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8907 - loss: 0.3417 - val_accuracy: 0.8167 - val_loss: 0.4398 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9056 - loss: 0.2529\n",
      "Epoch 92: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9066 - loss: 0.2506 - val_accuracy: 0.8667 - val_loss: 0.2933 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9201 - loss: 0.1908\n",
      "Epoch 93: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9212 - loss: 0.1881 - val_accuracy: 0.8750 - val_loss: 0.3755 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9233 - loss: 0.1806\n",
      "Epoch 94: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9245 - loss: 0.1785 - val_accuracy: 0.8500 - val_loss: 0.3443 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9461 - loss: 0.1382\n",
      "Epoch 95: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9465 - loss: 0.1389 - val_accuracy: 0.8750 - val_loss: 0.3057 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9502 - loss: 0.1678\n",
      "Epoch 96: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9505 - loss: 0.1648 - val_accuracy: 0.8083 - val_loss: 0.3778 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9551 - loss: 0.1046\n",
      "Epoch 97: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9546 - loss: 0.1052 - val_accuracy: 0.8583 - val_loss: 0.3121 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9461 - loss: 0.1379\n",
      "Epoch 98: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9456 - loss: 0.1390 - val_accuracy: 0.7750 - val_loss: 0.5928 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9374 - loss: 0.1892\n",
      "Epoch 99: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9374 - loss: 0.1889 - val_accuracy: 0.7417 - val_loss: 0.5258 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9119 - loss: 0.2261\n",
      "Epoch 100: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9156 - loss: 0.2183 - val_accuracy: 0.8417 - val_loss: 0.3961 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8456 - loss: 0.4062\n",
      "Epoch 1/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3608 - loss: 2.8483\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.3774 - loss: 2.7155 - val_accuracy: 0.5500 - val_loss: 0.6831 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6763 - loss: 0.5774\n",
      "Epoch 2: val_accuracy improved from 0.55000 to 0.72500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6761 - loss: 0.5763 - val_accuracy: 0.7250 - val_loss: 0.5390 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7174 - loss: 0.5273\n",
      "Epoch 3: val_accuracy improved from 0.72500 to 0.77500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7184 - loss: 0.5255 - val_accuracy: 0.7750 - val_loss: 0.4623 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8247 - loss: 0.4447\n",
      "Epoch 4: val_accuracy improved from 0.77500 to 0.84167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8241 - loss: 0.4443 - val_accuracy: 0.8417 - val_loss: 0.3844 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8499 - loss: 0.3946\n",
      "Epoch 5: val_accuracy improved from 0.84167 to 0.87500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8495 - loss: 0.3935 - val_accuracy: 0.8750 - val_loss: 0.3368 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7404 - loss: 0.5456\n",
      "Epoch 6: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7385 - loss: 0.5427 - val_accuracy: 0.7833 - val_loss: 0.4481 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7607 - loss: 0.4768\n",
      "Epoch 7: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7658 - loss: 0.4718 - val_accuracy: 0.8083 - val_loss: 0.3854 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8953 - loss: 0.3503\n",
      "Epoch 8: val_accuracy improved from 0.87500 to 0.89167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8915 - loss: 0.3519 - val_accuracy: 0.8917 - val_loss: 0.3211 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8482 - loss: 0.3290\n",
      "Epoch 9: val_accuracy improved from 0.89167 to 0.90000, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8487 - loss: 0.3315 - val_accuracy: 0.9000 - val_loss: 0.3000 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8463 - loss: 0.3455\n",
      "Epoch 10: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8466 - loss: 0.3450 - val_accuracy: 0.8667 - val_loss: 0.3315 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8264 - loss: 0.3558\n",
      "Epoch 11: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8270 - loss: 0.3568 - val_accuracy: 0.8500 - val_loss: 0.3760 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8825 - loss: 0.3098\n",
      "Epoch 12: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8818 - loss: 0.3102 - val_accuracy: 0.9000 - val_loss: 0.2709 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8510 - loss: 0.3514\n",
      "Epoch 13: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8506 - loss: 0.3510 - val_accuracy: 0.8833 - val_loss: 0.3086 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9016 - loss: 0.2785\n",
      "Epoch 14: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9014 - loss: 0.2791 - val_accuracy: 0.8500 - val_loss: 0.3011 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9152 - loss: 0.2354\n",
      "Epoch 15: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9115 - loss: 0.2440 - val_accuracy: 0.8500 - val_loss: 0.3786 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8857 - loss: 0.2649\n",
      "Epoch 16: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8841 - loss: 0.2671 - val_accuracy: 0.8917 - val_loss: 0.2554 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8703 - loss: 0.2963\n",
      "Epoch 17: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8694 - loss: 0.2970 - val_accuracy: 0.8417 - val_loss: 0.3614 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8730 - loss: 0.2498\n",
      "Epoch 18: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8750 - loss: 0.2480 - val_accuracy: 0.8917 - val_loss: 0.2646 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8863 - loss: 0.3149\n",
      "Epoch 19: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8877 - loss: 0.3109 - val_accuracy: 0.8667 - val_loss: 0.2847 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9071 - loss: 0.2351\n",
      "Epoch 20: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9078 - loss: 0.2329 - val_accuracy: 0.9000 - val_loss: 0.2550 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9059 - loss: 0.2217\n",
      "Epoch 21: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9075 - loss: 0.2199 - val_accuracy: 0.9000 - val_loss: 0.2278 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9088 - loss: 0.2308\n",
      "Epoch 22: val_accuracy improved from 0.90000 to 0.90833, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9087 - loss: 0.2307 - val_accuracy: 0.9083 - val_loss: 0.2743 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8841 - loss: 0.2846\n",
      "Epoch 23: val_accuracy improved from 0.90833 to 0.91667, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8850 - loss: 0.2830 - val_accuracy: 0.9167 - val_loss: 0.2192 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9266 - loss: 0.1923\n",
      "Epoch 24: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9256 - loss: 0.1940 - val_accuracy: 0.8333 - val_loss: 0.3644 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9275 - loss: 0.1892\n",
      "Epoch 25: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9272 - loss: 0.1901 - val_accuracy: 0.9000 - val_loss: 0.2581 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9095 - loss: 0.2042\n",
      "Epoch 26: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9083 - loss: 0.2064 - val_accuracy: 0.8833 - val_loss: 0.2329 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8927 - loss: 0.2722\n",
      "Epoch 27: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8939 - loss: 0.2701 - val_accuracy: 0.8917 - val_loss: 0.2731 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8983 - loss: 0.2105\n",
      "Epoch 28: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8992 - loss: 0.2105 - val_accuracy: 0.8750 - val_loss: 0.3153 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9017 - loss: 0.2370\n",
      "Epoch 29: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9015 - loss: 0.2376 - val_accuracy: 0.9083 - val_loss: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9209 - loss: 0.1947\n",
      "Epoch 30: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9201 - loss: 0.1962 - val_accuracy: 0.9083 - val_loss: 0.2345 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9260 - loss: 0.1861\n",
      "Epoch 31: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9250 - loss: 0.1884 - val_accuracy: 0.8667 - val_loss: 0.2709 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9205 - loss: 0.1689\n",
      "Epoch 32: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9202 - loss: 0.1696 - val_accuracy: 0.8917 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8815 - loss: 0.2580\n",
      "Epoch 33: val_accuracy improved from 0.91667 to 0.92500, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8823 - loss: 0.2562 - val_accuracy: 0.9250 - val_loss: 0.2235 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9009 - loss: 0.2403\n",
      "Epoch 34: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9039 - loss: 0.2368 - val_accuracy: 0.8667 - val_loss: 0.3187 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9193 - loss: 0.2166\n",
      "Epoch 35: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9197 - loss: 0.2153 - val_accuracy: 0.8750 - val_loss: 0.2860 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9119 - loss: 0.2161\n",
      "Epoch 36: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9125 - loss: 0.2156 - val_accuracy: 0.8667 - val_loss: 0.3001 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9405 - loss: 0.1629\n",
      "Epoch 37: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9401 - loss: 0.1634 - val_accuracy: 0.8917 - val_loss: 0.2396 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9306 - loss: 0.2012\n",
      "Epoch 38: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9307 - loss: 0.1990 - val_accuracy: 0.9000 - val_loss: 0.2086 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9016 - loss: 0.2134\n",
      "Epoch 39: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9030 - loss: 0.2120 - val_accuracy: 0.8917 - val_loss: 0.2636 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9104 - loss: 0.2126\n",
      "Epoch 40: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9099 - loss: 0.2128 - val_accuracy: 0.9167 - val_loss: 0.2120 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9198 - loss: 0.2036\n",
      "Epoch 41: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9194 - loss: 0.2043 - val_accuracy: 0.9083 - val_loss: 0.2528 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9216 - loss: 0.2188\n",
      "Epoch 42: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9215 - loss: 0.2180 - val_accuracy: 0.8833 - val_loss: 0.2499 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9326 - loss: 0.1856\n",
      "Epoch 43: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9335 - loss: 0.1843 - val_accuracy: 0.9000 - val_loss: 0.2993 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9266 - loss: 0.1754\n",
      "Epoch 44: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9269 - loss: 0.1758 - val_accuracy: 0.8500 - val_loss: 0.3253 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9122 - loss: 0.1904\n",
      "Epoch 45: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9130 - loss: 0.1908 - val_accuracy: 0.9167 - val_loss: 0.2277 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8973 - loss: 0.2299\n",
      "Epoch 46: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8981 - loss: 0.2283 - val_accuracy: 0.9000 - val_loss: 0.1792 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9297 - loss: 0.1921\n",
      "Epoch 47: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9299 - loss: 0.1901 - val_accuracy: 0.9083 - val_loss: 0.2649 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9266 - loss: 0.1692\n",
      "Epoch 48: val_accuracy improved from 0.92500 to 0.93333, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9262 - loss: 0.1695 - val_accuracy: 0.9333 - val_loss: 0.1813 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9122 - loss: 0.1919\n",
      "Epoch 49: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9128 - loss: 0.1917 - val_accuracy: 0.9000 - val_loss: 0.2222 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9341 - loss: 0.1804\n",
      "Epoch 50: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9339 - loss: 0.1802 - val_accuracy: 0.8833 - val_loss: 0.2476 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9514 - loss: 0.1494\n",
      "Epoch 51: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9499 - loss: 0.1510 - val_accuracy: 0.9083 - val_loss: 0.2233 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9458 - loss: 0.1464\n",
      "Epoch 52: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9453 - loss: 0.1477 - val_accuracy: 0.9000 - val_loss: 0.2282 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9368 - loss: 0.1827\n",
      "Epoch 53: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9353 - loss: 0.1839 - val_accuracy: 0.8667 - val_loss: 0.3529 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9038 - loss: 0.2406\n",
      "Epoch 54: val_accuracy did not improve from 0.93333\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9037 - loss: 0.2403 - val_accuracy: 0.8917 - val_loss: 0.2570 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9229 - loss: 0.1909\n",
      "Epoch 55: val_accuracy improved from 0.93333 to 0.94167, saving model to saved_models/best_model_fold.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9216 - loss: 0.1945 - val_accuracy: 0.9417 - val_loss: 0.1754 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9286 - loss: 0.1761\n",
      "Epoch 56: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9287 - loss: 0.1761 - val_accuracy: 0.9167 - val_loss: 0.2106 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9207 - loss: 0.2159\n",
      "Epoch 57: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9192 - loss: 0.2178 - val_accuracy: 0.9167 - val_loss: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9061 - loss: 0.2128\n",
      "Epoch 58: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9059 - loss: 0.2140 - val_accuracy: 0.9000 - val_loss: 0.2440 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9544 - loss: 0.1412\n",
      "Epoch 59: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9523 - loss: 0.1432 - val_accuracy: 0.9167 - val_loss: 0.2093 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9172 - loss: 0.1727\n",
      "Epoch 60: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9171 - loss: 0.1734 - val_accuracy: 0.9083 - val_loss: 0.2011 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9447 - loss: 0.1386\n",
      "Epoch 61: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9430 - loss: 0.1417 - val_accuracy: 0.9167 - val_loss: 0.2147 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9448 - loss: 0.1384\n",
      "Epoch 62: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9443 - loss: 0.1401 - val_accuracy: 0.9250 - val_loss: 0.2484 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9251 - loss: 0.1891\n",
      "Epoch 63: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9248 - loss: 0.1885 - val_accuracy: 0.8750 - val_loss: 0.3497 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9127 - loss: 0.1887\n",
      "Epoch 64: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9133 - loss: 0.1875 - val_accuracy: 0.9083 - val_loss: 0.2398 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9279 - loss: 0.1795\n",
      "Epoch 65: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9283 - loss: 0.1794 - val_accuracy: 0.8833 - val_loss: 0.2954 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9179 - loss: 0.1695\n",
      "Epoch 66: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9172 - loss: 0.1723 - val_accuracy: 0.8750 - val_loss: 0.2494 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9191 - loss: 0.2040\n",
      "Epoch 67: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9204 - loss: 0.2020 - val_accuracy: 0.9167 - val_loss: 0.2434 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9243 - loss: 0.1955\n",
      "Epoch 68: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9242 - loss: 0.1942 - val_accuracy: 0.8750 - val_loss: 0.3404 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9278 - loss: 0.1807\n",
      "Epoch 69: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9275 - loss: 0.1798 - val_accuracy: 0.8833 - val_loss: 0.3953 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9132 - loss: 0.2098\n",
      "Epoch 70: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9135 - loss: 0.2094 - val_accuracy: 0.8500 - val_loss: 0.3711 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9343 - loss: 0.1559\n",
      "Epoch 71: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9346 - loss: 0.1561 - val_accuracy: 0.9167 - val_loss: 0.2116 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9374 - loss: 0.1457\n",
      "Epoch 72: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9366 - loss: 0.1495 - val_accuracy: 0.8917 - val_loss: 0.2089 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9491 - loss: 0.1416\n",
      "Epoch 73: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9482 - loss: 0.1427 - val_accuracy: 0.9000 - val_loss: 0.1963 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9294 - loss: 0.1594\n",
      "Epoch 74: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9307 - loss: 0.1577 - val_accuracy: 0.9417 - val_loss: 0.2026 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9374 - loss: 0.1314\n",
      "Epoch 75: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9380 - loss: 0.1325 - val_accuracy: 0.9083 - val_loss: 0.2011 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9261 - loss: 0.1730\n",
      "Epoch 76: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9257 - loss: 0.1731 - val_accuracy: 0.8917 - val_loss: 0.2393 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9249 - loss: 0.1587\n",
      "Epoch 77: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9246 - loss: 0.1588 - val_accuracy: 0.9000 - val_loss: 0.2214 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9094 - loss: 0.2077\n",
      "Epoch 78: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9096 - loss: 0.2079 - val_accuracy: 0.9333 - val_loss: 0.1933 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9477 - loss: 0.1486\n",
      "Epoch 79: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9475 - loss: 0.1489 - val_accuracy: 0.8917 - val_loss: 0.2805 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9208 - loss: 0.1636\n",
      "Epoch 80: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9229 - loss: 0.1625 - val_accuracy: 0.9167 - val_loss: 0.1904 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9211 - loss: 0.1596\n",
      "Epoch 81: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9237 - loss: 0.1572 - val_accuracy: 0.8833 - val_loss: 0.2682 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9442 - loss: 0.1392\n",
      "Epoch 82: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9436 - loss: 0.1402 - val_accuracy: 0.9250 - val_loss: 0.2505 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9344 - loss: 0.1586\n",
      "Epoch 83: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9344 - loss: 0.1588 - val_accuracy: 0.9000 - val_loss: 0.2043 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9347 - loss: 0.1505\n",
      "Epoch 84: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9340 - loss: 0.1514 - val_accuracy: 0.9167 - val_loss: 0.2036 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9323 - loss: 0.1823\n",
      "Epoch 85: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9324 - loss: 0.1816 - val_accuracy: 0.9167 - val_loss: 0.2215 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9528 - loss: 0.1356\n",
      "Epoch 86: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9509 - loss: 0.1370 - val_accuracy: 0.8833 - val_loss: 0.2992 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9227 - loss: 0.1916\n",
      "Epoch 87: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9235 - loss: 0.1892 - val_accuracy: 0.9083 - val_loss: 0.2230 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9363 - loss: 0.1368\n",
      "Epoch 88: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9375 - loss: 0.1363 - val_accuracy: 0.9000 - val_loss: 0.2492 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9478 - loss: 0.1441\n",
      "Epoch 89: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9480 - loss: 0.1433 - val_accuracy: 0.9250 - val_loss: 0.2147 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9491 - loss: 0.1338\n",
      "Epoch 90: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9492 - loss: 0.1336 - val_accuracy: 0.9083 - val_loss: 0.2186 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9449 - loss: 0.1418\n",
      "Epoch 91: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9451 - loss: 0.1411 - val_accuracy: 0.9083 - val_loss: 0.2256 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9390 - loss: 0.1411\n",
      "Epoch 92: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9391 - loss: 0.1423 - val_accuracy: 0.9083 - val_loss: 0.2525 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9281 - loss: 0.1591\n",
      "Epoch 93: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9287 - loss: 0.1578 - val_accuracy: 0.9167 - val_loss: 0.1973 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9530 - loss: 0.1227\n",
      "Epoch 94: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9521 - loss: 0.1235 - val_accuracy: 0.9417 - val_loss: 0.2297 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9472 - loss: 0.1361\n",
      "Epoch 95: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9486 - loss: 0.1348 - val_accuracy: 0.9167 - val_loss: 0.2308 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9628 - loss: 0.1100\n",
      "Epoch 96: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9630 - loss: 0.1088 - val_accuracy: 0.9000 - val_loss: 0.3193 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9496 - loss: 0.1554\n",
      "Epoch 97: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9494 - loss: 0.1536 - val_accuracy: 0.9417 - val_loss: 0.1879 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9551 - loss: 0.1139\n",
      "Epoch 98: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9547 - loss: 0.1158 - val_accuracy: 0.9333 - val_loss: 0.1754 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.2125\n",
      "Epoch 99: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9096 - loss: 0.2133 - val_accuracy: 0.9167 - val_loss: 0.2269 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9420 - loss: 0.1419\n",
      "Epoch 100: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9420 - loss: 0.1429 - val_accuracy: 0.9250 - val_loss: 0.2132 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9010 - loss: 0.2378\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3619 - loss: 10.5933\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53333, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.3626 - loss: 10.3399 - val_accuracy: 0.5333 - val_loss: 1.0370 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6091 - loss: 0.9412\n",
      "Epoch 2: val_accuracy improved from 0.53333 to 0.60000, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6130 - loss: 0.9274 - val_accuracy: 0.6000 - val_loss: 0.8754 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6734 - loss: 0.6251\n",
      "Epoch 3: val_accuracy improved from 0.60000 to 0.63333, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6751 - loss: 0.6229 - val_accuracy: 0.6333 - val_loss: 0.6346 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6929 - loss: 0.5534\n",
      "Epoch 4: val_accuracy improved from 0.63333 to 0.71667, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6948 - loss: 0.5505 - val_accuracy: 0.7167 - val_loss: 0.4911 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7355 - loss: 0.4898\n",
      "Epoch 5: val_accuracy did not improve from 0.71667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7345 - loss: 0.4944 - val_accuracy: 0.4750 - val_loss: 0.7475 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6920 - loss: 0.5369\n",
      "Epoch 6: val_accuracy improved from 0.71667 to 0.79167, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6938 - loss: 0.5362 - val_accuracy: 0.7917 - val_loss: 0.4578 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7149 - loss: 0.5028\n",
      "Epoch 7: val_accuracy improved from 0.79167 to 0.80000, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7172 - loss: 0.5007 - val_accuracy: 0.8000 - val_loss: 0.4536 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7739 - loss: 0.4661\n",
      "Epoch 8: val_accuracy did not improve from 0.80000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7743 - loss: 0.4649 - val_accuracy: 0.7333 - val_loss: 0.4925 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7730 - loss: 0.4490\n",
      "Epoch 9: val_accuracy improved from 0.80000 to 0.84167, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7734 - loss: 0.4492 - val_accuracy: 0.8417 - val_loss: 0.4153 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8278 - loss: 0.4004\n",
      "Epoch 10: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8259 - loss: 0.4013 - val_accuracy: 0.6750 - val_loss: 0.5811 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7843 - loss: 0.4490\n",
      "Epoch 11: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7857 - loss: 0.4472 - val_accuracy: 0.8000 - val_loss: 0.4481 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8434 - loss: 0.3706\n",
      "Epoch 12: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8437 - loss: 0.3702 - val_accuracy: 0.8417 - val_loss: 0.3316 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8469 - loss: 0.3503\n",
      "Epoch 13: val_accuracy did not improve from 0.84167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8455 - loss: 0.3525 - val_accuracy: 0.7750 - val_loss: 0.4668 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8055 - loss: 0.4175\n",
      "Epoch 14: val_accuracy improved from 0.84167 to 0.89167, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8074 - loss: 0.4150 - val_accuracy: 0.8917 - val_loss: 0.3118 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8310 - loss: 0.3834\n",
      "Epoch 15: val_accuracy improved from 0.89167 to 0.90000, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.8322 - loss: 0.3824 - val_accuracy: 0.9000 - val_loss: 0.3297 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8513 - loss: 0.3456\n",
      "Epoch 16: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8514 - loss: 0.3447 - val_accuracy: 0.8583 - val_loss: 0.3269 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8469 - loss: 0.3284\n",
      "Epoch 17: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8471 - loss: 0.3283 - val_accuracy: 0.8750 - val_loss: 0.3155 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8512 - loss: 0.3590\n",
      "Epoch 18: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8517 - loss: 0.3575 - val_accuracy: 0.8833 - val_loss: 0.2889 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8857 - loss: 0.2598\n",
      "Epoch 19: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8843 - loss: 0.2645 - val_accuracy: 0.8167 - val_loss: 0.4173 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8126 - loss: 0.3775\n",
      "Epoch 20: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8139 - loss: 0.3761 - val_accuracy: 0.8250 - val_loss: 0.4103 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8830 - loss: 0.3026\n",
      "Epoch 21: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8789 - loss: 0.3096 - val_accuracy: 0.8667 - val_loss: 0.3536 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8619 - loss: 0.3587\n",
      "Epoch 22: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8614 - loss: 0.3597 - val_accuracy: 0.9000 - val_loss: 0.2891 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8466 - loss: 0.3951\n",
      "Epoch 23: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8481 - loss: 0.3918 - val_accuracy: 0.8833 - val_loss: 0.2931 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8517 - loss: 0.2975\n",
      "Epoch 24: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8538 - loss: 0.2957 - val_accuracy: 0.9000 - val_loss: 0.2861 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8643 - loss: 0.2671\n",
      "Epoch 25: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8652 - loss: 0.2667 - val_accuracy: 0.9000 - val_loss: 0.2636 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8721 - loss: 0.2882\n",
      "Epoch 26: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8730 - loss: 0.2870 - val_accuracy: 0.9000 - val_loss: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8733 - loss: 0.2936\n",
      "Epoch 27: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8738 - loss: 0.2932 - val_accuracy: 0.8583 - val_loss: 0.3105 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8486 - loss: 0.3379\n",
      "Epoch 28: val_accuracy did not improve from 0.90000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8494 - loss: 0.3362 - val_accuracy: 0.8833 - val_loss: 0.2716 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8831 - loss: 0.2663\n",
      "Epoch 29: val_accuracy improved from 0.90000 to 0.91667, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8826 - loss: 0.2673 - val_accuracy: 0.9167 - val_loss: 0.2814 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9210 - loss: 0.2349\n",
      "Epoch 30: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9208 - loss: 0.2354 - val_accuracy: 0.8500 - val_loss: 0.3664 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8711 - loss: 0.3055\n",
      "Epoch 31: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8730 - loss: 0.3029 - val_accuracy: 0.9000 - val_loss: 0.2273 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8723 - loss: 0.2807\n",
      "Epoch 32: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8721 - loss: 0.2831 - val_accuracy: 0.8583 - val_loss: 0.3127 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8933 - loss: 0.2808\n",
      "Epoch 33: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8923 - loss: 0.2826 - val_accuracy: 0.8750 - val_loss: 0.3154 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9051 - loss: 0.2586\n",
      "Epoch 34: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9052 - loss: 0.2581 - val_accuracy: 0.8833 - val_loss: 0.2415 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8921 - loss: 0.2460\n",
      "Epoch 35: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8919 - loss: 0.2463 - val_accuracy: 0.8917 - val_loss: 0.2690 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9008 - loss: 0.2316\n",
      "Epoch 36: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9005 - loss: 0.2321 - val_accuracy: 0.8667 - val_loss: 0.2296 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9126 - loss: 0.2335\n",
      "Epoch 37: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9122 - loss: 0.2343 - val_accuracy: 0.8833 - val_loss: 0.2446 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8774 - loss: 0.2715\n",
      "Epoch 38: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8780 - loss: 0.2708 - val_accuracy: 0.9000 - val_loss: 0.2676 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8796 - loss: 0.2830\n",
      "Epoch 39: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8795 - loss: 0.2828 - val_accuracy: 0.8833 - val_loss: 0.3415 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8647 - loss: 0.3233\n",
      "Epoch 40: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8644 - loss: 0.3233 - val_accuracy: 0.8833 - val_loss: 0.3056 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8978 - loss: 0.2685\n",
      "Epoch 41: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8975 - loss: 0.2685 - val_accuracy: 0.8750 - val_loss: 0.2453 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9075 - loss: 0.2362\n",
      "Epoch 42: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9076 - loss: 0.2354 - val_accuracy: 0.8917 - val_loss: 0.2940 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8956 - loss: 0.2638\n",
      "Epoch 43: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8958 - loss: 0.2621 - val_accuracy: 0.8917 - val_loss: 0.2631 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8850 - loss: 0.2985\n",
      "Epoch 44: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8858 - loss: 0.2952 - val_accuracy: 0.9167 - val_loss: 0.2089 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9264 - loss: 0.1951\n",
      "Epoch 45: val_accuracy did not improve from 0.91667\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9258 - loss: 0.1972 - val_accuracy: 0.9167 - val_loss: 0.2336 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8964 - loss: 0.2436\n",
      "Epoch 46: val_accuracy improved from 0.91667 to 0.94167, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8970 - loss: 0.2435 - val_accuracy: 0.9417 - val_loss: 0.1614 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9088 - loss: 0.1930\n",
      "Epoch 47: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9078 - loss: 0.1954 - val_accuracy: 0.9083 - val_loss: 0.2114 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9202 - loss: 0.2452\n",
      "Epoch 48: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9195 - loss: 0.2450 - val_accuracy: 0.9333 - val_loss: 0.2213 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9230 - loss: 0.2185\n",
      "Epoch 49: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9225 - loss: 0.2183 - val_accuracy: 0.8917 - val_loss: 0.2379 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9273 - loss: 0.1827\n",
      "Epoch 50: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9266 - loss: 0.1842 - val_accuracy: 0.9083 - val_loss: 0.2182 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9300 - loss: 0.1851\n",
      "Epoch 51: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9291 - loss: 0.1860 - val_accuracy: 0.8833 - val_loss: 0.2458 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8751 - loss: 0.2747\n",
      "Epoch 52: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8749 - loss: 0.2757 - val_accuracy: 0.8583 - val_loss: 0.2612 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9130 - loss: 0.2188\n",
      "Epoch 53: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9131 - loss: 0.2193 - val_accuracy: 0.9083 - val_loss: 0.2304 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9046 - loss: 0.2445\n",
      "Epoch 54: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9036 - loss: 0.2459 - val_accuracy: 0.9083 - val_loss: 0.2200 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9055 - loss: 0.2283\n",
      "Epoch 55: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9053 - loss: 0.2291 - val_accuracy: 0.9083 - val_loss: 0.2269 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9010 - loss: 0.2177\n",
      "Epoch 56: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8995 - loss: 0.2206 - val_accuracy: 0.8667 - val_loss: 0.3471 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8787 - loss: 0.3048\n",
      "Epoch 57: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8795 - loss: 0.3026 - val_accuracy: 0.9250 - val_loss: 0.1952 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9268 - loss: 0.1959\n",
      "Epoch 58: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9258 - loss: 0.1987 - val_accuracy: 0.8500 - val_loss: 0.3358 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8992 - loss: 0.2864\n",
      "Epoch 59: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8995 - loss: 0.2826 - val_accuracy: 0.8917 - val_loss: 0.2084 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9216 - loss: 0.1940\n",
      "Epoch 60: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9213 - loss: 0.1951 - val_accuracy: 0.9250 - val_loss: 0.2122 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9166 - loss: 0.2443\n",
      "Epoch 61: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9173 - loss: 0.2421 - val_accuracy: 0.9083 - val_loss: 0.2190 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9219 - loss: 0.2007\n",
      "Epoch 62: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9215 - loss: 0.2006 - val_accuracy: 0.9000 - val_loss: 0.2176 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9201 - loss: 0.2136\n",
      "Epoch 63: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9190 - loss: 0.2138 - val_accuracy: 0.9167 - val_loss: 0.1988 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9383 - loss: 0.1739\n",
      "Epoch 64: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9375 - loss: 0.1747 - val_accuracy: 0.8833 - val_loss: 0.1999 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9201 - loss: 0.1949\n",
      "Epoch 65: val_accuracy improved from 0.94167 to 0.95000, saving model to saved_models/best_model_final.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9202 - loss: 0.1959 - val_accuracy: 0.9500 - val_loss: 0.1431 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9057 - loss: 0.2272\n",
      "Epoch 66: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9030 - loss: 0.2325 - val_accuracy: 0.8583 - val_loss: 0.3080 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8877 - loss: 0.2431\n",
      "Epoch 67: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8883 - loss: 0.2426 - val_accuracy: 0.9250 - val_loss: 0.2056 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8929 - loss: 0.2294\n",
      "Epoch 68: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8938 - loss: 0.2285 - val_accuracy: 0.9083 - val_loss: 0.2143 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9126 - loss: 0.1853\n",
      "Epoch 69: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9135 - loss: 0.1851 - val_accuracy: 0.9250 - val_loss: 0.1634 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9160 - loss: 0.1858\n",
      "Epoch 70: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9149 - loss: 0.1887 - val_accuracy: 0.9333 - val_loss: 0.1972 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9138 - loss: 0.2165\n",
      "Epoch 71: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9135 - loss: 0.2167 - val_accuracy: 0.8917 - val_loss: 0.2355 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9002 - loss: 0.2387\n",
      "Epoch 72: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8998 - loss: 0.2375 - val_accuracy: 0.8833 - val_loss: 0.2305 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9171 - loss: 0.1902\n",
      "Epoch 73: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9173 - loss: 0.1899 - val_accuracy: 0.9083 - val_loss: 0.2577 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9252 - loss: 0.1715\n",
      "Epoch 74: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9247 - loss: 0.1723 - val_accuracy: 0.9250 - val_loss: 0.1993 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9015 - loss: 0.2343\n",
      "Epoch 75: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9013 - loss: 0.2356 - val_accuracy: 0.9167 - val_loss: 0.2009 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9081 - loss: 0.2367\n",
      "Epoch 76: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9088 - loss: 0.2352 - val_accuracy: 0.9250 - val_loss: 0.2118 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9050 - loss: 0.1968\n",
      "Epoch 77: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9055 - loss: 0.1973 - val_accuracy: 0.9333 - val_loss: 0.1696 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8911 - loss: 0.2403\n",
      "Epoch 78: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8921 - loss: 0.2384 - val_accuracy: 0.9083 - val_loss: 0.2270 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9218 - loss: 0.2029\n",
      "Epoch 79: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9218 - loss: 0.2025 - val_accuracy: 0.8917 - val_loss: 0.2304 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9125 - loss: 0.2144\n",
      "Epoch 80: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9125 - loss: 0.2148 - val_accuracy: 0.8917 - val_loss: 0.2017 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9381 - loss: 0.1854\n",
      "Epoch 81: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9353 - loss: 0.1884 - val_accuracy: 0.9083 - val_loss: 0.1869 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9247 - loss: 0.2006\n",
      "Epoch 82: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9246 - loss: 0.2010 - val_accuracy: 0.9333 - val_loss: 0.1817 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9246 - loss: 0.1903\n",
      "Epoch 83: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9244 - loss: 0.1904 - val_accuracy: 0.9083 - val_loss: 0.1988 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9424 - loss: 0.1462\n",
      "Epoch 84: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9417 - loss: 0.1476 - val_accuracy: 0.9000 - val_loss: 0.2311 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9317 - loss: 0.1810\n",
      "Epoch 85: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9307 - loss: 0.1822 - val_accuracy: 0.9167 - val_loss: 0.2112 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9294 - loss: 0.1904\n",
      "Epoch 86: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9284 - loss: 0.1925 - val_accuracy: 0.9083 - val_loss: 0.2039 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9225 - loss: 0.1908\n",
      "Epoch 87: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9212 - loss: 0.1948 - val_accuracy: 0.8583 - val_loss: 0.4066 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9082 - loss: 0.2218\n",
      "Epoch 88: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9089 - loss: 0.2203 - val_accuracy: 0.8917 - val_loss: 0.2604 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9228 - loss: 0.2114\n",
      "Epoch 89: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9234 - loss: 0.2108 - val_accuracy: 0.9333 - val_loss: 0.1676 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9173 - loss: 0.1888\n",
      "Epoch 90: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9175 - loss: 0.1890 - val_accuracy: 0.9333 - val_loss: 0.1655 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9352 - loss: 0.1797\n",
      "Epoch 91: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9343 - loss: 0.1806 - val_accuracy: 0.9417 - val_loss: 0.1570 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9035 - loss: 0.2134\n",
      "Epoch 92: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9045 - loss: 0.2119 - val_accuracy: 0.9417 - val_loss: 0.1945 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9313 - loss: 0.1673\n",
      "Epoch 93: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9311 - loss: 0.1678 - val_accuracy: 0.9417 - val_loss: 0.1537 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9236 - loss: 0.1787\n",
      "Epoch 94: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9239 - loss: 0.1785 - val_accuracy: 0.9000 - val_loss: 0.1977 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9314 - loss: 0.1721\n",
      "Epoch 95: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9304 - loss: 0.1743 - val_accuracy: 0.9250 - val_loss: 0.1552 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9317 - loss: 0.1665\n",
      "Epoch 96: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9315 - loss: 0.1667 - val_accuracy: 0.8917 - val_loss: 0.2161 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9293 - loss: 0.1806\n",
      "Epoch 97: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9295 - loss: 0.1805 - val_accuracy: 0.9167 - val_loss: 0.2212 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9219 - loss: 0.1789\n",
      "Epoch 98: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9216 - loss: 0.1798 - val_accuracy: 0.9000 - val_loss: 0.2978 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9098 - loss: 0.2397\n",
      "Epoch 99: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9098 - loss: 0.2386 - val_accuracy: 0.9083 - val_loss: 0.1958 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9259 - loss: 0.1791\n",
      "Epoch 100: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9264 - loss: 0.1771 - val_accuracy: 0.9083 - val_loss: 0.1825 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.9531 - loss: 0.2065\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "EPOCHS = 100\n",
    "RANDOM_SEED = 1024\n",
    "\n",
    "# Hyperparameters\n",
    "drop = 0.25\n",
    "kernel_initializer = 'he_uniform'\n",
    "optimizer = 'Adam'\n",
    "\n",
    "# Set up the directories\n",
    "train_dir = \"../Images_data/training_test_reduced/training_set\"\n",
    "test_dir = \"../Images_data/training_test_reduced/test_set\"\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='training_log.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Save hyperparameters\n",
    "with open('hyperparameters.txt', 'w') as f:\n",
    "    f.write(f\"Epochs: {EPOCHS}\\n\")\n",
    "    f.write(f\"Optimizer: {optimizer}\\n\")\n",
    "    f.write(f\"Kernel Initializer: {kernel_initializer}\\n\")\n",
    "    f.write(f\"Dropout: {drop}\\n\")\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data normalization for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    seed=RANDOM_SEED,\n",
    "    shuffle=False  # No shuffling to maintain order for evaluation\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same', input_shape=(32, 32, 3)),\n",
    "        Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop),\n",
    "    \n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(drop),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu', kernel_initializer=kernel_initializer),\n",
    "        Dropout(drop),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    opt = Adam(use_ema=True)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < int(0.3 * epoch):\n",
    "        return lr\n",
    "    else:\n",
    "        return lr # * np.exp(-1)\n",
    "\n",
    "# Function to load images and labels into numpy arrays\n",
    "def load_data(image_paths, labels, target_size):\n",
    "    data = []\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        data.append(img_array)\n",
    "    return np.array(data), to_categorical(np.array(labels), num_classes=3)\n",
    "\n",
    "# Cross-validation settings\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Get the list of all images and labels in the training directory\n",
    "image_paths = []\n",
    "labels = []\n",
    "classes = sorted(os.listdir(train_dir))\n",
    "class_indices = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(train_dir, cls)\n",
    "    if os.path.isdir(cls_dir):\n",
    "        for img in os.listdir(cls_dir):\n",
    "            img_path = os.path.join(cls_dir, img)\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(class_indices[cls])\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Cross-validation loop\n",
    "cv_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(image_paths):\n",
    "    train_data_paths = image_paths[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "    val_data_paths = image_paths[val_index]\n",
    "    val_labels = labels[val_index]\n",
    "    \n",
    "    # Load data for the current fold\n",
    "    train_data, train_labels = load_data(train_data_paths, train_labels, target_size=(32, 32))\n",
    "    val_data, val_labels = load_data(val_data_paths, val_labels, target_size=(32, 32))\n",
    "    \n",
    "    # Create ImageDataGenerators for the current fold\n",
    "    train_generator = train_datagen.flow(train_data, train_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "    validation_generator = train_datagen.flow(val_data, val_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('saved_models/best_model_fold.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    log_csv = CSVLogger(f'saved_logs/my_logs_fold.csv', separator=',', append=False)\n",
    "    callbacks_list = [checkpoint, log_csv, LearningRateScheduler(scheduler)]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    _, val_acc = model.evaluate(validation_generator)\n",
    "    cv_scores.append(val_acc)\n",
    "\n",
    "# Train final model on all training data and evaluate on test data\n",
    "train_data, train_labels = load_data(image_paths, labels, target_size=(32, 32))\n",
    "train_generator = train_datagen.flow(train_data, train_labels, batch_size=32, seed=RANDOM_SEED)\n",
    "\n",
    "model = create_model()\n",
    "checkpoint = ModelCheckpoint('saved_models/best_model_final.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "log_csv = CSVLogger('saved_logs/my_logs_final.csv', separator=',', append=False)\n",
    "callbacks_list = [checkpoint, log_csv, LearningRateScheduler(scheduler)]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "_, test_acc = model.evaluate(test_generator)\n",
    "logging.info(f\"Accuracy on the test dataset: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Calculate average validation accuracy\n",
    "avg_val_acc = np.mean(cv_scores)\n",
    "logging.info(f\"Cross-Validation accuracy: {cv_scores}\")\n",
    "logging.info(f\"Average validation accuracy: {avg_val_acc * 100:.2f}%\")\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_validation_loss.jpg')\n",
    "    np.savetxt('training_validation_loss.txt', np.column_stack((history.history['loss'], history.history['val_loss'])), delimiter=',', header='Training Loss,Validation Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_validation_accuracy.jpg')\n",
    "    np.savetxt('training_validation_accuracy.txt', np.column_stack((history.history['accuracy'], history.history['val_accuracy'])), delimiter=',', header='Training Accuracy,Validation Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_test = model.predict(test_generator)\n",
    "prediction_test = np.argmax(y_pred_test, axis=1)\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "# Parallelizing confusion matrix computation using ThreadPoolExecutor\n",
    "def compute_confusion_matrix(ground_truth, prediction_test):\n",
    "    return confusion_matrix(ground_truth, prediction_test)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    cm = executor.submit(compute_confusion_matrix, ground_truth, prediction_test).result()\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.savefig('confusion_matrix.jpg')\n",
    "np.savetxt('confusion_matrix.txt', cm, delimiter=',')\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(ground_truth, y_pred_test[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Save ROC data for replots\n",
    "for i in range(3):\n",
    "    np.savetxt(f'roc_data_class_{i}.txt', np.column_stack((fpr[i], tpr[i])), delimiter=',', header='FPR,TPR')\n",
    "\n",
    "# Plot ROC AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curve.jpg')\n",
    "plt.show()\n",
    "\n",
    "logging.info(\"Finished training and evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy-VS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

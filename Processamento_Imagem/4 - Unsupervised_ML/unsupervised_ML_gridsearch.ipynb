{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training and test datasets...\n",
      "Datasets loaded.\n",
      "Extracting features...\n",
      "Features extracted.\n",
      "Starting GridSearch for Random Forest hyperparameters...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.filters import sobel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Dataset path\n",
    "train_path = \"images/cats_dogs_light/train/*\"\n",
    "test_path = \"images/cats_dogs_light/test/*\"\n",
    "\n",
    "# Resize images to\n",
    "SIZE = 128\n",
    "\n",
    "# Function to count the number of images\n",
    "def count_images(path):\n",
    "    count = 0\n",
    "    for directory_path in glob.glob(path):\n",
    "        count += len(glob.glob(os.path.join(directory_path, \"*.jpg\")))\n",
    "    return count\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(path):\n",
    "    num_images = count_images(path)\n",
    "    images = np.zeros((num_images, SIZE, SIZE), dtype=np.uint8)\n",
    "    labels = np.empty(num_images, dtype=object)\n",
    "    \n",
    "    idx = 0\n",
    "    for directory_path in glob.glob(path):\n",
    "        label = os.path.basename(directory_path)\n",
    "        for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images[idx] = img\n",
    "            labels[idx] = label\n",
    "            idx += 1\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Load training and test datasets\n",
    "print(\"Loading training and test datasets...\")\n",
    "train_images, train_labels = load_images_and_labels(train_path)\n",
    "test_images, test_labels = load_images_and_labels(test_path)\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Encode labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels_encoded = le.fit_transform(train_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train, x_test = train_images / 255.0, test_images / 255.0\n",
    "y_train, y_test = train_labels_encoded, test_labels_encoded\n",
    "\n",
    "# Feature extractor function\n",
    "def feature_extractor(images):\n",
    "    num_images = images.shape[0]\n",
    "    image_dataset = []\n",
    "\n",
    "    def process_image(image_idx):\n",
    "        img = images[image_idx, :, :]\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # Pixel values\n",
    "        pixel_values = img.reshape(-1)\n",
    "        df['Pixel_Value'] = pixel_values\n",
    "\n",
    "        # Gabor filters\n",
    "        num = 1\n",
    "        for theta in range(2):\n",
    "            theta = theta / 4. * np.pi\n",
    "            for sigma in (1, 3):\n",
    "                lamda = np.pi/4\n",
    "                gamma = 0.5\n",
    "                gabor_label = f'Gabor{num}'\n",
    "                kernel = cv2.getGaborKernel((9, 9), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)\n",
    "                fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel).reshape(-1)\n",
    "                df[gabor_label] = fimg\n",
    "                num += 1\n",
    "\n",
    "        # Sobel filter\n",
    "        edge_sobel = sobel(img).reshape(-1)\n",
    "        df['Sobel'] = edge_sobel\n",
    "\n",
    "        return df\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(process_image, range(num_images)))\n",
    "\n",
    "    image_dataset = pd.concat(results, ignore_index=True)\n",
    "    return image_dataset\n",
    "\n",
    "print(\"Extracting features...\")\n",
    "train_features = feature_extractor(x_train)\n",
    "test_features = feature_extractor(x_test)\n",
    "print(\"Features extracted.\")\n",
    "\n",
    "# Reshape to a vector for Random Forest training\n",
    "X_for_RF = train_features.values.reshape((x_train.shape[0], -1))\n",
    "test_for_RF = test_features.values.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# GridSearch setup\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid,\n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "def run_grid_search():\n",
    "    grid_search.fit(X_for_RF, y_train)\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    test_prediction = best_rf.predict(test_for_RF)\n",
    "    accuracy = metrics.accuracy_score(y_test, test_prediction)\n",
    "    return best_rf, accuracy\n",
    "\n",
    "print(\"Starting GridSearch for Random Forest hyperparameters...\")\n",
    "desired_accuracy = 0.8\n",
    "best_model = None\n",
    "current_accuracy = 0.0\n",
    "\n",
    "while current_accuracy < desired_accuracy:\n",
    "    best_model, current_accuracy = run_grid_search()\n",
    "    print(f\"Current best accuracy: {current_accuracy}\")\n",
    "\n",
    "print(f\"Best model parameters: {best_model.get_params()}\")\n",
    "print(f\"Achieved accuracy: {current_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy-VS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
